//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-30672275
// Cuda compilation tools, release 11.5, V11.5.119
// Based on NVVM 7.0.1
//

.version 7.5
.target sm_75
.address_size 64

	// .globl	heavy_hash
.global .align 1 .b8 rho[24] = {1, 3, 6, 10, 15, 21, 28, 36, 45, 55, 2, 14, 27, 41, 56, 8, 25, 43, 62, 18, 39, 61, 20, 44};
.global .align 1 .b8 pi[24] = {10, 7, 11, 17, 18, 3, 5, 16, 8, 21, 24, 4, 15, 23, 19, 13, 12, 2, 20, 14, 22, 9, 6, 1};
.global .align 8 .b8 RC[192] = {1, 0, 0, 0, 0, 0, 0, 0, 130, 128, 0, 0, 0, 0, 0, 0, 138, 128, 0, 0, 0, 0, 0, 128, 0, 128, 0, 128, 0, 0, 0, 128, 139, 128, 0, 0, 0, 0, 0, 0, 1, 0, 0, 128, 0, 0, 0, 0, 129, 128, 0, 128, 0, 0, 0, 128, 9, 128, 0, 0, 0, 0, 0, 128, 138, 0, 0, 0, 0, 0, 0, 0, 136, 0, 0, 0, 0, 0, 0, 0, 9, 128, 0, 128, 0, 0, 0, 0, 10, 0, 0, 128, 0, 0, 0, 0, 139, 128, 0, 128, 0, 0, 0, 0, 139, 0, 0, 0, 0, 0, 0, 128, 137, 128, 0, 0, 0, 0, 0, 128, 3, 128, 0, 0, 0, 0, 0, 128, 2, 128, 0, 0, 0, 0, 0, 128, 128, 0, 0, 0, 0, 0, 0, 128, 10, 128, 0, 0, 0, 0, 0, 0, 10, 0, 0, 128, 0, 0, 0, 128, 129, 128, 0, 128, 0, 0, 0, 128, 128, 128, 0, 0, 0, 0, 0, 128, 1, 0, 0, 128, 0, 0, 0, 0, 8, 128, 0, 128, 0, 0, 0, 128};
.global .align 8 .b8 _ZZ15xoshiro256_jumpP10ulonglong4E4JUMP[32] = {186, 10, 253, 60, 211, 198, 14, 24, 44, 57, 201, 240, 102, 18, 166, 213, 170, 201, 63, 224, 24, 38, 88, 169, 28, 102, 177, 41, 69, 220, 171, 57};
.global .align 8 .b8 _ZZ20xoshiro256_long_jumpP10ulonglong4E9LONG_JUMP[32] = {191, 203, 253, 254, 62, 93, 225, 118, 179, 47, 82, 28, 68, 78, 0, 197, 65, 226, 78, 133, 105, 0, 113, 119, 53, 230, 203, 42, 176, 155, 16, 57};
.const .align 4 .b8 matrix[4096];
.const .align 8 .b8 hash_header[72];
.const .align 8 .b8 target[32];
.const .align 1 .b8 powP[200] = {61, 216, 246, 161, 13, 255, 60, 17, 60, 126, 2, 183, 85, 136, 191, 41, 210, 68, 251, 14, 114, 46, 95, 30, 160, 105, 152, 245, 163, 164, 165, 27, 101, 45, 94, 135, 202, 175, 47, 123, 70, 226, 220, 41, 214, 97, 239, 74, 16, 91, 65, 173, 30, 152, 58, 24, 156, 194, 155, 120, 12, 246, 107, 119, 64, 49, 102, 136, 51, 241, 235, 248, 240, 95, 40, 67, 60, 28, 101, 46, 10, 74, 241, 64, 5, 7, 150, 15, 82, 145, 41, 91, 135, 103, 227, 68, 21, 55, 177, 37, 164, 241, 112, 236, 137, 218, 233, 130, 143, 93, 200, 230, 35, 178, 180, 133, 31, 96, 26, 178, 70, 106, 163, 100, 144, 84, 133, 52, 26, 133, 47, 122, 28, 221, 6, 15, 66, 177, 59, 86, 29, 2, 162, 193, 228, 104, 22, 69, 228, 229, 29, 186, 141, 95, 9, 5, 65, 87, 2, 209, 74, 207, 206, 155, 132, 78, 202, 137, 219, 46, 116, 168, 39, 148, 176, 72, 114, 82, 139, 231, 156, 206, 252, 177, 188, 165, 175, 130, 207, 41, 17, 93, 131, 67, 130, 111, 120, 124, 185, 2};
.const .align 1 .b8 heavyP[200] = {9, 133, 36, 178, 82, 76, 215, 58, 22, 66, 159, 47, 14, 155, 98, 121, 238, 248, 199, 22, 72, 255, 20, 122, 152, 100, 5, 128, 76, 95, 167, 17, 218, 206, 238, 68, 223, 224, 32, 231, 105, 64, 243, 20, 46, 216, 199, 114, 186, 53, 137, 147, 42, 255, 0, 193, 98, 196, 15, 37, 64, 144, 33, 94, 72, 106, 207, 13, 166, 249, 57, 128, 12, 61, 42, 121, 159, 170, 188, 160, 38, 162, 169, 208, 93, 192, 49, 244, 63, 140, 193, 84, 195, 76, 31, 211, 61, 204, 105, 167, 1, 125, 107, 108, 228, 147, 36, 86, 211, 91, 198, 46, 68, 176, 205, 153, 58, 75, 247, 78, 176, 242, 52, 84, 131, 134, 76, 119, 22, 148, 188, 54, 176, 97, 233, 7, 7, 204, 101, 119, 177, 29, 143, 126, 57, 109, 196, 186, 128, 219, 143, 234, 88, 202, 52, 123, 211, 242, 146, 185, 87, 185, 129, 132, 4, 197, 118, 199, 46, 194, 18, 81, 103, 159, 195, 71, 10, 12, 41, 181, 157, 57, 187, 146, 21, 198, 159, 47, 49, 224, 154, 84, 53, 218, 185, 16, 125, 50, 25, 22};

.visible .entry heavy_hash(
	.param .u64 heavy_hash_param_0,
	.param .u64 heavy_hash_param_1,
	.param .u64 heavy_hash_param_2,
	.param .u8 heavy_hash_param_3,
	.param .u64 heavy_hash_param_4,
	.param .u64 heavy_hash_param_5
)
{
	.reg .pred 	%p<16>;
	.reg .b16 	%rs<14>;
	.reg .b32 	%r<4642>;
	.reg .b64 	%rd<710>;


	ld.param.u8 	%rs1, [heavy_hash_param_3];
	ld.param.u64 	%rd129, [heavy_hash_param_0];
	ld.param.u64 	%rd130, [heavy_hash_param_1];
	ld.param.u64 	%rd131, [heavy_hash_param_2];
	ld.param.u64 	%rd132, [heavy_hash_param_4];
	ld.param.u64 	%rd133, [heavy_hash_param_5];
	cvta.to.global.u64 	%rd1, %rd132;
	cvta.to.global.u64 	%rd2, %rd133;
	mov.u32 	%r5, %ntid.x;
	mov.u32 	%r6, %ctaid.x;
	mov.u32 	%r7, %tid.x;
	mad.lo.s32 	%r8, %r6, %r5, %r7;
	cvt.s64.s32 	%rd3, %r8;
	setp.ge.u64 	%p6, %rd3, %rd131;
	@%p6 bra 	$L__BB0_19;

	cvt.u32.u64 	%r9, %rd3;
	setp.ne.s32 	%p7, %r9, 0;
	@%p7 bra 	$L__BB0_3;

	mov.u64 	%rd134, 0;
	st.global.u64 	[%rd2], %rd134;

$L__BB0_3:
	setp.eq.s16 	%p8, %rs1, 0;
	@%p8 bra 	$L__BB0_5;

	shl.b64 	%rd135, %rd3, 5;
	add.s64 	%rd136, %rd1, %rd135;
	ld.global.v2.u64 	{%rd137, %rd138}, [%rd136];
	mul.lo.s64 	%rd141, %rd138, 5;
	{
	.reg .b64 %lhs;
	.reg .b64 %rhs;
	shl.b64 	%lhs, %rd141, 7;
	shr.b64 	%rhs, %rd141, 57;
	add.u64 	%rd142, %lhs, %rhs;
	}
	mul.lo.s64 	%rd657, %rd142, 9;
	shl.b64 	%rd143, %rd138, 17;
	ld.global.v2.u64 	{%rd144, %rd145}, [%rd136+16];
	xor.b64  	%rd148, %rd144, %rd137;
	xor.b64  	%rd149, %rd145, %rd138;
	xor.b64  	%rd150, %rd138, %rd148;
	xor.b64  	%rd151, %rd137, %rd149;
	st.global.v2.u64 	[%rd136], {%rd151, %rd150};
	{
	.reg .b32 %dummy;
	mov.b64 	{%r10,%dummy}, %rd149;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r11}, %rd149;
	}
	shf.r.wrap.b32 	%r12, %r11, %r10, 19;
	shf.r.wrap.b32 	%r13, %r10, %r11, 19;
	mov.b64 	%rd152, {%r13, %r12};
	xor.b64  	%rd153, %rd148, %rd143;
	st.global.v2.u64 	[%rd136+16], {%rd153, %rd152};
	bra.uni 	$L__BB0_6;

$L__BB0_5:
	ld.global.u64 	%rd154, [%rd1];
	xor.b64  	%rd657, %rd154, %rd3;

$L__BB0_6:
	and.b64  	%rd171, %rd657, %rd129;
	or.b64  	%rd7, %rd171, %rd130;
	ld.const.u64 	%rd172, [hash_header];
	xor.b64  	%rd683, %rd172, 1242148031264380989;
	ld.const.u64 	%rd173, [hash_header+8];
	xor.b64  	%rd678, %rd173, 3008272977830772284;
	ld.const.u64 	%rd174, [hash_header+16];
	xor.b64  	%rd673, %rd174, 2188519011337848018;
	ld.const.u64 	%rd175, [hash_header+24];
	xor.b64  	%rd668, %rd175, 1992179434288343456;
	ld.const.u64 	%rd176, [hash_header+32];
	xor.b64  	%rd663, %rd176, 8876506674959887717;
	ld.const.u64 	%rd177, [hash_header+40];
	xor.b64  	%rd682, %rd177, 5399642050693751366;
	ld.const.u64 	%rd178, [hash_header+48];
	xor.b64  	%rd677, %rd178, 1745875063082670864;
	ld.const.u64 	%rd179, [hash_header+56];
	xor.b64  	%rd672, %rd179, 8605242046444978844;
	ld.const.u64 	%rd180, [hash_header+64];
	xor.b64  	%rd667, %rd180, -510048929142394560;
	xor.b64  	%rd662, %rd7, 3343109343542796272;
	mov.u32 	%r4640, 0;
	mov.u64 	%rd681, 1123092876221303306;
	mov.u64 	%rd680, 3784524041015224902;
	mov.u64 	%rd679, -8517909413761200310;
	mov.u64 	%rd676, 4963925045340115282;
	mov.u64 	%rd675, 1082795874807940378;
	mov.u64 	%rd674, 5237849264682708699;
	mov.u64 	%rd671, -1409360996057663723;
	mov.u64 	%rd670, -4494027153138273982;
	mov.u64 	%rd669, -5621391061570334094;
	mov.u64 	%rd666, -1817099578685924727;
	mov.u64 	%rd665, -5035616039755945756;
	mov.u64 	%rd664, 6706187291358897596;
	mov.u64 	%rd661, -5613068297060437469;
	mov.u64 	%rd660, -3386048033060200563;
	mov.u64 	%rd659, 196324915476054915;
	mov.u64 	%rd658, RC;

$L__BB0_7:
	xor.b64  	%rd181, %rd682, %rd683;
	xor.b64  	%rd182, %rd181, %rd681;
	xor.b64  	%rd183, %rd182, %rd680;
	xor.b64  	%rd184, %rd183, %rd679;
	xor.b64  	%rd185, %rd677, %rd678;
	xor.b64  	%rd186, %rd185, %rd676;
	xor.b64  	%rd187, %rd186, %rd675;
	xor.b64  	%rd188, %rd187, %rd674;
	xor.b64  	%rd189, %rd672, %rd673;
	xor.b64  	%rd190, %rd189, %rd671;
	xor.b64  	%rd191, %rd190, %rd670;
	xor.b64  	%rd192, %rd191, %rd669;
	xor.b64  	%rd193, %rd667, %rd668;
	xor.b64  	%rd194, %rd193, %rd666;
	xor.b64  	%rd195, %rd194, %rd665;
	xor.b64  	%rd196, %rd195, %rd664;
	xor.b64  	%rd197, %rd662, %rd663;
	xor.b64  	%rd198, %rd197, %rd661;
	xor.b64  	%rd199, %rd198, %rd660;
	xor.b64  	%rd200, %rd199, %rd659;
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r15}, %rd188;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r16,%dummy}, %rd188;
	}
	shf.l.wrap.b32 	%r17, %r16, %r15, 1;
	shf.l.wrap.b32 	%r18, %r15, %r16, 1;
	mov.b64 	%rd201, {%r18, %r17};
	xor.b64  	%rd202, %rd200, %rd201;
	xor.b64  	%rd203, %rd202, %rd683;
	xor.b64  	%rd204, %rd682, %rd202;
	xor.b64  	%rd205, %rd681, %rd202;
	xor.b64  	%rd206, %rd680, %rd202;
	xor.b64  	%rd207, %rd679, %rd202;
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r19}, %rd192;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r20,%dummy}, %rd192;
	}
	shf.l.wrap.b32 	%r21, %r20, %r19, 1;
	shf.l.wrap.b32 	%r22, %r19, %r20, 1;
	mov.b64 	%rd208, {%r22, %r21};
	xor.b64  	%rd209, %rd208, %rd184;
	xor.b64  	%rd210, %rd678, %rd209;
	xor.b64  	%rd211, %rd677, %rd209;
	xor.b64  	%rd212, %rd676, %rd209;
	xor.b64  	%rd213, %rd675, %rd209;
	xor.b64  	%rd214, %rd674, %rd209;
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r23}, %rd196;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r24,%dummy}, %rd196;
	}
	shf.l.wrap.b32 	%r25, %r24, %r23, 1;
	shf.l.wrap.b32 	%r26, %r23, %r24, 1;
	mov.b64 	%rd215, {%r26, %r25};
	xor.b64  	%rd216, %rd215, %rd188;
	xor.b64  	%rd217, %rd673, %rd216;
	xor.b64  	%rd218, %rd672, %rd216;
	xor.b64  	%rd219, %rd671, %rd216;
	xor.b64  	%rd220, %rd670, %rd216;
	xor.b64  	%rd221, %rd669, %rd216;
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r27}, %rd200;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r28,%dummy}, %rd200;
	}
	shf.l.wrap.b32 	%r29, %r28, %r27, 1;
	shf.l.wrap.b32 	%r30, %r27, %r28, 1;
	mov.b64 	%rd222, {%r30, %r29};
	xor.b64  	%rd223, %rd222, %rd192;
	xor.b64  	%rd224, %rd668, %rd223;
	xor.b64  	%rd225, %rd667, %rd223;
	xor.b64  	%rd226, %rd666, %rd223;
	xor.b64  	%rd227, %rd665, %rd223;
	xor.b64  	%rd228, %rd664, %rd223;
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r31}, %rd184;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r32,%dummy}, %rd184;
	}
	shf.l.wrap.b32 	%r33, %r32, %r31, 1;
	shf.l.wrap.b32 	%r34, %r31, %r32, 1;
	mov.b64 	%rd229, {%r34, %r33};
	xor.b64  	%rd230, %rd196, %rd229;
	xor.b64  	%rd231, %rd663, %rd230;
	xor.b64  	%rd232, %rd662, %rd230;
	xor.b64  	%rd233, %rd661, %rd230;
	xor.b64  	%rd234, %rd660, %rd230;
	xor.b64  	%rd235, %rd659, %rd230;
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r35}, %rd210;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r36,%dummy}, %rd210;
	}
	shf.l.wrap.b32 	%r37, %r36, %r35, 1;
	shf.l.wrap.b32 	%r38, %r35, %r36, 1;
	mov.b64 	%rd236, {%r38, %r37};
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r39}, %rd205;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r40,%dummy}, %rd205;
	}
	shf.l.wrap.b32 	%r41, %r40, %r39, 3;
	shf.l.wrap.b32 	%r42, %r39, %r40, 3;
	mov.b64 	%rd237, {%r42, %r41};
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r43}, %rd218;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r44,%dummy}, %rd218;
	}
	shf.l.wrap.b32 	%r45, %r44, %r43, 6;
	shf.l.wrap.b32 	%r46, %r43, %r44, 6;
	mov.b64 	%rd238, {%r46, %r45};
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r47}, %rd212;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r48,%dummy}, %rd212;
	}
	shf.l.wrap.b32 	%r49, %r48, %r47, 10;
	shf.l.wrap.b32 	%r50, %r47, %r48, 10;
	mov.b64 	%rd239, {%r50, %r49};
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r51}, %rd220;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r52,%dummy}, %rd220;
	}
	shf.l.wrap.b32 	%r53, %r52, %r51, 15;
	shf.l.wrap.b32 	%r54, %r51, %r52, 15;
	mov.b64 	%rd240, {%r54, %r53};
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r55}, %rd227;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r56,%dummy}, %rd227;
	}
	shf.l.wrap.b32 	%r57, %r56, %r55, 21;
	shf.l.wrap.b32 	%r58, %r55, %r56, 21;
	mov.b64 	%rd241, {%r58, %r57};
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r59}, %rd224;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r60,%dummy}, %rd224;
	}
	shf.l.wrap.b32 	%r61, %r60, %r59, 28;
	shf.l.wrap.b32 	%r62, %r59, %r60, 28;
	mov.b64 	%rd242, {%r62, %r61};
	{
	.reg .b32 %dummy;
	mov.b64 	{%r63,%dummy}, %rd204;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r64}, %rd204;
	}
	shf.r.wrap.b32 	%r65, %r64, %r63, 28;
	shf.r.wrap.b32 	%r66, %r63, %r64, 28;
	mov.b64 	%rd243, {%r66, %r65};
	{
	.reg .b32 %dummy;
	mov.b64 	{%r67,%dummy}, %rd213;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r68}, %rd213;
	}
	shf.r.wrap.b32 	%r69, %r68, %r67, 19;
	shf.r.wrap.b32 	%r70, %r67, %r68, 19;
	mov.b64 	%rd244, {%r70, %r69};
	{
	.reg .b32 %dummy;
	mov.b64 	{%r71,%dummy}, %rd225;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r72}, %rd225;
	}
	shf.r.wrap.b32 	%r73, %r72, %r71, 9;
	shf.r.wrap.b32 	%r74, %r71, %r72, 9;
	mov.b64 	%rd245, {%r74, %r73};
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r75}, %rd214;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r76,%dummy}, %rd214;
	}
	shf.l.wrap.b32 	%r77, %r76, %r75, 2;
	shf.l.wrap.b32 	%r78, %r75, %r76, 2;
	mov.b64 	%rd246, {%r78, %r77};
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r79}, %rd235;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r80,%dummy}, %rd235;
	}
	shf.l.wrap.b32 	%r81, %r80, %r79, 14;
	shf.l.wrap.b32 	%r82, %r79, %r80, 14;
	mov.b64 	%rd247, {%r82, %r81};
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r83}, %rd231;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r84,%dummy}, %rd231;
	}
	shf.l.wrap.b32 	%r85, %r84, %r83, 27;
	shf.l.wrap.b32 	%r86, %r83, %r84, 27;
	mov.b64 	%rd248, {%r86, %r85};
	{
	.reg .b32 %dummy;
	mov.b64 	{%r87,%dummy}, %rd206;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r88}, %rd206;
	}
	shf.r.wrap.b32 	%r89, %r88, %r87, 23;
	shf.r.wrap.b32 	%r90, %r87, %r88, 23;
	mov.b64 	%rd249, {%r90, %r89};
	{
	.reg .b32 %dummy;
	mov.b64 	{%r91,%dummy}, %rd228;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r92}, %rd228;
	}
	shf.r.wrap.b32 	%r93, %r92, %r91, 8;
	shf.r.wrap.b32 	%r94, %r91, %r92, 8;
	mov.b64 	%rd250, {%r94, %r93};
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r95}, %rd234;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r96,%dummy}, %rd234;
	}
	shf.l.wrap.b32 	%r97, %r96, %r95, 8;
	shf.l.wrap.b32 	%r98, %r95, %r96, 8;
	mov.b64 	%rd251, {%r98, %r97};
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r99}, %rd226;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r100,%dummy}, %rd226;
	}
	shf.l.wrap.b32 	%r101, %r100, %r99, 25;
	shf.l.wrap.b32 	%r102, %r99, %r100, 25;
	mov.b64 	%rd252, {%r102, %r101};
	{
	.reg .b32 %dummy;
	mov.b64 	{%r103,%dummy}, %rd219;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r104}, %rd219;
	}
	shf.r.wrap.b32 	%r105, %r104, %r103, 21;
	shf.r.wrap.b32 	%r106, %r103, %r104, 21;
	mov.b64 	%rd253, {%r106, %r105};
	{
	.reg .b32 %dummy;
	mov.b64 	{%r107,%dummy}, %rd217;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r108}, %rd217;
	}
	shf.r.wrap.b32 	%r109, %r108, %r107, 2;
	shf.r.wrap.b32 	%r110, %r107, %r108, 2;
	mov.b64 	%rd254, {%r110, %r109};
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r111}, %rd207;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r112,%dummy}, %rd207;
	}
	shf.l.wrap.b32 	%r113, %r112, %r111, 18;
	shf.l.wrap.b32 	%r114, %r111, %r112, 18;
	mov.b64 	%rd255, {%r114, %r113};
	{
	.reg .b32 %dummy;
	mov.b64 	{%r115,%dummy}, %rd233;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r116}, %rd233;
	}
	shf.r.wrap.b32 	%r117, %r116, %r115, 25;
	shf.r.wrap.b32 	%r118, %r115, %r116, 25;
	mov.b64 	%rd256, {%r118, %r117};
	{
	.reg .b32 %dummy;
	mov.b64 	{%r119,%dummy}, %rd221;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r120}, %rd221;
	}
	shf.r.wrap.b32 	%r121, %r120, %r119, 3;
	shf.r.wrap.b32 	%r122, %r119, %r120, 3;
	mov.b64 	%rd257, {%r122, %r121};
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r123}, %rd232;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r124,%dummy}, %rd232;
	}
	shf.l.wrap.b32 	%r125, %r124, %r123, 20;
	shf.l.wrap.b32 	%r126, %r123, %r124, 20;
	mov.b64 	%rd258, {%r126, %r125};
	{
	.reg .b32 %dummy;
	mov.b64 	{%r127,%dummy}, %rd211;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r128}, %rd211;
	}
	shf.r.wrap.b32 	%r129, %r128, %r127, 20;
	shf.r.wrap.b32 	%r130, %r127, %r128, 20;
	mov.b64 	%rd259, {%r130, %r129};
	not.b64 	%rd260, %rd259;
	and.b64  	%rd261, %rd253, %rd260;
	xor.b64  	%rd262, %rd261, %rd203;
	not.b64 	%rd263, %rd253;
	and.b64  	%rd264, %rd241, %rd263;
	xor.b64  	%rd678, %rd264, %rd259;
	not.b64 	%rd265, %rd241;
	and.b64  	%rd266, %rd247, %rd265;
	xor.b64  	%rd673, %rd266, %rd253;
	not.b64 	%rd267, %rd247;
	and.b64  	%rd268, %rd203, %rd267;
	xor.b64  	%rd668, %rd268, %rd241;
	not.b64 	%rd269, %rd203;
	and.b64  	%rd270, %rd259, %rd269;
	xor.b64  	%rd663, %rd247, %rd270;
	not.b64 	%rd271, %rd258;
	and.b64  	%rd272, %rd237, %rd271;
	xor.b64  	%rd682, %rd272, %rd242;
	not.b64 	%rd273, %rd237;
	and.b64  	%rd274, %rd244, %rd273;
	xor.b64  	%rd677, %rd274, %rd258;
	not.b64 	%rd275, %rd244;
	and.b64  	%rd276, %rd257, %rd275;
	xor.b64  	%rd672, %rd276, %rd237;
	not.b64 	%rd277, %rd257;
	and.b64  	%rd278, %rd242, %rd277;
	xor.b64  	%rd667, %rd278, %rd244;
	not.b64 	%rd279, %rd242;
	and.b64  	%rd280, %rd258, %rd279;
	xor.b64  	%rd662, %rd257, %rd280;
	not.b64 	%rd281, %rd238;
	and.b64  	%rd282, %rd252, %rd281;
	xor.b64  	%rd681, %rd282, %rd236;
	not.b64 	%rd283, %rd252;
	and.b64  	%rd284, %rd251, %rd283;
	xor.b64  	%rd676, %rd284, %rd238;
	not.b64 	%rd285, %rd251;
	and.b64  	%rd286, %rd255, %rd285;
	xor.b64  	%rd671, %rd286, %rd252;
	not.b64 	%rd287, %rd255;
	and.b64  	%rd288, %rd236, %rd287;
	xor.b64  	%rd666, %rd288, %rd251;
	not.b64 	%rd289, %rd236;
	and.b64  	%rd290, %rd238, %rd289;
	xor.b64  	%rd661, %rd255, %rd290;
	not.b64 	%rd291, %rd243;
	and.b64  	%rd292, %rd239, %rd291;
	xor.b64  	%rd680, %rd292, %rd248;
	not.b64 	%rd293, %rd239;
	and.b64  	%rd294, %rd240, %rd293;
	xor.b64  	%rd675, %rd294, %rd243;
	not.b64 	%rd295, %rd240;
	and.b64  	%rd296, %rd250, %rd295;
	xor.b64  	%rd670, %rd296, %rd239;
	not.b64 	%rd297, %rd250;
	and.b64  	%rd298, %rd248, %rd297;
	xor.b64  	%rd665, %rd298, %rd240;
	not.b64 	%rd299, %rd248;
	and.b64  	%rd300, %rd243, %rd299;
	xor.b64  	%rd660, %rd250, %rd300;
	not.b64 	%rd301, %rd245;
	and.b64  	%rd302, %rd256, %rd301;
	xor.b64  	%rd679, %rd302, %rd254;
	not.b64 	%rd303, %rd256;
	and.b64  	%rd304, %rd249, %rd303;
	xor.b64  	%rd674, %rd304, %rd245;
	not.b64 	%rd305, %rd249;
	and.b64  	%rd306, %rd246, %rd305;
	xor.b64  	%rd669, %rd306, %rd256;
	not.b64 	%rd307, %rd246;
	and.b64  	%rd308, %rd254, %rd307;
	xor.b64  	%rd664, %rd308, %rd249;
	not.b64 	%rd309, %rd254;
	and.b64  	%rd310, %rd245, %rd309;
	xor.b64  	%rd659, %rd246, %rd310;
	ld.global.nc.u64 	%rd311, [%rd658];
	xor.b64  	%rd683, %rd262, %rd311;
	add.s64 	%rd658, %rd658, 8;
	add.s32 	%r4640, %r4640, 1;
	setp.ne.s32 	%p9, %r4640, 24;
	@%p9 bra 	$L__BB0_7;

	cvt.u16.u64 	%rs2, %rd683;
	and.b16  	%rs3, %rs2, 240;
	shr.u64 	%rd334, %rd683, 8;
	cvt.u32.u64 	%r4228, %rd334;
	shr.u64 	%rd335, %rd683, 16;
	cvt.u32.u64 	%r4229, %rd335;
	shr.u64 	%rd336, %rd683, 24;
	cvt.u32.u64 	%r4230, %rd336;
	shr.u64 	%rd337, %rd683, 32;
	cvt.u32.u64 	%r4231, %rd337;
	shr.u64 	%rd338, %rd683, 40;
	cvt.u32.u64 	%r4232, %rd338;
	shr.u64 	%rd339, %rd683, 48;
	cvt.u32.u64 	%r4233, %rd339;
	shr.u64 	%rd340, %rd683, 56;
	cvt.u32.u64 	%r4234, %rd340;
	shr.u64 	%rd341, %rd678, 8;
	cvt.u32.u64 	%r4235, %rd341;
	shr.u64 	%rd342, %rd678, 16;
	cvt.u32.u64 	%r4236, %rd342;
	shr.u64 	%rd343, %rd678, 24;
	cvt.u32.u64 	%r4237, %rd343;
	shr.u64 	%rd344, %rd678, 32;
	cvt.u32.u64 	%r4238, %rd344;
	shr.u64 	%rd345, %rd678, 40;
	cvt.u32.u64 	%r4239, %rd345;
	shr.u64 	%rd346, %rd678, 48;
	cvt.u32.u64 	%r4240, %rd346;
	shr.u64 	%rd347, %rd678, 56;
	cvt.u32.u64 	%r4241, %rd347;
	shr.u64 	%rd348, %rd673, 8;
	cvt.u32.u64 	%r4242, %rd348;
	shr.u64 	%rd349, %rd673, 16;
	cvt.u32.u64 	%r4243, %rd349;
	shr.u64 	%rd350, %rd673, 24;
	cvt.u32.u64 	%r4244, %rd350;
	shr.u64 	%rd351, %rd673, 32;
	cvt.u32.u64 	%r4245, %rd351;
	shr.u64 	%rd352, %rd673, 40;
	cvt.u32.u64 	%r4246, %rd352;
	shr.u64 	%rd353, %rd673, 48;
	cvt.u32.u64 	%r4247, %rd353;
	shr.u64 	%rd354, %rd673, 56;
	cvt.u32.u64 	%r4248, %rd354;
	shr.u16 	%rs4, %rs3, 4;
	cvt.u32.u64 	%r4249, %rd683;
	shr.u32 	%r4250, %r4249, 12;
	cvt.u32.u16 	%r4251, %rs4;
	and.b32  	%r4252, %r4249, 15;
	prmt.b32 	%r4253, %r4252, %r4251, 30212;
	shl.b32 	%r4254, %r4249, 4;
	and.b32  	%r4255, %r4254, 983040;
	or.b32  	%r4256, %r4253, %r4255;
	shl.b32 	%r4257, %r4228, 24;
	and.b32  	%r4258, %r4257, 251658240;
	or.b32  	%r4165, %r4256, %r4258;
	bfe.u32 	%r4259, %r4249, 20, 4;
	and.b32  	%r4260, %r4229, 15;
	bfi.b32 	%r4261, %r4260, %r4259, 8, 4;
	and.b32  	%r4262, %r4250, 983040;
	or.b32  	%r4263, %r4261, %r4262;
	shl.b32 	%r4264, %r4230, 24;
	and.b32  	%r4265, %r4264, 251658240;
	or.b32  	%r4169, %r4263, %r4265;
	shr.u64 	%rd355, %rd683, 36;
	cvt.u32.u64 	%r4266, %rd355;
	and.b32  	%r4267, %r4266, 15;
	and.b32  	%r4268, %r4231, 15;
	shr.u64 	%rd356, %rd683, 44;
	cvt.u32.u64 	%r4269, %rd356;
	bfi.b32 	%r4270, %r4268, %r4267, 8, 4;
	shl.b32 	%r4271, %r4269, 16;
	and.b32  	%r4272, %r4271, 983040;
	or.b32  	%r4273, %r4270, %r4272;
	shl.b32 	%r4274, %r4232, 24;
	and.b32  	%r4275, %r4274, 251658240;
	or.b32  	%r4173, %r4273, %r4275;
	shr.u64 	%rd357, %rd683, 52;
	cvt.u32.u64 	%r4276, %rd357;
	and.b32  	%r4277, %r4276, 15;
	and.b32  	%r4278, %r4233, 15;
	bfi.b32 	%r4279, %r4278, %r4277, 8, 4;
	and.b32  	%r4280, %r4269, 983040;
	or.b32  	%r4281, %r4279, %r4280;
	shl.b32 	%r4282, %r4234, 24;
	and.b32  	%r4283, %r4282, 251658240;
	or.b32  	%r4177, %r4281, %r4283;
	cvt.u16.u64 	%rs5, %rd678;
	and.b16  	%rs6, %rs5, 240;
	shr.u16 	%rs7, %rs6, 4;
	cvt.u32.u64 	%r4284, %rd678;
	shr.u32 	%r4285, %r4284, 12;
	cvt.u32.u16 	%r4286, %rs7;
	and.b32  	%r4287, %r4284, 15;
	prmt.b32 	%r4288, %r4287, %r4286, 30212;
	shl.b32 	%r4289, %r4284, 4;
	and.b32  	%r4290, %r4289, 983040;
	or.b32  	%r4291, %r4288, %r4290;
	shl.b32 	%r4292, %r4235, 24;
	and.b32  	%r4293, %r4292, 251658240;
	or.b32  	%r4181, %r4291, %r4293;
	bfe.u32 	%r4294, %r4284, 20, 4;
	and.b32  	%r4295, %r4236, 15;
	bfi.b32 	%r4296, %r4295, %r4294, 8, 4;
	and.b32  	%r4297, %r4285, 983040;
	or.b32  	%r4298, %r4296, %r4297;
	shl.b32 	%r4299, %r4237, 24;
	and.b32  	%r4300, %r4299, 251658240;
	or.b32  	%r4185, %r4298, %r4300;
	shr.u64 	%rd358, %rd678, 36;
	cvt.u32.u64 	%r4301, %rd358;
	and.b32  	%r4302, %r4301, 15;
	and.b32  	%r4303, %r4238, 15;
	shr.u64 	%rd359, %rd678, 44;
	cvt.u32.u64 	%r4304, %rd359;
	bfi.b32 	%r4305, %r4303, %r4302, 8, 4;
	shl.b32 	%r4306, %r4304, 16;
	and.b32  	%r4307, %r4306, 983040;
	or.b32  	%r4308, %r4305, %r4307;
	shl.b32 	%r4309, %r4239, 24;
	and.b32  	%r4310, %r4309, 251658240;
	or.b32  	%r4189, %r4308, %r4310;
	shr.u64 	%rd360, %rd678, 52;
	cvt.u32.u64 	%r4311, %rd360;
	and.b32  	%r4312, %r4311, 15;
	and.b32  	%r4313, %r4240, 15;
	bfi.b32 	%r4314, %r4313, %r4312, 8, 4;
	and.b32  	%r4315, %r4304, 983040;
	or.b32  	%r4316, %r4314, %r4315;
	shl.b32 	%r4317, %r4241, 24;
	and.b32  	%r4318, %r4317, 251658240;
	or.b32  	%r4193, %r4316, %r4318;
	cvt.u16.u64 	%rs8, %rd673;
	and.b16  	%rs9, %rs8, 240;
	shr.u16 	%rs10, %rs9, 4;
	cvt.u32.u64 	%r4319, %rd673;
	shr.u32 	%r4320, %r4319, 12;
	cvt.u32.u16 	%r4321, %rs10;
	and.b32  	%r4322, %r4319, 15;
	prmt.b32 	%r4323, %r4322, %r4321, 30212;
	shl.b32 	%r4324, %r4319, 4;
	and.b32  	%r4325, %r4324, 983040;
	or.b32  	%r4326, %r4323, %r4325;
	shl.b32 	%r4327, %r4242, 24;
	and.b32  	%r4328, %r4327, 251658240;
	or.b32  	%r4197, %r4326, %r4328;
	bfe.u32 	%r4329, %r4319, 20, 4;
	and.b32  	%r4330, %r4243, 15;
	bfi.b32 	%r4331, %r4330, %r4329, 8, 4;
	and.b32  	%r4332, %r4320, 983040;
	or.b32  	%r4333, %r4331, %r4332;
	shl.b32 	%r4334, %r4244, 24;
	and.b32  	%r4335, %r4334, 251658240;
	or.b32  	%r4201, %r4333, %r4335;
	shr.u64 	%rd361, %rd673, 36;
	cvt.u32.u64 	%r4336, %rd361;
	and.b32  	%r4337, %r4336, 15;
	and.b32  	%r4338, %r4245, 15;
	shr.u64 	%rd362, %rd673, 44;
	cvt.u32.u64 	%r4339, %rd362;
	bfi.b32 	%r4340, %r4338, %r4337, 8, 4;
	shl.b32 	%r4341, %r4339, 16;
	and.b32  	%r4342, %r4341, 983040;
	or.b32  	%r4343, %r4340, %r4342;
	shl.b32 	%r4344, %r4246, 24;
	and.b32  	%r4345, %r4344, 251658240;
	or.b32  	%r4205, %r4343, %r4345;
	shr.u64 	%rd363, %rd673, 52;
	cvt.u32.u64 	%r4346, %rd363;
	and.b32  	%r4347, %r4346, 15;
	and.b32  	%r4348, %r4247, 15;
	bfi.b32 	%r4349, %r4348, %r4347, 8, 4;
	and.b32  	%r4350, %r4339, 983040;
	or.b32  	%r4351, %r4349, %r4350;
	shl.b32 	%r4352, %r4248, 24;
	and.b32  	%r4353, %r4352, 251658240;
	or.b32  	%r4209, %r4351, %r4353;
	cvt.u16.u64 	%rs11, %rd668;
	and.b16  	%rs12, %rs11, 240;
	shr.u16 	%rs13, %rs12, 4;
	shr.u64 	%rd364, %rd668, 8;
	cvt.u32.u64 	%r4354, %rd364;
	cvt.u32.u64 	%r4355, %rd668;
	shr.u32 	%r4356, %r4355, 12;
	cvt.u32.u16 	%r4357, %rs13;
	and.b32  	%r4358, %r4355, 15;
	prmt.b32 	%r4359, %r4358, %r4357, 30212;
	shl.b32 	%r4360, %r4355, 4;
	and.b32  	%r4361, %r4360, 983040;
	or.b32  	%r4362, %r4359, %r4361;
	shl.b32 	%r4363, %r4354, 24;
	and.b32  	%r4364, %r4363, 251658240;
	or.b32  	%r4213, %r4362, %r4364;
	shr.u64 	%rd365, %rd668, 16;
	cvt.u32.u64 	%r4365, %rd365;
	bfe.u32 	%r4366, %r4355, 20, 4;
	and.b32  	%r4367, %r4365, 15;
	shr.u64 	%rd366, %rd668, 24;
	cvt.u32.u64 	%r4368, %rd366;
	bfi.b32 	%r4369, %r4367, %r4366, 8, 4;
	and.b32  	%r4370, %r4356, 983040;
	or.b32  	%r4371, %r4369, %r4370;
	shl.b32 	%r4372, %r4368, 24;
	and.b32  	%r4373, %r4372, 251658240;
	or.b32  	%r4217, %r4371, %r4373;
	shr.u64 	%rd367, %rd668, 32;
	cvt.u32.u64 	%r4374, %rd367;
	shr.u64 	%rd368, %rd668, 36;
	cvt.u32.u64 	%r4375, %rd368;
	and.b32  	%r4376, %r4375, 15;
	and.b32  	%r4377, %r4374, 15;
	shr.u64 	%rd369, %rd668, 40;
	cvt.u32.u64 	%r4378, %rd369;
	shr.u64 	%rd370, %rd668, 44;
	cvt.u32.u64 	%r4379, %rd370;
	bfi.b32 	%r4380, %r4377, %r4376, 8, 4;
	shl.b32 	%r4381, %r4379, 16;
	and.b32  	%r4382, %r4381, 983040;
	or.b32  	%r4383, %r4380, %r4382;
	shl.b32 	%r4384, %r4378, 24;
	and.b32  	%r4385, %r4384, 251658240;
	or.b32  	%r4221, %r4383, %r4385;
	shr.u64 	%rd371, %rd668, 48;
	cvt.u32.u64 	%r4386, %rd371;
	shr.u64 	%rd372, %rd668, 52;
	cvt.u32.u64 	%r4387, %rd372;
	and.b32  	%r4388, %r4387, 15;
	and.b32  	%r4389, %r4386, 15;
	shr.u64 	%rd373, %rd668, 56;
	cvt.u32.u64 	%r4390, %rd373;
	bfi.b32 	%r4391, %r4389, %r4388, 8, 4;
	and.b32  	%r4392, %r4379, 983040;
	or.b32  	%r4393, %r4391, %r4392;
	shl.b32 	%r4394, %r4390, 24;
	and.b32  	%r4395, %r4394, 251658240;
	or.b32  	%r4225, %r4393, %r4395;
	ld.const.u32 	%r132, [matrix];
	mov.u32 	%r4641, 0;
	// begin inline asm
	dp4a.u32.u32 %r131, %r132, %r4165, %r4641;
	// end inline asm
	ld.const.u32 	%r136, [matrix+4];
	// begin inline asm
	dp4a.u32.u32 %r135, %r136, %r4169, %r131;
	// end inline asm
	ld.const.u32 	%r140, [matrix+8];
	// begin inline asm
	dp4a.u32.u32 %r139, %r140, %r4173, %r135;
	// end inline asm
	ld.const.u32 	%r144, [matrix+12];
	// begin inline asm
	dp4a.u32.u32 %r143, %r144, %r4177, %r139;
	// end inline asm
	ld.const.u32 	%r148, [matrix+16];
	// begin inline asm
	dp4a.u32.u32 %r147, %r148, %r4181, %r143;
	// end inline asm
	ld.const.u32 	%r152, [matrix+20];
	// begin inline asm
	dp4a.u32.u32 %r151, %r152, %r4185, %r147;
	// end inline asm
	ld.const.u32 	%r156, [matrix+24];
	// begin inline asm
	dp4a.u32.u32 %r155, %r156, %r4189, %r151;
	// end inline asm
	ld.const.u32 	%r160, [matrix+28];
	// begin inline asm
	dp4a.u32.u32 %r159, %r160, %r4193, %r155;
	// end inline asm
	ld.const.u32 	%r164, [matrix+32];
	// begin inline asm
	dp4a.u32.u32 %r163, %r164, %r4197, %r159;
	// end inline asm
	ld.const.u32 	%r168, [matrix+36];
	// begin inline asm
	dp4a.u32.u32 %r167, %r168, %r4201, %r163;
	// end inline asm
	ld.const.u32 	%r172, [matrix+40];
	// begin inline asm
	dp4a.u32.u32 %r171, %r172, %r4205, %r167;
	// end inline asm
	ld.const.u32 	%r176, [matrix+44];
	// begin inline asm
	dp4a.u32.u32 %r175, %r176, %r4209, %r171;
	// end inline asm
	ld.const.u32 	%r180, [matrix+48];
	// begin inline asm
	dp4a.u32.u32 %r179, %r180, %r4213, %r175;
	// end inline asm
	ld.const.u32 	%r184, [matrix+52];
	// begin inline asm
	dp4a.u32.u32 %r183, %r184, %r4217, %r179;
	// end inline asm
	ld.const.u32 	%r188, [matrix+56];
	// begin inline asm
	dp4a.u32.u32 %r187, %r188, %r4221, %r183;
	// end inline asm
	ld.const.u32 	%r192, [matrix+60];
	// begin inline asm
	dp4a.u32.u32 %r191, %r192, %r4225, %r187;
	// end inline asm
	ld.const.u32 	%r196, [matrix+64];
	// begin inline asm
	dp4a.u32.u32 %r195, %r196, %r4165, %r4641;
	// end inline asm
	ld.const.u32 	%r200, [matrix+68];
	// begin inline asm
	dp4a.u32.u32 %r199, %r200, %r4169, %r195;
	// end inline asm
	ld.const.u32 	%r204, [matrix+72];
	// begin inline asm
	dp4a.u32.u32 %r203, %r204, %r4173, %r199;
	// end inline asm
	ld.const.u32 	%r208, [matrix+76];
	// begin inline asm
	dp4a.u32.u32 %r207, %r208, %r4177, %r203;
	// end inline asm
	ld.const.u32 	%r212, [matrix+80];
	// begin inline asm
	dp4a.u32.u32 %r211, %r212, %r4181, %r207;
	// end inline asm
	ld.const.u32 	%r216, [matrix+84];
	// begin inline asm
	dp4a.u32.u32 %r215, %r216, %r4185, %r211;
	// end inline asm
	ld.const.u32 	%r220, [matrix+88];
	// begin inline asm
	dp4a.u32.u32 %r219, %r220, %r4189, %r215;
	// end inline asm
	ld.const.u32 	%r224, [matrix+92];
	// begin inline asm
	dp4a.u32.u32 %r223, %r224, %r4193, %r219;
	// end inline asm
	ld.const.u32 	%r228, [matrix+96];
	// begin inline asm
	dp4a.u32.u32 %r227, %r228, %r4197, %r223;
	// end inline asm
	ld.const.u32 	%r232, [matrix+100];
	// begin inline asm
	dp4a.u32.u32 %r231, %r232, %r4201, %r227;
	// end inline asm
	ld.const.u32 	%r236, [matrix+104];
	// begin inline asm
	dp4a.u32.u32 %r235, %r236, %r4205, %r231;
	// end inline asm
	ld.const.u32 	%r240, [matrix+108];
	// begin inline asm
	dp4a.u32.u32 %r239, %r240, %r4209, %r235;
	// end inline asm
	ld.const.u32 	%r244, [matrix+112];
	// begin inline asm
	dp4a.u32.u32 %r243, %r244, %r4213, %r239;
	// end inline asm
	ld.const.u32 	%r248, [matrix+116];
	// begin inline asm
	dp4a.u32.u32 %r247, %r248, %r4217, %r243;
	// end inline asm
	ld.const.u32 	%r252, [matrix+120];
	// begin inline asm
	dp4a.u32.u32 %r251, %r252, %r4221, %r247;
	// end inline asm
	ld.const.u32 	%r256, [matrix+124];
	// begin inline asm
	dp4a.u32.u32 %r255, %r256, %r4225, %r251;
	// end inline asm
	shr.u32 	%r4396, %r191, 6;
	and.b32  	%r4397, %r4396, 240;
	shr.u32 	%r4398, %r255, 10;
	or.b32  	%r4399, %r4398, %r4397;
	cvt.u64.u32 	%rd374, %r4399;
	xor.b64  	%rd375, %rd683, %rd374;
	ld.const.u32 	%r260, [matrix+128];
	// begin inline asm
	dp4a.u32.u32 %r259, %r260, %r4165, %r4641;
	// end inline asm
	ld.const.u32 	%r264, [matrix+132];
	// begin inline asm
	dp4a.u32.u32 %r263, %r264, %r4169, %r259;
	// end inline asm
	ld.const.u32 	%r268, [matrix+136];
	// begin inline asm
	dp4a.u32.u32 %r267, %r268, %r4173, %r263;
	// end inline asm
	ld.const.u32 	%r272, [matrix+140];
	// begin inline asm
	dp4a.u32.u32 %r271, %r272, %r4177, %r267;
	// end inline asm
	ld.const.u32 	%r276, [matrix+144];
	// begin inline asm
	dp4a.u32.u32 %r275, %r276, %r4181, %r271;
	// end inline asm
	ld.const.u32 	%r280, [matrix+148];
	// begin inline asm
	dp4a.u32.u32 %r279, %r280, %r4185, %r275;
	// end inline asm
	ld.const.u32 	%r284, [matrix+152];
	// begin inline asm
	dp4a.u32.u32 %r283, %r284, %r4189, %r279;
	// end inline asm
	ld.const.u32 	%r288, [matrix+156];
	// begin inline asm
	dp4a.u32.u32 %r287, %r288, %r4193, %r283;
	// end inline asm
	ld.const.u32 	%r292, [matrix+160];
	// begin inline asm
	dp4a.u32.u32 %r291, %r292, %r4197, %r287;
	// end inline asm
	ld.const.u32 	%r296, [matrix+164];
	// begin inline asm
	dp4a.u32.u32 %r295, %r296, %r4201, %r291;
	// end inline asm
	ld.const.u32 	%r300, [matrix+168];
	// begin inline asm
	dp4a.u32.u32 %r299, %r300, %r4205, %r295;
	// end inline asm
	ld.const.u32 	%r304, [matrix+172];
	// begin inline asm
	dp4a.u32.u32 %r303, %r304, %r4209, %r299;
	// end inline asm
	ld.const.u32 	%r308, [matrix+176];
	// begin inline asm
	dp4a.u32.u32 %r307, %r308, %r4213, %r303;
	// end inline asm
	ld.const.u32 	%r312, [matrix+180];
	// begin inline asm
	dp4a.u32.u32 %r311, %r312, %r4217, %r307;
	// end inline asm
	ld.const.u32 	%r316, [matrix+184];
	// begin inline asm
	dp4a.u32.u32 %r315, %r316, %r4221, %r311;
	// end inline asm
	ld.const.u32 	%r320, [matrix+188];
	// begin inline asm
	dp4a.u32.u32 %r319, %r320, %r4225, %r315;
	// end inline asm
	ld.const.u32 	%r324, [matrix+192];
	// begin inline asm
	dp4a.u32.u32 %r323, %r324, %r4165, %r4641;
	// end inline asm
	ld.const.u32 	%r328, [matrix+196];
	// begin inline asm
	dp4a.u32.u32 %r327, %r328, %r4169, %r323;
	// end inline asm
	ld.const.u32 	%r332, [matrix+200];
	// begin inline asm
	dp4a.u32.u32 %r331, %r332, %r4173, %r327;
	// end inline asm
	ld.const.u32 	%r336, [matrix+204];
	// begin inline asm
	dp4a.u32.u32 %r335, %r336, %r4177, %r331;
	// end inline asm
	ld.const.u32 	%r340, [matrix+208];
	// begin inline asm
	dp4a.u32.u32 %r339, %r340, %r4181, %r335;
	// end inline asm
	ld.const.u32 	%r344, [matrix+212];
	// begin inline asm
	dp4a.u32.u32 %r343, %r344, %r4185, %r339;
	// end inline asm
	ld.const.u32 	%r348, [matrix+216];
	// begin inline asm
	dp4a.u32.u32 %r347, %r348, %r4189, %r343;
	// end inline asm
	ld.const.u32 	%r352, [matrix+220];
	// begin inline asm
	dp4a.u32.u32 %r351, %r352, %r4193, %r347;
	// end inline asm
	ld.const.u32 	%r356, [matrix+224];
	// begin inline asm
	dp4a.u32.u32 %r355, %r356, %r4197, %r351;
	// end inline asm
	ld.const.u32 	%r360, [matrix+228];
	// begin inline asm
	dp4a.u32.u32 %r359, %r360, %r4201, %r355;
	// end inline asm
	ld.const.u32 	%r364, [matrix+232];
	// begin inline asm
	dp4a.u32.u32 %r363, %r364, %r4205, %r359;
	// end inline asm
	ld.const.u32 	%r368, [matrix+236];
	// begin inline asm
	dp4a.u32.u32 %r367, %r368, %r4209, %r363;
	// end inline asm
	ld.const.u32 	%r372, [matrix+240];
	// begin inline asm
	dp4a.u32.u32 %r371, %r372, %r4213, %r367;
	// end inline asm
	ld.const.u32 	%r376, [matrix+244];
	// begin inline asm
	dp4a.u32.u32 %r375, %r376, %r4217, %r371;
	// end inline asm
	ld.const.u32 	%r380, [matrix+248];
	// begin inline asm
	dp4a.u32.u32 %r379, %r380, %r4221, %r375;
	// end inline asm
	ld.const.u32 	%r384, [matrix+252];
	// begin inline asm
	dp4a.u32.u32 %r383, %r384, %r4225, %r379;
	// end inline asm
	shr.u32 	%r4400, %r319, 6;
	and.b32  	%r4401, %r4400, 240;
	shr.u32 	%r4402, %r383, 10;
	or.b32  	%r4403, %r4402, %r4401;
	cvt.u64.u32 	%rd376, %r4403;
	xor.b64  	%rd377, %rd334, %rd376;
	ld.const.u32 	%r388, [matrix+256];
	// begin inline asm
	dp4a.u32.u32 %r387, %r388, %r4165, %r4641;
	// end inline asm
	ld.const.u32 	%r392, [matrix+260];
	// begin inline asm
	dp4a.u32.u32 %r391, %r392, %r4169, %r387;
	// end inline asm
	ld.const.u32 	%r396, [matrix+264];
	// begin inline asm
	dp4a.u32.u32 %r395, %r396, %r4173, %r391;
	// end inline asm
	ld.const.u32 	%r400, [matrix+268];
	// begin inline asm
	dp4a.u32.u32 %r399, %r400, %r4177, %r395;
	// end inline asm
	ld.const.u32 	%r404, [matrix+272];
	// begin inline asm
	dp4a.u32.u32 %r403, %r404, %r4181, %r399;
	// end inline asm
	ld.const.u32 	%r408, [matrix+276];
	// begin inline asm
	dp4a.u32.u32 %r407, %r408, %r4185, %r403;
	// end inline asm
	ld.const.u32 	%r412, [matrix+280];
	// begin inline asm
	dp4a.u32.u32 %r411, %r412, %r4189, %r407;
	// end inline asm
	ld.const.u32 	%r416, [matrix+284];
	// begin inline asm
	dp4a.u32.u32 %r415, %r416, %r4193, %r411;
	// end inline asm
	ld.const.u32 	%r420, [matrix+288];
	// begin inline asm
	dp4a.u32.u32 %r419, %r420, %r4197, %r415;
	// end inline asm
	ld.const.u32 	%r424, [matrix+292];
	// begin inline asm
	dp4a.u32.u32 %r423, %r424, %r4201, %r419;
	// end inline asm
	ld.const.u32 	%r428, [matrix+296];
	// begin inline asm
	dp4a.u32.u32 %r427, %r428, %r4205, %r423;
	// end inline asm
	ld.const.u32 	%r432, [matrix+300];
	// begin inline asm
	dp4a.u32.u32 %r431, %r432, %r4209, %r427;
	// end inline asm
	ld.const.u32 	%r436, [matrix+304];
	// begin inline asm
	dp4a.u32.u32 %r435, %r436, %r4213, %r431;
	// end inline asm
	ld.const.u32 	%r440, [matrix+308];
	// begin inline asm
	dp4a.u32.u32 %r439, %r440, %r4217, %r435;
	// end inline asm
	ld.const.u32 	%r444, [matrix+312];
	// begin inline asm
	dp4a.u32.u32 %r443, %r444, %r4221, %r439;
	// end inline asm
	ld.const.u32 	%r448, [matrix+316];
	// begin inline asm
	dp4a.u32.u32 %r447, %r448, %r4225, %r443;
	// end inline asm
	ld.const.u32 	%r452, [matrix+320];
	// begin inline asm
	dp4a.u32.u32 %r451, %r452, %r4165, %r4641;
	// end inline asm
	ld.const.u32 	%r456, [matrix+324];
	// begin inline asm
	dp4a.u32.u32 %r455, %r456, %r4169, %r451;
	// end inline asm
	ld.const.u32 	%r460, [matrix+328];
	// begin inline asm
	dp4a.u32.u32 %r459, %r460, %r4173, %r455;
	// end inline asm
	ld.const.u32 	%r464, [matrix+332];
	// begin inline asm
	dp4a.u32.u32 %r463, %r464, %r4177, %r459;
	// end inline asm
	ld.const.u32 	%r468, [matrix+336];
	// begin inline asm
	dp4a.u32.u32 %r467, %r468, %r4181, %r463;
	// end inline asm
	ld.const.u32 	%r472, [matrix+340];
	// begin inline asm
	dp4a.u32.u32 %r471, %r472, %r4185, %r467;
	// end inline asm
	ld.const.u32 	%r476, [matrix+344];
	// begin inline asm
	dp4a.u32.u32 %r475, %r476, %r4189, %r471;
	// end inline asm
	ld.const.u32 	%r480, [matrix+348];
	// begin inline asm
	dp4a.u32.u32 %r479, %r480, %r4193, %r475;
	// end inline asm
	ld.const.u32 	%r484, [matrix+352];
	// begin inline asm
	dp4a.u32.u32 %r483, %r484, %r4197, %r479;
	// end inline asm
	ld.const.u32 	%r488, [matrix+356];
	// begin inline asm
	dp4a.u32.u32 %r487, %r488, %r4201, %r483;
	// end inline asm
	ld.const.u32 	%r492, [matrix+360];
	// begin inline asm
	dp4a.u32.u32 %r491, %r492, %r4205, %r487;
	// end inline asm
	ld.const.u32 	%r496, [matrix+364];
	// begin inline asm
	dp4a.u32.u32 %r495, %r496, %r4209, %r491;
	// end inline asm
	ld.const.u32 	%r500, [matrix+368];
	// begin inline asm
	dp4a.u32.u32 %r499, %r500, %r4213, %r495;
	// end inline asm
	ld.const.u32 	%r504, [matrix+372];
	// begin inline asm
	dp4a.u32.u32 %r503, %r504, %r4217, %r499;
	// end inline asm
	ld.const.u32 	%r508, [matrix+376];
	// begin inline asm
	dp4a.u32.u32 %r507, %r508, %r4221, %r503;
	// end inline asm
	ld.const.u32 	%r512, [matrix+380];
	// begin inline asm
	dp4a.u32.u32 %r511, %r512, %r4225, %r507;
	// end inline asm
	shr.u32 	%r4404, %r447, 6;
	and.b32  	%r4405, %r4404, 240;
	shr.u32 	%r4406, %r511, 10;
	or.b32  	%r4407, %r4406, %r4405;
	cvt.u64.u32 	%rd378, %r4407;
	xor.b64  	%rd379, %rd335, %rd378;
	ld.const.u32 	%r516, [matrix+384];
	// begin inline asm
	dp4a.u32.u32 %r515, %r516, %r4165, %r4641;
	// end inline asm
	ld.const.u32 	%r520, [matrix+388];
	// begin inline asm
	dp4a.u32.u32 %r519, %r520, %r4169, %r515;
	// end inline asm
	ld.const.u32 	%r524, [matrix+392];
	// begin inline asm
	dp4a.u32.u32 %r523, %r524, %r4173, %r519;
	// end inline asm
	ld.const.u32 	%r528, [matrix+396];
	// begin inline asm
	dp4a.u32.u32 %r527, %r528, %r4177, %r523;
	// end inline asm
	ld.const.u32 	%r532, [matrix+400];
	// begin inline asm
	dp4a.u32.u32 %r531, %r532, %r4181, %r527;
	// end inline asm
	ld.const.u32 	%r536, [matrix+404];
	// begin inline asm
	dp4a.u32.u32 %r535, %r536, %r4185, %r531;
	// end inline asm
	ld.const.u32 	%r540, [matrix+408];
	// begin inline asm
	dp4a.u32.u32 %r539, %r540, %r4189, %r535;
	// end inline asm
	ld.const.u32 	%r544, [matrix+412];
	// begin inline asm
	dp4a.u32.u32 %r543, %r544, %r4193, %r539;
	// end inline asm
	ld.const.u32 	%r548, [matrix+416];
	// begin inline asm
	dp4a.u32.u32 %r547, %r548, %r4197, %r543;
	// end inline asm
	ld.const.u32 	%r552, [matrix+420];
	// begin inline asm
	dp4a.u32.u32 %r551, %r552, %r4201, %r547;
	// end inline asm
	ld.const.u32 	%r556, [matrix+424];
	// begin inline asm
	dp4a.u32.u32 %r555, %r556, %r4205, %r551;
	// end inline asm
	ld.const.u32 	%r560, [matrix+428];
	// begin inline asm
	dp4a.u32.u32 %r559, %r560, %r4209, %r555;
	// end inline asm
	ld.const.u32 	%r564, [matrix+432];
	// begin inline asm
	dp4a.u32.u32 %r563, %r564, %r4213, %r559;
	// end inline asm
	ld.const.u32 	%r568, [matrix+436];
	// begin inline asm
	dp4a.u32.u32 %r567, %r568, %r4217, %r563;
	// end inline asm
	ld.const.u32 	%r572, [matrix+440];
	// begin inline asm
	dp4a.u32.u32 %r571, %r572, %r4221, %r567;
	// end inline asm
	ld.const.u32 	%r576, [matrix+444];
	// begin inline asm
	dp4a.u32.u32 %r575, %r576, %r4225, %r571;
	// end inline asm
	ld.const.u32 	%r580, [matrix+448];
	// begin inline asm
	dp4a.u32.u32 %r579, %r580, %r4165, %r4641;
	// end inline asm
	ld.const.u32 	%r584, [matrix+452];
	// begin inline asm
	dp4a.u32.u32 %r583, %r584, %r4169, %r579;
	// end inline asm
	ld.const.u32 	%r588, [matrix+456];
	// begin inline asm
	dp4a.u32.u32 %r587, %r588, %r4173, %r583;
	// end inline asm
	ld.const.u32 	%r592, [matrix+460];
	// begin inline asm
	dp4a.u32.u32 %r591, %r592, %r4177, %r587;
	// end inline asm
	ld.const.u32 	%r596, [matrix+464];
	// begin inline asm
	dp4a.u32.u32 %r595, %r596, %r4181, %r591;
	// end inline asm
	ld.const.u32 	%r600, [matrix+468];
	// begin inline asm
	dp4a.u32.u32 %r599, %r600, %r4185, %r595;
	// end inline asm
	ld.const.u32 	%r604, [matrix+472];
	// begin inline asm
	dp4a.u32.u32 %r603, %r604, %r4189, %r599;
	// end inline asm
	ld.const.u32 	%r608, [matrix+476];
	// begin inline asm
	dp4a.u32.u32 %r607, %r608, %r4193, %r603;
	// end inline asm
	ld.const.u32 	%r612, [matrix+480];
	// begin inline asm
	dp4a.u32.u32 %r611, %r612, %r4197, %r607;
	// end inline asm
	ld.const.u32 	%r616, [matrix+484];
	// begin inline asm
	dp4a.u32.u32 %r615, %r616, %r4201, %r611;
	// end inline asm
	ld.const.u32 	%r620, [matrix+488];
	// begin inline asm
	dp4a.u32.u32 %r619, %r620, %r4205, %r615;
	// end inline asm
	ld.const.u32 	%r624, [matrix+492];
	// begin inline asm
	dp4a.u32.u32 %r623, %r624, %r4209, %r619;
	// end inline asm
	ld.const.u32 	%r628, [matrix+496];
	// begin inline asm
	dp4a.u32.u32 %r627, %r628, %r4213, %r623;
	// end inline asm
	ld.const.u32 	%r632, [matrix+500];
	// begin inline asm
	dp4a.u32.u32 %r631, %r632, %r4217, %r627;
	// end inline asm
	ld.const.u32 	%r636, [matrix+504];
	// begin inline asm
	dp4a.u32.u32 %r635, %r636, %r4221, %r631;
	// end inline asm
	ld.const.u32 	%r640, [matrix+508];
	// begin inline asm
	dp4a.u32.u32 %r639, %r640, %r4225, %r635;
	// end inline asm
	shr.u32 	%r4408, %r575, 6;
	and.b32  	%r4409, %r4408, 240;
	shr.u32 	%r4410, %r639, 10;
	or.b32  	%r4411, %r4410, %r4409;
	cvt.u64.u32 	%rd380, %r4411;
	xor.b64  	%rd381, %rd336, %rd380;
	ld.const.u32 	%r644, [matrix+512];
	// begin inline asm
	dp4a.u32.u32 %r643, %r644, %r4165, %r4641;
	// end inline asm
	ld.const.u32 	%r648, [matrix+516];
	// begin inline asm
	dp4a.u32.u32 %r647, %r648, %r4169, %r643;
	// end inline asm
	ld.const.u32 	%r652, [matrix+520];
	// begin inline asm
	dp4a.u32.u32 %r651, %r652, %r4173, %r647;
	// end inline asm
	ld.const.u32 	%r656, [matrix+524];
	// begin inline asm
	dp4a.u32.u32 %r655, %r656, %r4177, %r651;
	// end inline asm
	ld.const.u32 	%r660, [matrix+528];
	// begin inline asm
	dp4a.u32.u32 %r659, %r660, %r4181, %r655;
	// end inline asm
	ld.const.u32 	%r664, [matrix+532];
	// begin inline asm
	dp4a.u32.u32 %r663, %r664, %r4185, %r659;
	// end inline asm
	ld.const.u32 	%r668, [matrix+536];
	// begin inline asm
	dp4a.u32.u32 %r667, %r668, %r4189, %r663;
	// end inline asm
	ld.const.u32 	%r672, [matrix+540];
	// begin inline asm
	dp4a.u32.u32 %r671, %r672, %r4193, %r667;
	// end inline asm
	ld.const.u32 	%r676, [matrix+544];
	// begin inline asm
	dp4a.u32.u32 %r675, %r676, %r4197, %r671;
	// end inline asm
	ld.const.u32 	%r680, [matrix+548];
	// begin inline asm
	dp4a.u32.u32 %r679, %r680, %r4201, %r675;
	// end inline asm
	ld.const.u32 	%r684, [matrix+552];
	// begin inline asm
	dp4a.u32.u32 %r683, %r684, %r4205, %r679;
	// end inline asm
	ld.const.u32 	%r688, [matrix+556];
	// begin inline asm
	dp4a.u32.u32 %r687, %r688, %r4209, %r683;
	// end inline asm
	ld.const.u32 	%r692, [matrix+560];
	// begin inline asm
	dp4a.u32.u32 %r691, %r692, %r4213, %r687;
	// end inline asm
	ld.const.u32 	%r696, [matrix+564];
	// begin inline asm
	dp4a.u32.u32 %r695, %r696, %r4217, %r691;
	// end inline asm
	ld.const.u32 	%r700, [matrix+568];
	// begin inline asm
	dp4a.u32.u32 %r699, %r700, %r4221, %r695;
	// end inline asm
	ld.const.u32 	%r704, [matrix+572];
	// begin inline asm
	dp4a.u32.u32 %r703, %r704, %r4225, %r699;
	// end inline asm
	ld.const.u32 	%r708, [matrix+576];
	// begin inline asm
	dp4a.u32.u32 %r707, %r708, %r4165, %r4641;
	// end inline asm
	ld.const.u32 	%r712, [matrix+580];
	// begin inline asm
	dp4a.u32.u32 %r711, %r712, %r4169, %r707;
	// end inline asm
	ld.const.u32 	%r716, [matrix+584];
	// begin inline asm
	dp4a.u32.u32 %r715, %r716, %r4173, %r711;
	// end inline asm
	ld.const.u32 	%r720, [matrix+588];
	// begin inline asm
	dp4a.u32.u32 %r719, %r720, %r4177, %r715;
	// end inline asm
	ld.const.u32 	%r724, [matrix+592];
	// begin inline asm
	dp4a.u32.u32 %r723, %r724, %r4181, %r719;
	// end inline asm
	ld.const.u32 	%r728, [matrix+596];
	// begin inline asm
	dp4a.u32.u32 %r727, %r728, %r4185, %r723;
	// end inline asm
	ld.const.u32 	%r732, [matrix+600];
	// begin inline asm
	dp4a.u32.u32 %r731, %r732, %r4189, %r727;
	// end inline asm
	ld.const.u32 	%r736, [matrix+604];
	// begin inline asm
	dp4a.u32.u32 %r735, %r736, %r4193, %r731;
	// end inline asm
	ld.const.u32 	%r740, [matrix+608];
	// begin inline asm
	dp4a.u32.u32 %r739, %r740, %r4197, %r735;
	// end inline asm
	ld.const.u32 	%r744, [matrix+612];
	// begin inline asm
	dp4a.u32.u32 %r743, %r744, %r4201, %r739;
	// end inline asm
	ld.const.u32 	%r748, [matrix+616];
	// begin inline asm
	dp4a.u32.u32 %r747, %r748, %r4205, %r743;
	// end inline asm
	ld.const.u32 	%r752, [matrix+620];
	// begin inline asm
	dp4a.u32.u32 %r751, %r752, %r4209, %r747;
	// end inline asm
	ld.const.u32 	%r756, [matrix+624];
	// begin inline asm
	dp4a.u32.u32 %r755, %r756, %r4213, %r751;
	// end inline asm
	ld.const.u32 	%r760, [matrix+628];
	// begin inline asm
	dp4a.u32.u32 %r759, %r760, %r4217, %r755;
	// end inline asm
	ld.const.u32 	%r764, [matrix+632];
	// begin inline asm
	dp4a.u32.u32 %r763, %r764, %r4221, %r759;
	// end inline asm
	ld.const.u32 	%r768, [matrix+636];
	// begin inline asm
	dp4a.u32.u32 %r767, %r768, %r4225, %r763;
	// end inline asm
	shr.u32 	%r4412, %r703, 6;
	and.b32  	%r4413, %r4412, 240;
	shr.u32 	%r4414, %r767, 10;
	or.b32  	%r4415, %r4414, %r4413;
	cvt.u64.u32 	%rd382, %r4415;
	xor.b64  	%rd383, %rd337, %rd382;
	ld.const.u32 	%r772, [matrix+640];
	// begin inline asm
	dp4a.u32.u32 %r771, %r772, %r4165, %r4641;
	// end inline asm
	ld.const.u32 	%r776, [matrix+644];
	// begin inline asm
	dp4a.u32.u32 %r775, %r776, %r4169, %r771;
	// end inline asm
	ld.const.u32 	%r780, [matrix+648];
	// begin inline asm
	dp4a.u32.u32 %r779, %r780, %r4173, %r775;
	// end inline asm
	ld.const.u32 	%r784, [matrix+652];
	// begin inline asm
	dp4a.u32.u32 %r783, %r784, %r4177, %r779;
	// end inline asm
	ld.const.u32 	%r788, [matrix+656];
	// begin inline asm
	dp4a.u32.u32 %r787, %r788, %r4181, %r783;
	// end inline asm
	ld.const.u32 	%r792, [matrix+660];
	// begin inline asm
	dp4a.u32.u32 %r791, %r792, %r4185, %r787;
	// end inline asm
	ld.const.u32 	%r796, [matrix+664];
	// begin inline asm
	dp4a.u32.u32 %r795, %r796, %r4189, %r791;
	// end inline asm
	ld.const.u32 	%r800, [matrix+668];
	// begin inline asm
	dp4a.u32.u32 %r799, %r800, %r4193, %r795;
	// end inline asm
	ld.const.u32 	%r804, [matrix+672];
	// begin inline asm
	dp4a.u32.u32 %r803, %r804, %r4197, %r799;
	// end inline asm
	ld.const.u32 	%r808, [matrix+676];
	// begin inline asm
	dp4a.u32.u32 %r807, %r808, %r4201, %r803;
	// end inline asm
	ld.const.u32 	%r812, [matrix+680];
	// begin inline asm
	dp4a.u32.u32 %r811, %r812, %r4205, %r807;
	// end inline asm
	ld.const.u32 	%r816, [matrix+684];
	// begin inline asm
	dp4a.u32.u32 %r815, %r816, %r4209, %r811;
	// end inline asm
	ld.const.u32 	%r820, [matrix+688];
	// begin inline asm
	dp4a.u32.u32 %r819, %r820, %r4213, %r815;
	// end inline asm
	ld.const.u32 	%r824, [matrix+692];
	// begin inline asm
	dp4a.u32.u32 %r823, %r824, %r4217, %r819;
	// end inline asm
	ld.const.u32 	%r828, [matrix+696];
	// begin inline asm
	dp4a.u32.u32 %r827, %r828, %r4221, %r823;
	// end inline asm
	ld.const.u32 	%r832, [matrix+700];
	// begin inline asm
	dp4a.u32.u32 %r831, %r832, %r4225, %r827;
	// end inline asm
	ld.const.u32 	%r836, [matrix+704];
	// begin inline asm
	dp4a.u32.u32 %r835, %r836, %r4165, %r4641;
	// end inline asm
	ld.const.u32 	%r840, [matrix+708];
	// begin inline asm
	dp4a.u32.u32 %r839, %r840, %r4169, %r835;
	// end inline asm
	ld.const.u32 	%r844, [matrix+712];
	// begin inline asm
	dp4a.u32.u32 %r843, %r844, %r4173, %r839;
	// end inline asm
	ld.const.u32 	%r848, [matrix+716];
	// begin inline asm
	dp4a.u32.u32 %r847, %r848, %r4177, %r843;
	// end inline asm
	ld.const.u32 	%r852, [matrix+720];
	// begin inline asm
	dp4a.u32.u32 %r851, %r852, %r4181, %r847;
	// end inline asm
	ld.const.u32 	%r856, [matrix+724];
	// begin inline asm
	dp4a.u32.u32 %r855, %r856, %r4185, %r851;
	// end inline asm
	ld.const.u32 	%r860, [matrix+728];
	// begin inline asm
	dp4a.u32.u32 %r859, %r860, %r4189, %r855;
	// end inline asm
	ld.const.u32 	%r864, [matrix+732];
	// begin inline asm
	dp4a.u32.u32 %r863, %r864, %r4193, %r859;
	// end inline asm
	ld.const.u32 	%r868, [matrix+736];
	// begin inline asm
	dp4a.u32.u32 %r867, %r868, %r4197, %r863;
	// end inline asm
	ld.const.u32 	%r872, [matrix+740];
	// begin inline asm
	dp4a.u32.u32 %r871, %r872, %r4201, %r867;
	// end inline asm
	ld.const.u32 	%r876, [matrix+744];
	// begin inline asm
	dp4a.u32.u32 %r875, %r876, %r4205, %r871;
	// end inline asm
	ld.const.u32 	%r880, [matrix+748];
	// begin inline asm
	dp4a.u32.u32 %r879, %r880, %r4209, %r875;
	// end inline asm
	ld.const.u32 	%r884, [matrix+752];
	// begin inline asm
	dp4a.u32.u32 %r883, %r884, %r4213, %r879;
	// end inline asm
	ld.const.u32 	%r888, [matrix+756];
	// begin inline asm
	dp4a.u32.u32 %r887, %r888, %r4217, %r883;
	// end inline asm
	ld.const.u32 	%r892, [matrix+760];
	// begin inline asm
	dp4a.u32.u32 %r891, %r892, %r4221, %r887;
	// end inline asm
	ld.const.u32 	%r896, [matrix+764];
	// begin inline asm
	dp4a.u32.u32 %r895, %r896, %r4225, %r891;
	// end inline asm
	shr.u32 	%r4416, %r831, 6;
	and.b32  	%r4417, %r4416, 240;
	shr.u32 	%r4418, %r895, 10;
	or.b32  	%r4419, %r4418, %r4417;
	cvt.u64.u32 	%rd384, %r4419;
	xor.b64  	%rd385, %rd338, %rd384;
	ld.const.u32 	%r900, [matrix+768];
	// begin inline asm
	dp4a.u32.u32 %r899, %r900, %r4165, %r4641;
	// end inline asm
	ld.const.u32 	%r904, [matrix+772];
	// begin inline asm
	dp4a.u32.u32 %r903, %r904, %r4169, %r899;
	// end inline asm
	ld.const.u32 	%r908, [matrix+776];
	// begin inline asm
	dp4a.u32.u32 %r907, %r908, %r4173, %r903;
	// end inline asm
	ld.const.u32 	%r912, [matrix+780];
	// begin inline asm
	dp4a.u32.u32 %r911, %r912, %r4177, %r907;
	// end inline asm
	ld.const.u32 	%r916, [matrix+784];
	// begin inline asm
	dp4a.u32.u32 %r915, %r916, %r4181, %r911;
	// end inline asm
	ld.const.u32 	%r920, [matrix+788];
	// begin inline asm
	dp4a.u32.u32 %r919, %r920, %r4185, %r915;
	// end inline asm
	ld.const.u32 	%r924, [matrix+792];
	// begin inline asm
	dp4a.u32.u32 %r923, %r924, %r4189, %r919;
	// end inline asm
	ld.const.u32 	%r928, [matrix+796];
	// begin inline asm
	dp4a.u32.u32 %r927, %r928, %r4193, %r923;
	// end inline asm
	ld.const.u32 	%r932, [matrix+800];
	// begin inline asm
	dp4a.u32.u32 %r931, %r932, %r4197, %r927;
	// end inline asm
	ld.const.u32 	%r936, [matrix+804];
	// begin inline asm
	dp4a.u32.u32 %r935, %r936, %r4201, %r931;
	// end inline asm
	ld.const.u32 	%r940, [matrix+808];
	// begin inline asm
	dp4a.u32.u32 %r939, %r940, %r4205, %r935;
	// end inline asm
	ld.const.u32 	%r944, [matrix+812];
	// begin inline asm
	dp4a.u32.u32 %r943, %r944, %r4209, %r939;
	// end inline asm
	ld.const.u32 	%r948, [matrix+816];
	// begin inline asm
	dp4a.u32.u32 %r947, %r948, %r4213, %r943;
	// end inline asm
	ld.const.u32 	%r952, [matrix+820];
	// begin inline asm
	dp4a.u32.u32 %r951, %r952, %r4217, %r947;
	// end inline asm
	ld.const.u32 	%r956, [matrix+824];
	// begin inline asm
	dp4a.u32.u32 %r955, %r956, %r4221, %r951;
	// end inline asm
	ld.const.u32 	%r960, [matrix+828];
	// begin inline asm
	dp4a.u32.u32 %r959, %r960, %r4225, %r955;
	// end inline asm
	ld.const.u32 	%r964, [matrix+832];
	// begin inline asm
	dp4a.u32.u32 %r963, %r964, %r4165, %r4641;
	// end inline asm
	ld.const.u32 	%r968, [matrix+836];
	// begin inline asm
	dp4a.u32.u32 %r967, %r968, %r4169, %r963;
	// end inline asm
	ld.const.u32 	%r972, [matrix+840];
	// begin inline asm
	dp4a.u32.u32 %r971, %r972, %r4173, %r967;
	// end inline asm
	ld.const.u32 	%r976, [matrix+844];
	// begin inline asm
	dp4a.u32.u32 %r975, %r976, %r4177, %r971;
	// end inline asm
	ld.const.u32 	%r980, [matrix+848];
	// begin inline asm
	dp4a.u32.u32 %r979, %r980, %r4181, %r975;
	// end inline asm
	ld.const.u32 	%r984, [matrix+852];
	// begin inline asm
	dp4a.u32.u32 %r983, %r984, %r4185, %r979;
	// end inline asm
	ld.const.u32 	%r988, [matrix+856];
	// begin inline asm
	dp4a.u32.u32 %r987, %r988, %r4189, %r983;
	// end inline asm
	ld.const.u32 	%r992, [matrix+860];
	// begin inline asm
	dp4a.u32.u32 %r991, %r992, %r4193, %r987;
	// end inline asm
	ld.const.u32 	%r996, [matrix+864];
	// begin inline asm
	dp4a.u32.u32 %r995, %r996, %r4197, %r991;
	// end inline asm
	ld.const.u32 	%r1000, [matrix+868];
	// begin inline asm
	dp4a.u32.u32 %r999, %r1000, %r4201, %r995;
	// end inline asm
	ld.const.u32 	%r1004, [matrix+872];
	// begin inline asm
	dp4a.u32.u32 %r1003, %r1004, %r4205, %r999;
	// end inline asm
	ld.const.u32 	%r1008, [matrix+876];
	// begin inline asm
	dp4a.u32.u32 %r1007, %r1008, %r4209, %r1003;
	// end inline asm
	ld.const.u32 	%r1012, [matrix+880];
	// begin inline asm
	dp4a.u32.u32 %r1011, %r1012, %r4213, %r1007;
	// end inline asm
	ld.const.u32 	%r1016, [matrix+884];
	// begin inline asm
	dp4a.u32.u32 %r1015, %r1016, %r4217, %r1011;
	// end inline asm
	ld.const.u32 	%r1020, [matrix+888];
	// begin inline asm
	dp4a.u32.u32 %r1019, %r1020, %r4221, %r1015;
	// end inline asm
	ld.const.u32 	%r1024, [matrix+892];
	// begin inline asm
	dp4a.u32.u32 %r1023, %r1024, %r4225, %r1019;
	// end inline asm
	shr.u32 	%r4420, %r959, 6;
	and.b32  	%r4421, %r4420, 240;
	shr.u32 	%r4422, %r1023, 10;
	or.b32  	%r4423, %r4422, %r4421;
	cvt.u64.u32 	%rd386, %r4423;
	xor.b64  	%rd387, %rd339, %rd386;
	ld.const.u32 	%r1028, [matrix+896];
	// begin inline asm
	dp4a.u32.u32 %r1027, %r1028, %r4165, %r4641;
	// end inline asm
	ld.const.u32 	%r1032, [matrix+900];
	// begin inline asm
	dp4a.u32.u32 %r1031, %r1032, %r4169, %r1027;
	// end inline asm
	ld.const.u32 	%r1036, [matrix+904];
	// begin inline asm
	dp4a.u32.u32 %r1035, %r1036, %r4173, %r1031;
	// end inline asm
	ld.const.u32 	%r1040, [matrix+908];
	// begin inline asm
	dp4a.u32.u32 %r1039, %r1040, %r4177, %r1035;
	// end inline asm
	ld.const.u32 	%r1044, [matrix+912];
	// begin inline asm
	dp4a.u32.u32 %r1043, %r1044, %r4181, %r1039;
	// end inline asm
	ld.const.u32 	%r1048, [matrix+916];
	// begin inline asm
	dp4a.u32.u32 %r1047, %r1048, %r4185, %r1043;
	// end inline asm
	ld.const.u32 	%r1052, [matrix+920];
	// begin inline asm
	dp4a.u32.u32 %r1051, %r1052, %r4189, %r1047;
	// end inline asm
	ld.const.u32 	%r1056, [matrix+924];
	// begin inline asm
	dp4a.u32.u32 %r1055, %r1056, %r4193, %r1051;
	// end inline asm
	ld.const.u32 	%r1060, [matrix+928];
	// begin inline asm
	dp4a.u32.u32 %r1059, %r1060, %r4197, %r1055;
	// end inline asm
	ld.const.u32 	%r1064, [matrix+932];
	// begin inline asm
	dp4a.u32.u32 %r1063, %r1064, %r4201, %r1059;
	// end inline asm
	ld.const.u32 	%r1068, [matrix+936];
	// begin inline asm
	dp4a.u32.u32 %r1067, %r1068, %r4205, %r1063;
	// end inline asm
	ld.const.u32 	%r1072, [matrix+940];
	// begin inline asm
	dp4a.u32.u32 %r1071, %r1072, %r4209, %r1067;
	// end inline asm
	ld.const.u32 	%r1076, [matrix+944];
	// begin inline asm
	dp4a.u32.u32 %r1075, %r1076, %r4213, %r1071;
	// end inline asm
	ld.const.u32 	%r1080, [matrix+948];
	// begin inline asm
	dp4a.u32.u32 %r1079, %r1080, %r4217, %r1075;
	// end inline asm
	ld.const.u32 	%r1084, [matrix+952];
	// begin inline asm
	dp4a.u32.u32 %r1083, %r1084, %r4221, %r1079;
	// end inline asm
	ld.const.u32 	%r1088, [matrix+956];
	// begin inline asm
	dp4a.u32.u32 %r1087, %r1088, %r4225, %r1083;
	// end inline asm
	ld.const.u32 	%r1092, [matrix+960];
	// begin inline asm
	dp4a.u32.u32 %r1091, %r1092, %r4165, %r4641;
	// end inline asm
	ld.const.u32 	%r1096, [matrix+964];
	// begin inline asm
	dp4a.u32.u32 %r1095, %r1096, %r4169, %r1091;
	// end inline asm
	ld.const.u32 	%r1100, [matrix+968];
	// begin inline asm
	dp4a.u32.u32 %r1099, %r1100, %r4173, %r1095;
	// end inline asm
	ld.const.u32 	%r1104, [matrix+972];
	// begin inline asm
	dp4a.u32.u32 %r1103, %r1104, %r4177, %r1099;
	// end inline asm
	ld.const.u32 	%r1108, [matrix+976];
	// begin inline asm
	dp4a.u32.u32 %r1107, %r1108, %r4181, %r1103;
	// end inline asm
	ld.const.u32 	%r1112, [matrix+980];
	// begin inline asm
	dp4a.u32.u32 %r1111, %r1112, %r4185, %r1107;
	// end inline asm
	ld.const.u32 	%r1116, [matrix+984];
	// begin inline asm
	dp4a.u32.u32 %r1115, %r1116, %r4189, %r1111;
	// end inline asm
	ld.const.u32 	%r1120, [matrix+988];
	// begin inline asm
	dp4a.u32.u32 %r1119, %r1120, %r4193, %r1115;
	// end inline asm
	ld.const.u32 	%r1124, [matrix+992];
	// begin inline asm
	dp4a.u32.u32 %r1123, %r1124, %r4197, %r1119;
	// end inline asm
	ld.const.u32 	%r1128, [matrix+996];
	// begin inline asm
	dp4a.u32.u32 %r1127, %r1128, %r4201, %r1123;
	// end inline asm
	ld.const.u32 	%r1132, [matrix+1000];
	// begin inline asm
	dp4a.u32.u32 %r1131, %r1132, %r4205, %r1127;
	// end inline asm
	ld.const.u32 	%r1136, [matrix+1004];
	// begin inline asm
	dp4a.u32.u32 %r1135, %r1136, %r4209, %r1131;
	// end inline asm
	ld.const.u32 	%r1140, [matrix+1008];
	// begin inline asm
	dp4a.u32.u32 %r1139, %r1140, %r4213, %r1135;
	// end inline asm
	ld.const.u32 	%r1144, [matrix+1012];
	// begin inline asm
	dp4a.u32.u32 %r1143, %r1144, %r4217, %r1139;
	// end inline asm
	ld.const.u32 	%r1148, [matrix+1016];
	// begin inline asm
	dp4a.u32.u32 %r1147, %r1148, %r4221, %r1143;
	// end inline asm
	ld.const.u32 	%r1152, [matrix+1020];
	// begin inline asm
	dp4a.u32.u32 %r1151, %r1152, %r4225, %r1147;
	// end inline asm
	shr.u32 	%r4424, %r1087, 6;
	and.b32  	%r4425, %r4424, 240;
	shr.u32 	%r4426, %r1151, 10;
	or.b32  	%r4427, %r4426, %r4425;
	cvt.u64.u32 	%rd388, %r4427;
	ld.const.u32 	%r1156, [matrix+1024];
	// begin inline asm
	dp4a.u32.u32 %r1155, %r1156, %r4165, %r4641;
	// end inline asm
	ld.const.u32 	%r1160, [matrix+1028];
	// begin inline asm
	dp4a.u32.u32 %r1159, %r1160, %r4169, %r1155;
	// end inline asm
	ld.const.u32 	%r1164, [matrix+1032];
	// begin inline asm
	dp4a.u32.u32 %r1163, %r1164, %r4173, %r1159;
	// end inline asm
	ld.const.u32 	%r1168, [matrix+1036];
	// begin inline asm
	dp4a.u32.u32 %r1167, %r1168, %r4177, %r1163;
	// end inline asm
	ld.const.u32 	%r1172, [matrix+1040];
	// begin inline asm
	dp4a.u32.u32 %r1171, %r1172, %r4181, %r1167;
	// end inline asm
	ld.const.u32 	%r1176, [matrix+1044];
	// begin inline asm
	dp4a.u32.u32 %r1175, %r1176, %r4185, %r1171;
	// end inline asm
	ld.const.u32 	%r1180, [matrix+1048];
	// begin inline asm
	dp4a.u32.u32 %r1179, %r1180, %r4189, %r1175;
	// end inline asm
	ld.const.u32 	%r1184, [matrix+1052];
	// begin inline asm
	dp4a.u32.u32 %r1183, %r1184, %r4193, %r1179;
	// end inline asm
	ld.const.u32 	%r1188, [matrix+1056];
	// begin inline asm
	dp4a.u32.u32 %r1187, %r1188, %r4197, %r1183;
	// end inline asm
	ld.const.u32 	%r1192, [matrix+1060];
	// begin inline asm
	dp4a.u32.u32 %r1191, %r1192, %r4201, %r1187;
	// end inline asm
	ld.const.u32 	%r1196, [matrix+1064];
	// begin inline asm
	dp4a.u32.u32 %r1195, %r1196, %r4205, %r1191;
	// end inline asm
	ld.const.u32 	%r1200, [matrix+1068];
	// begin inline asm
	dp4a.u32.u32 %r1199, %r1200, %r4209, %r1195;
	// end inline asm
	ld.const.u32 	%r1204, [matrix+1072];
	// begin inline asm
	dp4a.u32.u32 %r1203, %r1204, %r4213, %r1199;
	// end inline asm
	ld.const.u32 	%r1208, [matrix+1076];
	// begin inline asm
	dp4a.u32.u32 %r1207, %r1208, %r4217, %r1203;
	// end inline asm
	ld.const.u32 	%r1212, [matrix+1080];
	// begin inline asm
	dp4a.u32.u32 %r1211, %r1212, %r4221, %r1207;
	// end inline asm
	ld.const.u32 	%r1216, [matrix+1084];
	// begin inline asm
	dp4a.u32.u32 %r1215, %r1216, %r4225, %r1211;
	// end inline asm
	ld.const.u32 	%r1220, [matrix+1088];
	// begin inline asm
	dp4a.u32.u32 %r1219, %r1220, %r4165, %r4641;
	// end inline asm
	ld.const.u32 	%r1224, [matrix+1092];
	// begin inline asm
	dp4a.u32.u32 %r1223, %r1224, %r4169, %r1219;
	// end inline asm
	ld.const.u32 	%r1228, [matrix+1096];
	// begin inline asm
	dp4a.u32.u32 %r1227, %r1228, %r4173, %r1223;
	// end inline asm
	ld.const.u32 	%r1232, [matrix+1100];
	// begin inline asm
	dp4a.u32.u32 %r1231, %r1232, %r4177, %r1227;
	// end inline asm
	ld.const.u32 	%r1236, [matrix+1104];
	// begin inline asm
	dp4a.u32.u32 %r1235, %r1236, %r4181, %r1231;
	// end inline asm
	ld.const.u32 	%r1240, [matrix+1108];
	// begin inline asm
	dp4a.u32.u32 %r1239, %r1240, %r4185, %r1235;
	// end inline asm
	ld.const.u32 	%r1244, [matrix+1112];
	// begin inline asm
	dp4a.u32.u32 %r1243, %r1244, %r4189, %r1239;
	// end inline asm
	ld.const.u32 	%r1248, [matrix+1116];
	// begin inline asm
	dp4a.u32.u32 %r1247, %r1248, %r4193, %r1243;
	// end inline asm
	ld.const.u32 	%r1252, [matrix+1120];
	// begin inline asm
	dp4a.u32.u32 %r1251, %r1252, %r4197, %r1247;
	// end inline asm
	ld.const.u32 	%r1256, [matrix+1124];
	// begin inline asm
	dp4a.u32.u32 %r1255, %r1256, %r4201, %r1251;
	// end inline asm
	ld.const.u32 	%r1260, [matrix+1128];
	// begin inline asm
	dp4a.u32.u32 %r1259, %r1260, %r4205, %r1255;
	// end inline asm
	ld.const.u32 	%r1264, [matrix+1132];
	// begin inline asm
	dp4a.u32.u32 %r1263, %r1264, %r4209, %r1259;
	// end inline asm
	ld.const.u32 	%r1268, [matrix+1136];
	// begin inline asm
	dp4a.u32.u32 %r1267, %r1268, %r4213, %r1263;
	// end inline asm
	ld.const.u32 	%r1272, [matrix+1140];
	// begin inline asm
	dp4a.u32.u32 %r1271, %r1272, %r4217, %r1267;
	// end inline asm
	ld.const.u32 	%r1276, [matrix+1144];
	// begin inline asm
	dp4a.u32.u32 %r1275, %r1276, %r4221, %r1271;
	// end inline asm
	ld.const.u32 	%r1280, [matrix+1148];
	// begin inline asm
	dp4a.u32.u32 %r1279, %r1280, %r4225, %r1275;
	// end inline asm
	shr.u32 	%r4428, %r1215, 6;
	and.b32  	%r4429, %r4428, 240;
	shr.u32 	%r4430, %r1279, 10;
	or.b32  	%r4431, %r4430, %r4429;
	cvt.u64.u32 	%rd389, %r4431;
	xor.b64  	%rd390, %rd678, %rd389;
	ld.const.u32 	%r1284, [matrix+1152];
	// begin inline asm
	dp4a.u32.u32 %r1283, %r1284, %r4165, %r4641;
	// end inline asm
	ld.const.u32 	%r1288, [matrix+1156];
	// begin inline asm
	dp4a.u32.u32 %r1287, %r1288, %r4169, %r1283;
	// end inline asm
	ld.const.u32 	%r1292, [matrix+1160];
	// begin inline asm
	dp4a.u32.u32 %r1291, %r1292, %r4173, %r1287;
	// end inline asm
	ld.const.u32 	%r1296, [matrix+1164];
	// begin inline asm
	dp4a.u32.u32 %r1295, %r1296, %r4177, %r1291;
	// end inline asm
	ld.const.u32 	%r1300, [matrix+1168];
	// begin inline asm
	dp4a.u32.u32 %r1299, %r1300, %r4181, %r1295;
	// end inline asm
	ld.const.u32 	%r1304, [matrix+1172];
	// begin inline asm
	dp4a.u32.u32 %r1303, %r1304, %r4185, %r1299;
	// end inline asm
	ld.const.u32 	%r1308, [matrix+1176];
	// begin inline asm
	dp4a.u32.u32 %r1307, %r1308, %r4189, %r1303;
	// end inline asm
	ld.const.u32 	%r1312, [matrix+1180];
	// begin inline asm
	dp4a.u32.u32 %r1311, %r1312, %r4193, %r1307;
	// end inline asm
	ld.const.u32 	%r1316, [matrix+1184];
	// begin inline asm
	dp4a.u32.u32 %r1315, %r1316, %r4197, %r1311;
	// end inline asm
	ld.const.u32 	%r1320, [matrix+1188];
	// begin inline asm
	dp4a.u32.u32 %r1319, %r1320, %r4201, %r1315;
	// end inline asm
	ld.const.u32 	%r1324, [matrix+1192];
	// begin inline asm
	dp4a.u32.u32 %r1323, %r1324, %r4205, %r1319;
	// end inline asm
	ld.const.u32 	%r1328, [matrix+1196];
	// begin inline asm
	dp4a.u32.u32 %r1327, %r1328, %r4209, %r1323;
	// end inline asm
	ld.const.u32 	%r1332, [matrix+1200];
	// begin inline asm
	dp4a.u32.u32 %r1331, %r1332, %r4213, %r1327;
	// end inline asm
	ld.const.u32 	%r1336, [matrix+1204];
	// begin inline asm
	dp4a.u32.u32 %r1335, %r1336, %r4217, %r1331;
	// end inline asm
	ld.const.u32 	%r1340, [matrix+1208];
	// begin inline asm
	dp4a.u32.u32 %r1339, %r1340, %r4221, %r1335;
	// end inline asm
	ld.const.u32 	%r1344, [matrix+1212];
	// begin inline asm
	dp4a.u32.u32 %r1343, %r1344, %r4225, %r1339;
	// end inline asm
	ld.const.u32 	%r1348, [matrix+1216];
	// begin inline asm
	dp4a.u32.u32 %r1347, %r1348, %r4165, %r4641;
	// end inline asm
	ld.const.u32 	%r1352, [matrix+1220];
	// begin inline asm
	dp4a.u32.u32 %r1351, %r1352, %r4169, %r1347;
	// end inline asm
	ld.const.u32 	%r1356, [matrix+1224];
	// begin inline asm
	dp4a.u32.u32 %r1355, %r1356, %r4173, %r1351;
	// end inline asm
	ld.const.u32 	%r1360, [matrix+1228];
	// begin inline asm
	dp4a.u32.u32 %r1359, %r1360, %r4177, %r1355;
	// end inline asm
	ld.const.u32 	%r1364, [matrix+1232];
	// begin inline asm
	dp4a.u32.u32 %r1363, %r1364, %r4181, %r1359;
	// end inline asm
	ld.const.u32 	%r1368, [matrix+1236];
	// begin inline asm
	dp4a.u32.u32 %r1367, %r1368, %r4185, %r1363;
	// end inline asm
	ld.const.u32 	%r1372, [matrix+1240];
	// begin inline asm
	dp4a.u32.u32 %r1371, %r1372, %r4189, %r1367;
	// end inline asm
	ld.const.u32 	%r1376, [matrix+1244];
	// begin inline asm
	dp4a.u32.u32 %r1375, %r1376, %r4193, %r1371;
	// end inline asm
	ld.const.u32 	%r1380, [matrix+1248];
	// begin inline asm
	dp4a.u32.u32 %r1379, %r1380, %r4197, %r1375;
	// end inline asm
	ld.const.u32 	%r1384, [matrix+1252];
	// begin inline asm
	dp4a.u32.u32 %r1383, %r1384, %r4201, %r1379;
	// end inline asm
	ld.const.u32 	%r1388, [matrix+1256];
	// begin inline asm
	dp4a.u32.u32 %r1387, %r1388, %r4205, %r1383;
	// end inline asm
	ld.const.u32 	%r1392, [matrix+1260];
	// begin inline asm
	dp4a.u32.u32 %r1391, %r1392, %r4209, %r1387;
	// end inline asm
	ld.const.u32 	%r1396, [matrix+1264];
	// begin inline asm
	dp4a.u32.u32 %r1395, %r1396, %r4213, %r1391;
	// end inline asm
	ld.const.u32 	%r1400, [matrix+1268];
	// begin inline asm
	dp4a.u32.u32 %r1399, %r1400, %r4217, %r1395;
	// end inline asm
	ld.const.u32 	%r1404, [matrix+1272];
	// begin inline asm
	dp4a.u32.u32 %r1403, %r1404, %r4221, %r1399;
	// end inline asm
	ld.const.u32 	%r1408, [matrix+1276];
	// begin inline asm
	dp4a.u32.u32 %r1407, %r1408, %r4225, %r1403;
	// end inline asm
	shr.u32 	%r4432, %r1343, 6;
	and.b32  	%r4433, %r4432, 240;
	shr.u32 	%r4434, %r1407, 10;
	or.b32  	%r4435, %r4434, %r4433;
	cvt.u64.u32 	%rd391, %r4435;
	xor.b64  	%rd392, %rd341, %rd391;
	ld.const.u32 	%r1412, [matrix+1280];
	// begin inline asm
	dp4a.u32.u32 %r1411, %r1412, %r4165, %r4641;
	// end inline asm
	ld.const.u32 	%r1416, [matrix+1284];
	// begin inline asm
	dp4a.u32.u32 %r1415, %r1416, %r4169, %r1411;
	// end inline asm
	ld.const.u32 	%r1420, [matrix+1288];
	// begin inline asm
	dp4a.u32.u32 %r1419, %r1420, %r4173, %r1415;
	// end inline asm
	ld.const.u32 	%r1424, [matrix+1292];
	// begin inline asm
	dp4a.u32.u32 %r1423, %r1424, %r4177, %r1419;
	// end inline asm
	ld.const.u32 	%r1428, [matrix+1296];
	// begin inline asm
	dp4a.u32.u32 %r1427, %r1428, %r4181, %r1423;
	// end inline asm
	ld.const.u32 	%r1432, [matrix+1300];
	// begin inline asm
	dp4a.u32.u32 %r1431, %r1432, %r4185, %r1427;
	// end inline asm
	ld.const.u32 	%r1436, [matrix+1304];
	// begin inline asm
	dp4a.u32.u32 %r1435, %r1436, %r4189, %r1431;
	// end inline asm
	ld.const.u32 	%r1440, [matrix+1308];
	// begin inline asm
	dp4a.u32.u32 %r1439, %r1440, %r4193, %r1435;
	// end inline asm
	ld.const.u32 	%r1444, [matrix+1312];
	// begin inline asm
	dp4a.u32.u32 %r1443, %r1444, %r4197, %r1439;
	// end inline asm
	ld.const.u32 	%r1448, [matrix+1316];
	// begin inline asm
	dp4a.u32.u32 %r1447, %r1448, %r4201, %r1443;
	// end inline asm
	ld.const.u32 	%r1452, [matrix+1320];
	// begin inline asm
	dp4a.u32.u32 %r1451, %r1452, %r4205, %r1447;
	// end inline asm
	ld.const.u32 	%r1456, [matrix+1324];
	// begin inline asm
	dp4a.u32.u32 %r1455, %r1456, %r4209, %r1451;
	// end inline asm
	ld.const.u32 	%r1460, [matrix+1328];
	// begin inline asm
	dp4a.u32.u32 %r1459, %r1460, %r4213, %r1455;
	// end inline asm
	ld.const.u32 	%r1464, [matrix+1332];
	// begin inline asm
	dp4a.u32.u32 %r1463, %r1464, %r4217, %r1459;
	// end inline asm
	ld.const.u32 	%r1468, [matrix+1336];
	// begin inline asm
	dp4a.u32.u32 %r1467, %r1468, %r4221, %r1463;
	// end inline asm
	ld.const.u32 	%r1472, [matrix+1340];
	// begin inline asm
	dp4a.u32.u32 %r1471, %r1472, %r4225, %r1467;
	// end inline asm
	ld.const.u32 	%r1476, [matrix+1344];
	// begin inline asm
	dp4a.u32.u32 %r1475, %r1476, %r4165, %r4641;
	// end inline asm
	ld.const.u32 	%r1480, [matrix+1348];
	// begin inline asm
	dp4a.u32.u32 %r1479, %r1480, %r4169, %r1475;
	// end inline asm
	ld.const.u32 	%r1484, [matrix+1352];
	// begin inline asm
	dp4a.u32.u32 %r1483, %r1484, %r4173, %r1479;
	// end inline asm
	ld.const.u32 	%r1488, [matrix+1356];
	// begin inline asm
	dp4a.u32.u32 %r1487, %r1488, %r4177, %r1483;
	// end inline asm
	ld.const.u32 	%r1492, [matrix+1360];
	// begin inline asm
	dp4a.u32.u32 %r1491, %r1492, %r4181, %r1487;
	// end inline asm
	ld.const.u32 	%r1496, [matrix+1364];
	// begin inline asm
	dp4a.u32.u32 %r1495, %r1496, %r4185, %r1491;
	// end inline asm
	ld.const.u32 	%r1500, [matrix+1368];
	// begin inline asm
	dp4a.u32.u32 %r1499, %r1500, %r4189, %r1495;
	// end inline asm
	ld.const.u32 	%r1504, [matrix+1372];
	// begin inline asm
	dp4a.u32.u32 %r1503, %r1504, %r4193, %r1499;
	// end inline asm
	ld.const.u32 	%r1508, [matrix+1376];
	// begin inline asm
	dp4a.u32.u32 %r1507, %r1508, %r4197, %r1503;
	// end inline asm
	ld.const.u32 	%r1512, [matrix+1380];
	// begin inline asm
	dp4a.u32.u32 %r1511, %r1512, %r4201, %r1507;
	// end inline asm
	ld.const.u32 	%r1516, [matrix+1384];
	// begin inline asm
	dp4a.u32.u32 %r1515, %r1516, %r4205, %r1511;
	// end inline asm
	ld.const.u32 	%r1520, [matrix+1388];
	// begin inline asm
	dp4a.u32.u32 %r1519, %r1520, %r4209, %r1515;
	// end inline asm
	ld.const.u32 	%r1524, [matrix+1392];
	// begin inline asm
	dp4a.u32.u32 %r1523, %r1524, %r4213, %r1519;
	// end inline asm
	ld.const.u32 	%r1528, [matrix+1396];
	// begin inline asm
	dp4a.u32.u32 %r1527, %r1528, %r4217, %r1523;
	// end inline asm
	ld.const.u32 	%r1532, [matrix+1400];
	// begin inline asm
	dp4a.u32.u32 %r1531, %r1532, %r4221, %r1527;
	// end inline asm
	ld.const.u32 	%r1536, [matrix+1404];
	// begin inline asm
	dp4a.u32.u32 %r1535, %r1536, %r4225, %r1531;
	// end inline asm
	shr.u32 	%r4436, %r1471, 6;
	and.b32  	%r4437, %r4436, 240;
	shr.u32 	%r4438, %r1535, 10;
	or.b32  	%r4439, %r4438, %r4437;
	cvt.u64.u32 	%rd393, %r4439;
	xor.b64  	%rd394, %rd342, %rd393;
	ld.const.u32 	%r1540, [matrix+1408];
	// begin inline asm
	dp4a.u32.u32 %r1539, %r1540, %r4165, %r4641;
	// end inline asm
	ld.const.u32 	%r1544, [matrix+1412];
	// begin inline asm
	dp4a.u32.u32 %r1543, %r1544, %r4169, %r1539;
	// end inline asm
	ld.const.u32 	%r1548, [matrix+1416];
	// begin inline asm
	dp4a.u32.u32 %r1547, %r1548, %r4173, %r1543;
	// end inline asm
	ld.const.u32 	%r1552, [matrix+1420];
	// begin inline asm
	dp4a.u32.u32 %r1551, %r1552, %r4177, %r1547;
	// end inline asm
	ld.const.u32 	%r1556, [matrix+1424];
	// begin inline asm
	dp4a.u32.u32 %r1555, %r1556, %r4181, %r1551;
	// end inline asm
	ld.const.u32 	%r1560, [matrix+1428];
	// begin inline asm
	dp4a.u32.u32 %r1559, %r1560, %r4185, %r1555;
	// end inline asm
	ld.const.u32 	%r1564, [matrix+1432];
	// begin inline asm
	dp4a.u32.u32 %r1563, %r1564, %r4189, %r1559;
	// end inline asm
	ld.const.u32 	%r1568, [matrix+1436];
	// begin inline asm
	dp4a.u32.u32 %r1567, %r1568, %r4193, %r1563;
	// end inline asm
	ld.const.u32 	%r1572, [matrix+1440];
	// begin inline asm
	dp4a.u32.u32 %r1571, %r1572, %r4197, %r1567;
	// end inline asm
	ld.const.u32 	%r1576, [matrix+1444];
	// begin inline asm
	dp4a.u32.u32 %r1575, %r1576, %r4201, %r1571;
	// end inline asm
	ld.const.u32 	%r1580, [matrix+1448];
	// begin inline asm
	dp4a.u32.u32 %r1579, %r1580, %r4205, %r1575;
	// end inline asm
	ld.const.u32 	%r1584, [matrix+1452];
	// begin inline asm
	dp4a.u32.u32 %r1583, %r1584, %r4209, %r1579;
	// end inline asm
	ld.const.u32 	%r1588, [matrix+1456];
	// begin inline asm
	dp4a.u32.u32 %r1587, %r1588, %r4213, %r1583;
	// end inline asm
	ld.const.u32 	%r1592, [matrix+1460];
	// begin inline asm
	dp4a.u32.u32 %r1591, %r1592, %r4217, %r1587;
	// end inline asm
	ld.const.u32 	%r1596, [matrix+1464];
	// begin inline asm
	dp4a.u32.u32 %r1595, %r1596, %r4221, %r1591;
	// end inline asm
	ld.const.u32 	%r1600, [matrix+1468];
	// begin inline asm
	dp4a.u32.u32 %r1599, %r1600, %r4225, %r1595;
	// end inline asm
	ld.const.u32 	%r1604, [matrix+1472];
	// begin inline asm
	dp4a.u32.u32 %r1603, %r1604, %r4165, %r4641;
	// end inline asm
	ld.const.u32 	%r1608, [matrix+1476];
	// begin inline asm
	dp4a.u32.u32 %r1607, %r1608, %r4169, %r1603;
	// end inline asm
	ld.const.u32 	%r1612, [matrix+1480];
	// begin inline asm
	dp4a.u32.u32 %r1611, %r1612, %r4173, %r1607;
	// end inline asm
	ld.const.u32 	%r1616, [matrix+1484];
	// begin inline asm
	dp4a.u32.u32 %r1615, %r1616, %r4177, %r1611;
	// end inline asm
	ld.const.u32 	%r1620, [matrix+1488];
	// begin inline asm
	dp4a.u32.u32 %r1619, %r1620, %r4181, %r1615;
	// end inline asm
	ld.const.u32 	%r1624, [matrix+1492];
	// begin inline asm
	dp4a.u32.u32 %r1623, %r1624, %r4185, %r1619;
	// end inline asm
	ld.const.u32 	%r1628, [matrix+1496];
	// begin inline asm
	dp4a.u32.u32 %r1627, %r1628, %r4189, %r1623;
	// end inline asm
	ld.const.u32 	%r1632, [matrix+1500];
	// begin inline asm
	dp4a.u32.u32 %r1631, %r1632, %r4193, %r1627;
	// end inline asm
	ld.const.u32 	%r1636, [matrix+1504];
	// begin inline asm
	dp4a.u32.u32 %r1635, %r1636, %r4197, %r1631;
	// end inline asm
	ld.const.u32 	%r1640, [matrix+1508];
	// begin inline asm
	dp4a.u32.u32 %r1639, %r1640, %r4201, %r1635;
	// end inline asm
	ld.const.u32 	%r1644, [matrix+1512];
	// begin inline asm
	dp4a.u32.u32 %r1643, %r1644, %r4205, %r1639;
	// end inline asm
	ld.const.u32 	%r1648, [matrix+1516];
	// begin inline asm
	dp4a.u32.u32 %r1647, %r1648, %r4209, %r1643;
	// end inline asm
	ld.const.u32 	%r1652, [matrix+1520];
	// begin inline asm
	dp4a.u32.u32 %r1651, %r1652, %r4213, %r1647;
	// end inline asm
	ld.const.u32 	%r1656, [matrix+1524];
	// begin inline asm
	dp4a.u32.u32 %r1655, %r1656, %r4217, %r1651;
	// end inline asm
	ld.const.u32 	%r1660, [matrix+1528];
	// begin inline asm
	dp4a.u32.u32 %r1659, %r1660, %r4221, %r1655;
	// end inline asm
	ld.const.u32 	%r1664, [matrix+1532];
	// begin inline asm
	dp4a.u32.u32 %r1663, %r1664, %r4225, %r1659;
	// end inline asm
	shr.u32 	%r4440, %r1599, 6;
	and.b32  	%r4441, %r4440, 240;
	shr.u32 	%r4442, %r1663, 10;
	or.b32  	%r4443, %r4442, %r4441;
	cvt.u64.u32 	%rd395, %r4443;
	xor.b64  	%rd396, %rd343, %rd395;
	ld.const.u32 	%r1668, [matrix+1536];
	// begin inline asm
	dp4a.u32.u32 %r1667, %r1668, %r4165, %r4641;
	// end inline asm
	ld.const.u32 	%r1672, [matrix+1540];
	// begin inline asm
	dp4a.u32.u32 %r1671, %r1672, %r4169, %r1667;
	// end inline asm
	ld.const.u32 	%r1676, [matrix+1544];
	// begin inline asm
	dp4a.u32.u32 %r1675, %r1676, %r4173, %r1671;
	// end inline asm
	ld.const.u32 	%r1680, [matrix+1548];
	// begin inline asm
	dp4a.u32.u32 %r1679, %r1680, %r4177, %r1675;
	// end inline asm
	ld.const.u32 	%r1684, [matrix+1552];
	// begin inline asm
	dp4a.u32.u32 %r1683, %r1684, %r4181, %r1679;
	// end inline asm
	ld.const.u32 	%r1688, [matrix+1556];
	// begin inline asm
	dp4a.u32.u32 %r1687, %r1688, %r4185, %r1683;
	// end inline asm
	ld.const.u32 	%r1692, [matrix+1560];
	// begin inline asm
	dp4a.u32.u32 %r1691, %r1692, %r4189, %r1687;
	// end inline asm
	ld.const.u32 	%r1696, [matrix+1564];
	// begin inline asm
	dp4a.u32.u32 %r1695, %r1696, %r4193, %r1691;
	// end inline asm
	ld.const.u32 	%r1700, [matrix+1568];
	// begin inline asm
	dp4a.u32.u32 %r1699, %r1700, %r4197, %r1695;
	// end inline asm
	ld.const.u32 	%r1704, [matrix+1572];
	// begin inline asm
	dp4a.u32.u32 %r1703, %r1704, %r4201, %r1699;
	// end inline asm
	ld.const.u32 	%r1708, [matrix+1576];
	// begin inline asm
	dp4a.u32.u32 %r1707, %r1708, %r4205, %r1703;
	// end inline asm
	ld.const.u32 	%r1712, [matrix+1580];
	// begin inline asm
	dp4a.u32.u32 %r1711, %r1712, %r4209, %r1707;
	// end inline asm
	ld.const.u32 	%r1716, [matrix+1584];
	// begin inline asm
	dp4a.u32.u32 %r1715, %r1716, %r4213, %r1711;
	// end inline asm
	ld.const.u32 	%r1720, [matrix+1588];
	// begin inline asm
	dp4a.u32.u32 %r1719, %r1720, %r4217, %r1715;
	// end inline asm
	ld.const.u32 	%r1724, [matrix+1592];
	// begin inline asm
	dp4a.u32.u32 %r1723, %r1724, %r4221, %r1719;
	// end inline asm
	ld.const.u32 	%r1728, [matrix+1596];
	// begin inline asm
	dp4a.u32.u32 %r1727, %r1728, %r4225, %r1723;
	// end inline asm
	ld.const.u32 	%r1732, [matrix+1600];
	// begin inline asm
	dp4a.u32.u32 %r1731, %r1732, %r4165, %r4641;
	// end inline asm
	ld.const.u32 	%r1736, [matrix+1604];
	// begin inline asm
	dp4a.u32.u32 %r1735, %r1736, %r4169, %r1731;
	// end inline asm
	ld.const.u32 	%r1740, [matrix+1608];
	// begin inline asm
	dp4a.u32.u32 %r1739, %r1740, %r4173, %r1735;
	// end inline asm
	ld.const.u32 	%r1744, [matrix+1612];
	// begin inline asm
	dp4a.u32.u32 %r1743, %r1744, %r4177, %r1739;
	// end inline asm
	ld.const.u32 	%r1748, [matrix+1616];
	// begin inline asm
	dp4a.u32.u32 %r1747, %r1748, %r4181, %r1743;
	// end inline asm
	ld.const.u32 	%r1752, [matrix+1620];
	// begin inline asm
	dp4a.u32.u32 %r1751, %r1752, %r4185, %r1747;
	// end inline asm
	ld.const.u32 	%r1756, [matrix+1624];
	// begin inline asm
	dp4a.u32.u32 %r1755, %r1756, %r4189, %r1751;
	// end inline asm
	ld.const.u32 	%r1760, [matrix+1628];
	// begin inline asm
	dp4a.u32.u32 %r1759, %r1760, %r4193, %r1755;
	// end inline asm
	ld.const.u32 	%r1764, [matrix+1632];
	// begin inline asm
	dp4a.u32.u32 %r1763, %r1764, %r4197, %r1759;
	// end inline asm
	ld.const.u32 	%r1768, [matrix+1636];
	// begin inline asm
	dp4a.u32.u32 %r1767, %r1768, %r4201, %r1763;
	// end inline asm
	ld.const.u32 	%r1772, [matrix+1640];
	// begin inline asm
	dp4a.u32.u32 %r1771, %r1772, %r4205, %r1767;
	// end inline asm
	ld.const.u32 	%r1776, [matrix+1644];
	// begin inline asm
	dp4a.u32.u32 %r1775, %r1776, %r4209, %r1771;
	// end inline asm
	ld.const.u32 	%r1780, [matrix+1648];
	// begin inline asm
	dp4a.u32.u32 %r1779, %r1780, %r4213, %r1775;
	// end inline asm
	ld.const.u32 	%r1784, [matrix+1652];
	// begin inline asm
	dp4a.u32.u32 %r1783, %r1784, %r4217, %r1779;
	// end inline asm
	ld.const.u32 	%r1788, [matrix+1656];
	// begin inline asm
	dp4a.u32.u32 %r1787, %r1788, %r4221, %r1783;
	// end inline asm
	ld.const.u32 	%r1792, [matrix+1660];
	// begin inline asm
	dp4a.u32.u32 %r1791, %r1792, %r4225, %r1787;
	// end inline asm
	shr.u32 	%r4444, %r1727, 6;
	and.b32  	%r4445, %r4444, 240;
	shr.u32 	%r4446, %r1791, 10;
	or.b32  	%r4447, %r4446, %r4445;
	cvt.u64.u32 	%rd397, %r4447;
	xor.b64  	%rd398, %rd344, %rd397;
	ld.const.u32 	%r1796, [matrix+1664];
	// begin inline asm
	dp4a.u32.u32 %r1795, %r1796, %r4165, %r4641;
	// end inline asm
	ld.const.u32 	%r1800, [matrix+1668];
	// begin inline asm
	dp4a.u32.u32 %r1799, %r1800, %r4169, %r1795;
	// end inline asm
	ld.const.u32 	%r1804, [matrix+1672];
	// begin inline asm
	dp4a.u32.u32 %r1803, %r1804, %r4173, %r1799;
	// end inline asm
	ld.const.u32 	%r1808, [matrix+1676];
	// begin inline asm
	dp4a.u32.u32 %r1807, %r1808, %r4177, %r1803;
	// end inline asm
	ld.const.u32 	%r1812, [matrix+1680];
	// begin inline asm
	dp4a.u32.u32 %r1811, %r1812, %r4181, %r1807;
	// end inline asm
	ld.const.u32 	%r1816, [matrix+1684];
	// begin inline asm
	dp4a.u32.u32 %r1815, %r1816, %r4185, %r1811;
	// end inline asm
	ld.const.u32 	%r1820, [matrix+1688];
	// begin inline asm
	dp4a.u32.u32 %r1819, %r1820, %r4189, %r1815;
	// end inline asm
	ld.const.u32 	%r1824, [matrix+1692];
	// begin inline asm
	dp4a.u32.u32 %r1823, %r1824, %r4193, %r1819;
	// end inline asm
	ld.const.u32 	%r1828, [matrix+1696];
	// begin inline asm
	dp4a.u32.u32 %r1827, %r1828, %r4197, %r1823;
	// end inline asm
	ld.const.u32 	%r1832, [matrix+1700];
	// begin inline asm
	dp4a.u32.u32 %r1831, %r1832, %r4201, %r1827;
	// end inline asm
	ld.const.u32 	%r1836, [matrix+1704];
	// begin inline asm
	dp4a.u32.u32 %r1835, %r1836, %r4205, %r1831;
	// end inline asm
	ld.const.u32 	%r1840, [matrix+1708];
	// begin inline asm
	dp4a.u32.u32 %r1839, %r1840, %r4209, %r1835;
	// end inline asm
	ld.const.u32 	%r1844, [matrix+1712];
	// begin inline asm
	dp4a.u32.u32 %r1843, %r1844, %r4213, %r1839;
	// end inline asm
	ld.const.u32 	%r1848, [matrix+1716];
	// begin inline asm
	dp4a.u32.u32 %r1847, %r1848, %r4217, %r1843;
	// end inline asm
	ld.const.u32 	%r1852, [matrix+1720];
	// begin inline asm
	dp4a.u32.u32 %r1851, %r1852, %r4221, %r1847;
	// end inline asm
	ld.const.u32 	%r1856, [matrix+1724];
	// begin inline asm
	dp4a.u32.u32 %r1855, %r1856, %r4225, %r1851;
	// end inline asm
	ld.const.u32 	%r1860, [matrix+1728];
	// begin inline asm
	dp4a.u32.u32 %r1859, %r1860, %r4165, %r4641;
	// end inline asm
	ld.const.u32 	%r1864, [matrix+1732];
	// begin inline asm
	dp4a.u32.u32 %r1863, %r1864, %r4169, %r1859;
	// end inline asm
	ld.const.u32 	%r1868, [matrix+1736];
	// begin inline asm
	dp4a.u32.u32 %r1867, %r1868, %r4173, %r1863;
	// end inline asm
	ld.const.u32 	%r1872, [matrix+1740];
	// begin inline asm
	dp4a.u32.u32 %r1871, %r1872, %r4177, %r1867;
	// end inline asm
	ld.const.u32 	%r1876, [matrix+1744];
	// begin inline asm
	dp4a.u32.u32 %r1875, %r1876, %r4181, %r1871;
	// end inline asm
	ld.const.u32 	%r1880, [matrix+1748];
	// begin inline asm
	dp4a.u32.u32 %r1879, %r1880, %r4185, %r1875;
	// end inline asm
	ld.const.u32 	%r1884, [matrix+1752];
	// begin inline asm
	dp4a.u32.u32 %r1883, %r1884, %r4189, %r1879;
	// end inline asm
	ld.const.u32 	%r1888, [matrix+1756];
	// begin inline asm
	dp4a.u32.u32 %r1887, %r1888, %r4193, %r1883;
	// end inline asm
	ld.const.u32 	%r1892, [matrix+1760];
	// begin inline asm
	dp4a.u32.u32 %r1891, %r1892, %r4197, %r1887;
	// end inline asm
	ld.const.u32 	%r1896, [matrix+1764];
	// begin inline asm
	dp4a.u32.u32 %r1895, %r1896, %r4201, %r1891;
	// end inline asm
	ld.const.u32 	%r1900, [matrix+1768];
	// begin inline asm
	dp4a.u32.u32 %r1899, %r1900, %r4205, %r1895;
	// end inline asm
	ld.const.u32 	%r1904, [matrix+1772];
	// begin inline asm
	dp4a.u32.u32 %r1903, %r1904, %r4209, %r1899;
	// end inline asm
	ld.const.u32 	%r1908, [matrix+1776];
	// begin inline asm
	dp4a.u32.u32 %r1907, %r1908, %r4213, %r1903;
	// end inline asm
	ld.const.u32 	%r1912, [matrix+1780];
	// begin inline asm
	dp4a.u32.u32 %r1911, %r1912, %r4217, %r1907;
	// end inline asm
	ld.const.u32 	%r1916, [matrix+1784];
	// begin inline asm
	dp4a.u32.u32 %r1915, %r1916, %r4221, %r1911;
	// end inline asm
	ld.const.u32 	%r1920, [matrix+1788];
	// begin inline asm
	dp4a.u32.u32 %r1919, %r1920, %r4225, %r1915;
	// end inline asm
	shr.u32 	%r4448, %r1855, 6;
	and.b32  	%r4449, %r4448, 240;
	shr.u32 	%r4450, %r1919, 10;
	or.b32  	%r4451, %r4450, %r4449;
	cvt.u64.u32 	%rd399, %r4451;
	xor.b64  	%rd400, %rd345, %rd399;
	ld.const.u32 	%r1924, [matrix+1792];
	// begin inline asm
	dp4a.u32.u32 %r1923, %r1924, %r4165, %r4641;
	// end inline asm
	ld.const.u32 	%r1928, [matrix+1796];
	// begin inline asm
	dp4a.u32.u32 %r1927, %r1928, %r4169, %r1923;
	// end inline asm
	ld.const.u32 	%r1932, [matrix+1800];
	// begin inline asm
	dp4a.u32.u32 %r1931, %r1932, %r4173, %r1927;
	// end inline asm
	ld.const.u32 	%r1936, [matrix+1804];
	// begin inline asm
	dp4a.u32.u32 %r1935, %r1936, %r4177, %r1931;
	// end inline asm
	ld.const.u32 	%r1940, [matrix+1808];
	// begin inline asm
	dp4a.u32.u32 %r1939, %r1940, %r4181, %r1935;
	// end inline asm
	ld.const.u32 	%r1944, [matrix+1812];
	// begin inline asm
	dp4a.u32.u32 %r1943, %r1944, %r4185, %r1939;
	// end inline asm
	ld.const.u32 	%r1948, [matrix+1816];
	// begin inline asm
	dp4a.u32.u32 %r1947, %r1948, %r4189, %r1943;
	// end inline asm
	ld.const.u32 	%r1952, [matrix+1820];
	// begin inline asm
	dp4a.u32.u32 %r1951, %r1952, %r4193, %r1947;
	// end inline asm
	ld.const.u32 	%r1956, [matrix+1824];
	// begin inline asm
	dp4a.u32.u32 %r1955, %r1956, %r4197, %r1951;
	// end inline asm
	ld.const.u32 	%r1960, [matrix+1828];
	// begin inline asm
	dp4a.u32.u32 %r1959, %r1960, %r4201, %r1955;
	// end inline asm
	ld.const.u32 	%r1964, [matrix+1832];
	// begin inline asm
	dp4a.u32.u32 %r1963, %r1964, %r4205, %r1959;
	// end inline asm
	ld.const.u32 	%r1968, [matrix+1836];
	// begin inline asm
	dp4a.u32.u32 %r1967, %r1968, %r4209, %r1963;
	// end inline asm
	ld.const.u32 	%r1972, [matrix+1840];
	// begin inline asm
	dp4a.u32.u32 %r1971, %r1972, %r4213, %r1967;
	// end inline asm
	ld.const.u32 	%r1976, [matrix+1844];
	// begin inline asm
	dp4a.u32.u32 %r1975, %r1976, %r4217, %r1971;
	// end inline asm
	ld.const.u32 	%r1980, [matrix+1848];
	// begin inline asm
	dp4a.u32.u32 %r1979, %r1980, %r4221, %r1975;
	// end inline asm
	ld.const.u32 	%r1984, [matrix+1852];
	// begin inline asm
	dp4a.u32.u32 %r1983, %r1984, %r4225, %r1979;
	// end inline asm
	ld.const.u32 	%r1988, [matrix+1856];
	// begin inline asm
	dp4a.u32.u32 %r1987, %r1988, %r4165, %r4641;
	// end inline asm
	ld.const.u32 	%r1992, [matrix+1860];
	// begin inline asm
	dp4a.u32.u32 %r1991, %r1992, %r4169, %r1987;
	// end inline asm
	ld.const.u32 	%r1996, [matrix+1864];
	// begin inline asm
	dp4a.u32.u32 %r1995, %r1996, %r4173, %r1991;
	// end inline asm
	ld.const.u32 	%r2000, [matrix+1868];
	// begin inline asm
	dp4a.u32.u32 %r1999, %r2000, %r4177, %r1995;
	// end inline asm
	ld.const.u32 	%r2004, [matrix+1872];
	// begin inline asm
	dp4a.u32.u32 %r2003, %r2004, %r4181, %r1999;
	// end inline asm
	ld.const.u32 	%r2008, [matrix+1876];
	// begin inline asm
	dp4a.u32.u32 %r2007, %r2008, %r4185, %r2003;
	// end inline asm
	ld.const.u32 	%r2012, [matrix+1880];
	// begin inline asm
	dp4a.u32.u32 %r2011, %r2012, %r4189, %r2007;
	// end inline asm
	ld.const.u32 	%r2016, [matrix+1884];
	// begin inline asm
	dp4a.u32.u32 %r2015, %r2016, %r4193, %r2011;
	// end inline asm
	ld.const.u32 	%r2020, [matrix+1888];
	// begin inline asm
	dp4a.u32.u32 %r2019, %r2020, %r4197, %r2015;
	// end inline asm
	ld.const.u32 	%r2024, [matrix+1892];
	// begin inline asm
	dp4a.u32.u32 %r2023, %r2024, %r4201, %r2019;
	// end inline asm
	ld.const.u32 	%r2028, [matrix+1896];
	// begin inline asm
	dp4a.u32.u32 %r2027, %r2028, %r4205, %r2023;
	// end inline asm
	ld.const.u32 	%r2032, [matrix+1900];
	// begin inline asm
	dp4a.u32.u32 %r2031, %r2032, %r4209, %r2027;
	// end inline asm
	ld.const.u32 	%r2036, [matrix+1904];
	// begin inline asm
	dp4a.u32.u32 %r2035, %r2036, %r4213, %r2031;
	// end inline asm
	ld.const.u32 	%r2040, [matrix+1908];
	// begin inline asm
	dp4a.u32.u32 %r2039, %r2040, %r4217, %r2035;
	// end inline asm
	ld.const.u32 	%r2044, [matrix+1912];
	// begin inline asm
	dp4a.u32.u32 %r2043, %r2044, %r4221, %r2039;
	// end inline asm
	ld.const.u32 	%r2048, [matrix+1916];
	// begin inline asm
	dp4a.u32.u32 %r2047, %r2048, %r4225, %r2043;
	// end inline asm
	shr.u32 	%r4452, %r1983, 6;
	and.b32  	%r4453, %r4452, 240;
	shr.u32 	%r4454, %r2047, 10;
	or.b32  	%r4455, %r4454, %r4453;
	cvt.u64.u32 	%rd401, %r4455;
	xor.b64  	%rd402, %rd346, %rd401;
	ld.const.u32 	%r2052, [matrix+1920];
	// begin inline asm
	dp4a.u32.u32 %r2051, %r2052, %r4165, %r4641;
	// end inline asm
	ld.const.u32 	%r2056, [matrix+1924];
	// begin inline asm
	dp4a.u32.u32 %r2055, %r2056, %r4169, %r2051;
	// end inline asm
	ld.const.u32 	%r2060, [matrix+1928];
	// begin inline asm
	dp4a.u32.u32 %r2059, %r2060, %r4173, %r2055;
	// end inline asm
	ld.const.u32 	%r2064, [matrix+1932];
	// begin inline asm
	dp4a.u32.u32 %r2063, %r2064, %r4177, %r2059;
	// end inline asm
	ld.const.u32 	%r2068, [matrix+1936];
	// begin inline asm
	dp4a.u32.u32 %r2067, %r2068, %r4181, %r2063;
	// end inline asm
	ld.const.u32 	%r2072, [matrix+1940];
	// begin inline asm
	dp4a.u32.u32 %r2071, %r2072, %r4185, %r2067;
	// end inline asm
	ld.const.u32 	%r2076, [matrix+1944];
	// begin inline asm
	dp4a.u32.u32 %r2075, %r2076, %r4189, %r2071;
	// end inline asm
	ld.const.u32 	%r2080, [matrix+1948];
	// begin inline asm
	dp4a.u32.u32 %r2079, %r2080, %r4193, %r2075;
	// end inline asm
	ld.const.u32 	%r2084, [matrix+1952];
	// begin inline asm
	dp4a.u32.u32 %r2083, %r2084, %r4197, %r2079;
	// end inline asm
	ld.const.u32 	%r2088, [matrix+1956];
	// begin inline asm
	dp4a.u32.u32 %r2087, %r2088, %r4201, %r2083;
	// end inline asm
	ld.const.u32 	%r2092, [matrix+1960];
	// begin inline asm
	dp4a.u32.u32 %r2091, %r2092, %r4205, %r2087;
	// end inline asm
	ld.const.u32 	%r2096, [matrix+1964];
	// begin inline asm
	dp4a.u32.u32 %r2095, %r2096, %r4209, %r2091;
	// end inline asm
	ld.const.u32 	%r2100, [matrix+1968];
	// begin inline asm
	dp4a.u32.u32 %r2099, %r2100, %r4213, %r2095;
	// end inline asm
	ld.const.u32 	%r2104, [matrix+1972];
	// begin inline asm
	dp4a.u32.u32 %r2103, %r2104, %r4217, %r2099;
	// end inline asm
	ld.const.u32 	%r2108, [matrix+1976];
	// begin inline asm
	dp4a.u32.u32 %r2107, %r2108, %r4221, %r2103;
	// end inline asm
	ld.const.u32 	%r2112, [matrix+1980];
	// begin inline asm
	dp4a.u32.u32 %r2111, %r2112, %r4225, %r2107;
	// end inline asm
	ld.const.u32 	%r2116, [matrix+1984];
	// begin inline asm
	dp4a.u32.u32 %r2115, %r2116, %r4165, %r4641;
	// end inline asm
	ld.const.u32 	%r2120, [matrix+1988];
	// begin inline asm
	dp4a.u32.u32 %r2119, %r2120, %r4169, %r2115;
	// end inline asm
	ld.const.u32 	%r2124, [matrix+1992];
	// begin inline asm
	dp4a.u32.u32 %r2123, %r2124, %r4173, %r2119;
	// end inline asm
	ld.const.u32 	%r2128, [matrix+1996];
	// begin inline asm
	dp4a.u32.u32 %r2127, %r2128, %r4177, %r2123;
	// end inline asm
	ld.const.u32 	%r2132, [matrix+2000];
	// begin inline asm
	dp4a.u32.u32 %r2131, %r2132, %r4181, %r2127;
	// end inline asm
	ld.const.u32 	%r2136, [matrix+2004];
	// begin inline asm
	dp4a.u32.u32 %r2135, %r2136, %r4185, %r2131;
	// end inline asm
	ld.const.u32 	%r2140, [matrix+2008];
	// begin inline asm
	dp4a.u32.u32 %r2139, %r2140, %r4189, %r2135;
	// end inline asm
	ld.const.u32 	%r2144, [matrix+2012];
	// begin inline asm
	dp4a.u32.u32 %r2143, %r2144, %r4193, %r2139;
	// end inline asm
	ld.const.u32 	%r2148, [matrix+2016];
	// begin inline asm
	dp4a.u32.u32 %r2147, %r2148, %r4197, %r2143;
	// end inline asm
	ld.const.u32 	%r2152, [matrix+2020];
	// begin inline asm
	dp4a.u32.u32 %r2151, %r2152, %r4201, %r2147;
	// end inline asm
	ld.const.u32 	%r2156, [matrix+2024];
	// begin inline asm
	dp4a.u32.u32 %r2155, %r2156, %r4205, %r2151;
	// end inline asm
	ld.const.u32 	%r2160, [matrix+2028];
	// begin inline asm
	dp4a.u32.u32 %r2159, %r2160, %r4209, %r2155;
	// end inline asm
	ld.const.u32 	%r2164, [matrix+2032];
	// begin inline asm
	dp4a.u32.u32 %r2163, %r2164, %r4213, %r2159;
	// end inline asm
	ld.const.u32 	%r2168, [matrix+2036];
	// begin inline asm
	dp4a.u32.u32 %r2167, %r2168, %r4217, %r2163;
	// end inline asm
	ld.const.u32 	%r2172, [matrix+2040];
	// begin inline asm
	dp4a.u32.u32 %r2171, %r2172, %r4221, %r2167;
	// end inline asm
	ld.const.u32 	%r2176, [matrix+2044];
	// begin inline asm
	dp4a.u32.u32 %r2175, %r2176, %r4225, %r2171;
	// end inline asm
	shr.u32 	%r4456, %r2111, 6;
	and.b32  	%r4457, %r4456, 240;
	shr.u32 	%r4458, %r2175, 10;
	or.b32  	%r4459, %r4458, %r4457;
	cvt.u64.u32 	%rd403, %r4459;
	ld.const.u32 	%r2180, [matrix+2048];
	// begin inline asm
	dp4a.u32.u32 %r2179, %r2180, %r4165, %r4641;
	// end inline asm
	ld.const.u32 	%r2184, [matrix+2052];
	// begin inline asm
	dp4a.u32.u32 %r2183, %r2184, %r4169, %r2179;
	// end inline asm
	ld.const.u32 	%r2188, [matrix+2056];
	// begin inline asm
	dp4a.u32.u32 %r2187, %r2188, %r4173, %r2183;
	// end inline asm
	ld.const.u32 	%r2192, [matrix+2060];
	// begin inline asm
	dp4a.u32.u32 %r2191, %r2192, %r4177, %r2187;
	// end inline asm
	ld.const.u32 	%r2196, [matrix+2064];
	// begin inline asm
	dp4a.u32.u32 %r2195, %r2196, %r4181, %r2191;
	// end inline asm
	ld.const.u32 	%r2200, [matrix+2068];
	// begin inline asm
	dp4a.u32.u32 %r2199, %r2200, %r4185, %r2195;
	// end inline asm
	ld.const.u32 	%r2204, [matrix+2072];
	// begin inline asm
	dp4a.u32.u32 %r2203, %r2204, %r4189, %r2199;
	// end inline asm
	ld.const.u32 	%r2208, [matrix+2076];
	// begin inline asm
	dp4a.u32.u32 %r2207, %r2208, %r4193, %r2203;
	// end inline asm
	ld.const.u32 	%r2212, [matrix+2080];
	// begin inline asm
	dp4a.u32.u32 %r2211, %r2212, %r4197, %r2207;
	// end inline asm
	ld.const.u32 	%r2216, [matrix+2084];
	// begin inline asm
	dp4a.u32.u32 %r2215, %r2216, %r4201, %r2211;
	// end inline asm
	ld.const.u32 	%r2220, [matrix+2088];
	// begin inline asm
	dp4a.u32.u32 %r2219, %r2220, %r4205, %r2215;
	// end inline asm
	ld.const.u32 	%r2224, [matrix+2092];
	// begin inline asm
	dp4a.u32.u32 %r2223, %r2224, %r4209, %r2219;
	// end inline asm
	ld.const.u32 	%r2228, [matrix+2096];
	// begin inline asm
	dp4a.u32.u32 %r2227, %r2228, %r4213, %r2223;
	// end inline asm
	ld.const.u32 	%r2232, [matrix+2100];
	// begin inline asm
	dp4a.u32.u32 %r2231, %r2232, %r4217, %r2227;
	// end inline asm
	ld.const.u32 	%r2236, [matrix+2104];
	// begin inline asm
	dp4a.u32.u32 %r2235, %r2236, %r4221, %r2231;
	// end inline asm
	ld.const.u32 	%r2240, [matrix+2108];
	// begin inline asm
	dp4a.u32.u32 %r2239, %r2240, %r4225, %r2235;
	// end inline asm
	ld.const.u32 	%r2244, [matrix+2112];
	// begin inline asm
	dp4a.u32.u32 %r2243, %r2244, %r4165, %r4641;
	// end inline asm
	ld.const.u32 	%r2248, [matrix+2116];
	// begin inline asm
	dp4a.u32.u32 %r2247, %r2248, %r4169, %r2243;
	// end inline asm
	ld.const.u32 	%r2252, [matrix+2120];
	// begin inline asm
	dp4a.u32.u32 %r2251, %r2252, %r4173, %r2247;
	// end inline asm
	ld.const.u32 	%r2256, [matrix+2124];
	// begin inline asm
	dp4a.u32.u32 %r2255, %r2256, %r4177, %r2251;
	// end inline asm
	ld.const.u32 	%r2260, [matrix+2128];
	// begin inline asm
	dp4a.u32.u32 %r2259, %r2260, %r4181, %r2255;
	// end inline asm
	ld.const.u32 	%r2264, [matrix+2132];
	// begin inline asm
	dp4a.u32.u32 %r2263, %r2264, %r4185, %r2259;
	// end inline asm
	ld.const.u32 	%r2268, [matrix+2136];
	// begin inline asm
	dp4a.u32.u32 %r2267, %r2268, %r4189, %r2263;
	// end inline asm
	ld.const.u32 	%r2272, [matrix+2140];
	// begin inline asm
	dp4a.u32.u32 %r2271, %r2272, %r4193, %r2267;
	// end inline asm
	ld.const.u32 	%r2276, [matrix+2144];
	// begin inline asm
	dp4a.u32.u32 %r2275, %r2276, %r4197, %r2271;
	// end inline asm
	ld.const.u32 	%r2280, [matrix+2148];
	// begin inline asm
	dp4a.u32.u32 %r2279, %r2280, %r4201, %r2275;
	// end inline asm
	ld.const.u32 	%r2284, [matrix+2152];
	// begin inline asm
	dp4a.u32.u32 %r2283, %r2284, %r4205, %r2279;
	// end inline asm
	ld.const.u32 	%r2288, [matrix+2156];
	// begin inline asm
	dp4a.u32.u32 %r2287, %r2288, %r4209, %r2283;
	// end inline asm
	ld.const.u32 	%r2292, [matrix+2160];
	// begin inline asm
	dp4a.u32.u32 %r2291, %r2292, %r4213, %r2287;
	// end inline asm
	ld.const.u32 	%r2296, [matrix+2164];
	// begin inline asm
	dp4a.u32.u32 %r2295, %r2296, %r4217, %r2291;
	// end inline asm
	ld.const.u32 	%r2300, [matrix+2168];
	// begin inline asm
	dp4a.u32.u32 %r2299, %r2300, %r4221, %r2295;
	// end inline asm
	ld.const.u32 	%r2304, [matrix+2172];
	// begin inline asm
	dp4a.u32.u32 %r2303, %r2304, %r4225, %r2299;
	// end inline asm
	shr.u32 	%r4460, %r2239, 6;
	and.b32  	%r4461, %r4460, 240;
	shr.u32 	%r4462, %r2303, 10;
	or.b32  	%r4463, %r4462, %r4461;
	cvt.u64.u32 	%rd404, %r4463;
	xor.b64  	%rd405, %rd673, %rd404;
	ld.const.u32 	%r2308, [matrix+2176];
	// begin inline asm
	dp4a.u32.u32 %r2307, %r2308, %r4165, %r4641;
	// end inline asm
	ld.const.u32 	%r2312, [matrix+2180];
	// begin inline asm
	dp4a.u32.u32 %r2311, %r2312, %r4169, %r2307;
	// end inline asm
	ld.const.u32 	%r2316, [matrix+2184];
	// begin inline asm
	dp4a.u32.u32 %r2315, %r2316, %r4173, %r2311;
	// end inline asm
	ld.const.u32 	%r2320, [matrix+2188];
	// begin inline asm
	dp4a.u32.u32 %r2319, %r2320, %r4177, %r2315;
	// end inline asm
	ld.const.u32 	%r2324, [matrix+2192];
	// begin inline asm
	dp4a.u32.u32 %r2323, %r2324, %r4181, %r2319;
	// end inline asm
	ld.const.u32 	%r2328, [matrix+2196];
	// begin inline asm
	dp4a.u32.u32 %r2327, %r2328, %r4185, %r2323;
	// end inline asm
	ld.const.u32 	%r2332, [matrix+2200];
	// begin inline asm
	dp4a.u32.u32 %r2331, %r2332, %r4189, %r2327;
	// end inline asm
	ld.const.u32 	%r2336, [matrix+2204];
	// begin inline asm
	dp4a.u32.u32 %r2335, %r2336, %r4193, %r2331;
	// end inline asm
	ld.const.u32 	%r2340, [matrix+2208];
	// begin inline asm
	dp4a.u32.u32 %r2339, %r2340, %r4197, %r2335;
	// end inline asm
	ld.const.u32 	%r2344, [matrix+2212];
	// begin inline asm
	dp4a.u32.u32 %r2343, %r2344, %r4201, %r2339;
	// end inline asm
	ld.const.u32 	%r2348, [matrix+2216];
	// begin inline asm
	dp4a.u32.u32 %r2347, %r2348, %r4205, %r2343;
	// end inline asm
	ld.const.u32 	%r2352, [matrix+2220];
	// begin inline asm
	dp4a.u32.u32 %r2351, %r2352, %r4209, %r2347;
	// end inline asm
	ld.const.u32 	%r2356, [matrix+2224];
	// begin inline asm
	dp4a.u32.u32 %r2355, %r2356, %r4213, %r2351;
	// end inline asm
	ld.const.u32 	%r2360, [matrix+2228];
	// begin inline asm
	dp4a.u32.u32 %r2359, %r2360, %r4217, %r2355;
	// end inline asm
	ld.const.u32 	%r2364, [matrix+2232];
	// begin inline asm
	dp4a.u32.u32 %r2363, %r2364, %r4221, %r2359;
	// end inline asm
	ld.const.u32 	%r2368, [matrix+2236];
	// begin inline asm
	dp4a.u32.u32 %r2367, %r2368, %r4225, %r2363;
	// end inline asm
	ld.const.u32 	%r2372, [matrix+2240];
	// begin inline asm
	dp4a.u32.u32 %r2371, %r2372, %r4165, %r4641;
	// end inline asm
	ld.const.u32 	%r2376, [matrix+2244];
	// begin inline asm
	dp4a.u32.u32 %r2375, %r2376, %r4169, %r2371;
	// end inline asm
	ld.const.u32 	%r2380, [matrix+2248];
	// begin inline asm
	dp4a.u32.u32 %r2379, %r2380, %r4173, %r2375;
	// end inline asm
	ld.const.u32 	%r2384, [matrix+2252];
	// begin inline asm
	dp4a.u32.u32 %r2383, %r2384, %r4177, %r2379;
	// end inline asm
	ld.const.u32 	%r2388, [matrix+2256];
	// begin inline asm
	dp4a.u32.u32 %r2387, %r2388, %r4181, %r2383;
	// end inline asm
	ld.const.u32 	%r2392, [matrix+2260];
	// begin inline asm
	dp4a.u32.u32 %r2391, %r2392, %r4185, %r2387;
	// end inline asm
	ld.const.u32 	%r2396, [matrix+2264];
	// begin inline asm
	dp4a.u32.u32 %r2395, %r2396, %r4189, %r2391;
	// end inline asm
	ld.const.u32 	%r2400, [matrix+2268];
	// begin inline asm
	dp4a.u32.u32 %r2399, %r2400, %r4193, %r2395;
	// end inline asm
	ld.const.u32 	%r2404, [matrix+2272];
	// begin inline asm
	dp4a.u32.u32 %r2403, %r2404, %r4197, %r2399;
	// end inline asm
	ld.const.u32 	%r2408, [matrix+2276];
	// begin inline asm
	dp4a.u32.u32 %r2407, %r2408, %r4201, %r2403;
	// end inline asm
	ld.const.u32 	%r2412, [matrix+2280];
	// begin inline asm
	dp4a.u32.u32 %r2411, %r2412, %r4205, %r2407;
	// end inline asm
	ld.const.u32 	%r2416, [matrix+2284];
	// begin inline asm
	dp4a.u32.u32 %r2415, %r2416, %r4209, %r2411;
	// end inline asm
	ld.const.u32 	%r2420, [matrix+2288];
	// begin inline asm
	dp4a.u32.u32 %r2419, %r2420, %r4213, %r2415;
	// end inline asm
	ld.const.u32 	%r2424, [matrix+2292];
	// begin inline asm
	dp4a.u32.u32 %r2423, %r2424, %r4217, %r2419;
	// end inline asm
	ld.const.u32 	%r2428, [matrix+2296];
	// begin inline asm
	dp4a.u32.u32 %r2427, %r2428, %r4221, %r2423;
	// end inline asm
	ld.const.u32 	%r2432, [matrix+2300];
	// begin inline asm
	dp4a.u32.u32 %r2431, %r2432, %r4225, %r2427;
	// end inline asm
	shr.u32 	%r4464, %r2367, 6;
	and.b32  	%r4465, %r4464, 240;
	shr.u32 	%r4466, %r2431, 10;
	or.b32  	%r4467, %r4466, %r4465;
	cvt.u64.u32 	%rd406, %r4467;
	xor.b64  	%rd407, %rd348, %rd406;
	ld.const.u32 	%r2436, [matrix+2304];
	// begin inline asm
	dp4a.u32.u32 %r2435, %r2436, %r4165, %r4641;
	// end inline asm
	ld.const.u32 	%r2440, [matrix+2308];
	// begin inline asm
	dp4a.u32.u32 %r2439, %r2440, %r4169, %r2435;
	// end inline asm
	ld.const.u32 	%r2444, [matrix+2312];
	// begin inline asm
	dp4a.u32.u32 %r2443, %r2444, %r4173, %r2439;
	// end inline asm
	ld.const.u32 	%r2448, [matrix+2316];
	// begin inline asm
	dp4a.u32.u32 %r2447, %r2448, %r4177, %r2443;
	// end inline asm
	ld.const.u32 	%r2452, [matrix+2320];
	// begin inline asm
	dp4a.u32.u32 %r2451, %r2452, %r4181, %r2447;
	// end inline asm
	ld.const.u32 	%r2456, [matrix+2324];
	// begin inline asm
	dp4a.u32.u32 %r2455, %r2456, %r4185, %r2451;
	// end inline asm
	ld.const.u32 	%r2460, [matrix+2328];
	// begin inline asm
	dp4a.u32.u32 %r2459, %r2460, %r4189, %r2455;
	// end inline asm
	ld.const.u32 	%r2464, [matrix+2332];
	// begin inline asm
	dp4a.u32.u32 %r2463, %r2464, %r4193, %r2459;
	// end inline asm
	ld.const.u32 	%r2468, [matrix+2336];
	// begin inline asm
	dp4a.u32.u32 %r2467, %r2468, %r4197, %r2463;
	// end inline asm
	ld.const.u32 	%r2472, [matrix+2340];
	// begin inline asm
	dp4a.u32.u32 %r2471, %r2472, %r4201, %r2467;
	// end inline asm
	ld.const.u32 	%r2476, [matrix+2344];
	// begin inline asm
	dp4a.u32.u32 %r2475, %r2476, %r4205, %r2471;
	// end inline asm
	ld.const.u32 	%r2480, [matrix+2348];
	// begin inline asm
	dp4a.u32.u32 %r2479, %r2480, %r4209, %r2475;
	// end inline asm
	ld.const.u32 	%r2484, [matrix+2352];
	// begin inline asm
	dp4a.u32.u32 %r2483, %r2484, %r4213, %r2479;
	// end inline asm
	ld.const.u32 	%r2488, [matrix+2356];
	// begin inline asm
	dp4a.u32.u32 %r2487, %r2488, %r4217, %r2483;
	// end inline asm
	ld.const.u32 	%r2492, [matrix+2360];
	// begin inline asm
	dp4a.u32.u32 %r2491, %r2492, %r4221, %r2487;
	// end inline asm
	ld.const.u32 	%r2496, [matrix+2364];
	// begin inline asm
	dp4a.u32.u32 %r2495, %r2496, %r4225, %r2491;
	// end inline asm
	ld.const.u32 	%r2500, [matrix+2368];
	// begin inline asm
	dp4a.u32.u32 %r2499, %r2500, %r4165, %r4641;
	// end inline asm
	ld.const.u32 	%r2504, [matrix+2372];
	// begin inline asm
	dp4a.u32.u32 %r2503, %r2504, %r4169, %r2499;
	// end inline asm
	ld.const.u32 	%r2508, [matrix+2376];
	// begin inline asm
	dp4a.u32.u32 %r2507, %r2508, %r4173, %r2503;
	// end inline asm
	ld.const.u32 	%r2512, [matrix+2380];
	// begin inline asm
	dp4a.u32.u32 %r2511, %r2512, %r4177, %r2507;
	// end inline asm
	ld.const.u32 	%r2516, [matrix+2384];
	// begin inline asm
	dp4a.u32.u32 %r2515, %r2516, %r4181, %r2511;
	// end inline asm
	ld.const.u32 	%r2520, [matrix+2388];
	// begin inline asm
	dp4a.u32.u32 %r2519, %r2520, %r4185, %r2515;
	// end inline asm
	ld.const.u32 	%r2524, [matrix+2392];
	// begin inline asm
	dp4a.u32.u32 %r2523, %r2524, %r4189, %r2519;
	// end inline asm
	ld.const.u32 	%r2528, [matrix+2396];
	// begin inline asm
	dp4a.u32.u32 %r2527, %r2528, %r4193, %r2523;
	// end inline asm
	ld.const.u32 	%r2532, [matrix+2400];
	// begin inline asm
	dp4a.u32.u32 %r2531, %r2532, %r4197, %r2527;
	// end inline asm
	ld.const.u32 	%r2536, [matrix+2404];
	// begin inline asm
	dp4a.u32.u32 %r2535, %r2536, %r4201, %r2531;
	// end inline asm
	ld.const.u32 	%r2540, [matrix+2408];
	// begin inline asm
	dp4a.u32.u32 %r2539, %r2540, %r4205, %r2535;
	// end inline asm
	ld.const.u32 	%r2544, [matrix+2412];
	// begin inline asm
	dp4a.u32.u32 %r2543, %r2544, %r4209, %r2539;
	// end inline asm
	ld.const.u32 	%r2548, [matrix+2416];
	// begin inline asm
	dp4a.u32.u32 %r2547, %r2548, %r4213, %r2543;
	// end inline asm
	ld.const.u32 	%r2552, [matrix+2420];
	// begin inline asm
	dp4a.u32.u32 %r2551, %r2552, %r4217, %r2547;
	// end inline asm
	ld.const.u32 	%r2556, [matrix+2424];
	// begin inline asm
	dp4a.u32.u32 %r2555, %r2556, %r4221, %r2551;
	// end inline asm
	ld.const.u32 	%r2560, [matrix+2428];
	// begin inline asm
	dp4a.u32.u32 %r2559, %r2560, %r4225, %r2555;
	// end inline asm
	shr.u32 	%r4468, %r2495, 6;
	and.b32  	%r4469, %r4468, 240;
	shr.u32 	%r4470, %r2559, 10;
	or.b32  	%r4471, %r4470, %r4469;
	cvt.u64.u32 	%rd408, %r4471;
	xor.b64  	%rd409, %rd349, %rd408;
	ld.const.u32 	%r2564, [matrix+2432];
	// begin inline asm
	dp4a.u32.u32 %r2563, %r2564, %r4165, %r4641;
	// end inline asm
	ld.const.u32 	%r2568, [matrix+2436];
	// begin inline asm
	dp4a.u32.u32 %r2567, %r2568, %r4169, %r2563;
	// end inline asm
	ld.const.u32 	%r2572, [matrix+2440];
	// begin inline asm
	dp4a.u32.u32 %r2571, %r2572, %r4173, %r2567;
	// end inline asm
	ld.const.u32 	%r2576, [matrix+2444];
	// begin inline asm
	dp4a.u32.u32 %r2575, %r2576, %r4177, %r2571;
	// end inline asm
	ld.const.u32 	%r2580, [matrix+2448];
	// begin inline asm
	dp4a.u32.u32 %r2579, %r2580, %r4181, %r2575;
	// end inline asm
	ld.const.u32 	%r2584, [matrix+2452];
	// begin inline asm
	dp4a.u32.u32 %r2583, %r2584, %r4185, %r2579;
	// end inline asm
	ld.const.u32 	%r2588, [matrix+2456];
	// begin inline asm
	dp4a.u32.u32 %r2587, %r2588, %r4189, %r2583;
	// end inline asm
	ld.const.u32 	%r2592, [matrix+2460];
	// begin inline asm
	dp4a.u32.u32 %r2591, %r2592, %r4193, %r2587;
	// end inline asm
	ld.const.u32 	%r2596, [matrix+2464];
	// begin inline asm
	dp4a.u32.u32 %r2595, %r2596, %r4197, %r2591;
	// end inline asm
	ld.const.u32 	%r2600, [matrix+2468];
	// begin inline asm
	dp4a.u32.u32 %r2599, %r2600, %r4201, %r2595;
	// end inline asm
	ld.const.u32 	%r2604, [matrix+2472];
	// begin inline asm
	dp4a.u32.u32 %r2603, %r2604, %r4205, %r2599;
	// end inline asm
	ld.const.u32 	%r2608, [matrix+2476];
	// begin inline asm
	dp4a.u32.u32 %r2607, %r2608, %r4209, %r2603;
	// end inline asm
	ld.const.u32 	%r2612, [matrix+2480];
	// begin inline asm
	dp4a.u32.u32 %r2611, %r2612, %r4213, %r2607;
	// end inline asm
	ld.const.u32 	%r2616, [matrix+2484];
	// begin inline asm
	dp4a.u32.u32 %r2615, %r2616, %r4217, %r2611;
	// end inline asm
	ld.const.u32 	%r2620, [matrix+2488];
	// begin inline asm
	dp4a.u32.u32 %r2619, %r2620, %r4221, %r2615;
	// end inline asm
	ld.const.u32 	%r2624, [matrix+2492];
	// begin inline asm
	dp4a.u32.u32 %r2623, %r2624, %r4225, %r2619;
	// end inline asm
	ld.const.u32 	%r2628, [matrix+2496];
	// begin inline asm
	dp4a.u32.u32 %r2627, %r2628, %r4165, %r4641;
	// end inline asm
	ld.const.u32 	%r2632, [matrix+2500];
	// begin inline asm
	dp4a.u32.u32 %r2631, %r2632, %r4169, %r2627;
	// end inline asm
	ld.const.u32 	%r2636, [matrix+2504];
	// begin inline asm
	dp4a.u32.u32 %r2635, %r2636, %r4173, %r2631;
	// end inline asm
	ld.const.u32 	%r2640, [matrix+2508];
	// begin inline asm
	dp4a.u32.u32 %r2639, %r2640, %r4177, %r2635;
	// end inline asm
	ld.const.u32 	%r2644, [matrix+2512];
	// begin inline asm
	dp4a.u32.u32 %r2643, %r2644, %r4181, %r2639;
	// end inline asm
	ld.const.u32 	%r2648, [matrix+2516];
	// begin inline asm
	dp4a.u32.u32 %r2647, %r2648, %r4185, %r2643;
	// end inline asm
	ld.const.u32 	%r2652, [matrix+2520];
	// begin inline asm
	dp4a.u32.u32 %r2651, %r2652, %r4189, %r2647;
	// end inline asm
	ld.const.u32 	%r2656, [matrix+2524];
	// begin inline asm
	dp4a.u32.u32 %r2655, %r2656, %r4193, %r2651;
	// end inline asm
	ld.const.u32 	%r2660, [matrix+2528];
	// begin inline asm
	dp4a.u32.u32 %r2659, %r2660, %r4197, %r2655;
	// end inline asm
	ld.const.u32 	%r2664, [matrix+2532];
	// begin inline asm
	dp4a.u32.u32 %r2663, %r2664, %r4201, %r2659;
	// end inline asm
	ld.const.u32 	%r2668, [matrix+2536];
	// begin inline asm
	dp4a.u32.u32 %r2667, %r2668, %r4205, %r2663;
	// end inline asm
	ld.const.u32 	%r2672, [matrix+2540];
	// begin inline asm
	dp4a.u32.u32 %r2671, %r2672, %r4209, %r2667;
	// end inline asm
	ld.const.u32 	%r2676, [matrix+2544];
	// begin inline asm
	dp4a.u32.u32 %r2675, %r2676, %r4213, %r2671;
	// end inline asm
	ld.const.u32 	%r2680, [matrix+2548];
	// begin inline asm
	dp4a.u32.u32 %r2679, %r2680, %r4217, %r2675;
	// end inline asm
	ld.const.u32 	%r2684, [matrix+2552];
	// begin inline asm
	dp4a.u32.u32 %r2683, %r2684, %r4221, %r2679;
	// end inline asm
	ld.const.u32 	%r2688, [matrix+2556];
	// begin inline asm
	dp4a.u32.u32 %r2687, %r2688, %r4225, %r2683;
	// end inline asm
	shr.u32 	%r4472, %r2623, 6;
	and.b32  	%r4473, %r4472, 240;
	shr.u32 	%r4474, %r2687, 10;
	or.b32  	%r4475, %r4474, %r4473;
	cvt.u64.u32 	%rd410, %r4475;
	xor.b64  	%rd411, %rd350, %rd410;
	ld.const.u32 	%r2692, [matrix+2560];
	// begin inline asm
	dp4a.u32.u32 %r2691, %r2692, %r4165, %r4641;
	// end inline asm
	ld.const.u32 	%r2696, [matrix+2564];
	// begin inline asm
	dp4a.u32.u32 %r2695, %r2696, %r4169, %r2691;
	// end inline asm
	ld.const.u32 	%r2700, [matrix+2568];
	// begin inline asm
	dp4a.u32.u32 %r2699, %r2700, %r4173, %r2695;
	// end inline asm
	ld.const.u32 	%r2704, [matrix+2572];
	// begin inline asm
	dp4a.u32.u32 %r2703, %r2704, %r4177, %r2699;
	// end inline asm
	ld.const.u32 	%r2708, [matrix+2576];
	// begin inline asm
	dp4a.u32.u32 %r2707, %r2708, %r4181, %r2703;
	// end inline asm
	ld.const.u32 	%r2712, [matrix+2580];
	// begin inline asm
	dp4a.u32.u32 %r2711, %r2712, %r4185, %r2707;
	// end inline asm
	ld.const.u32 	%r2716, [matrix+2584];
	// begin inline asm
	dp4a.u32.u32 %r2715, %r2716, %r4189, %r2711;
	// end inline asm
	ld.const.u32 	%r2720, [matrix+2588];
	// begin inline asm
	dp4a.u32.u32 %r2719, %r2720, %r4193, %r2715;
	// end inline asm
	ld.const.u32 	%r2724, [matrix+2592];
	// begin inline asm
	dp4a.u32.u32 %r2723, %r2724, %r4197, %r2719;
	// end inline asm
	ld.const.u32 	%r2728, [matrix+2596];
	// begin inline asm
	dp4a.u32.u32 %r2727, %r2728, %r4201, %r2723;
	// end inline asm
	ld.const.u32 	%r2732, [matrix+2600];
	// begin inline asm
	dp4a.u32.u32 %r2731, %r2732, %r4205, %r2727;
	// end inline asm
	ld.const.u32 	%r2736, [matrix+2604];
	// begin inline asm
	dp4a.u32.u32 %r2735, %r2736, %r4209, %r2731;
	// end inline asm
	ld.const.u32 	%r2740, [matrix+2608];
	// begin inline asm
	dp4a.u32.u32 %r2739, %r2740, %r4213, %r2735;
	// end inline asm
	ld.const.u32 	%r2744, [matrix+2612];
	// begin inline asm
	dp4a.u32.u32 %r2743, %r2744, %r4217, %r2739;
	// end inline asm
	ld.const.u32 	%r2748, [matrix+2616];
	// begin inline asm
	dp4a.u32.u32 %r2747, %r2748, %r4221, %r2743;
	// end inline asm
	ld.const.u32 	%r2752, [matrix+2620];
	// begin inline asm
	dp4a.u32.u32 %r2751, %r2752, %r4225, %r2747;
	// end inline asm
	ld.const.u32 	%r2756, [matrix+2624];
	// begin inline asm
	dp4a.u32.u32 %r2755, %r2756, %r4165, %r4641;
	// end inline asm
	ld.const.u32 	%r2760, [matrix+2628];
	// begin inline asm
	dp4a.u32.u32 %r2759, %r2760, %r4169, %r2755;
	// end inline asm
	ld.const.u32 	%r2764, [matrix+2632];
	// begin inline asm
	dp4a.u32.u32 %r2763, %r2764, %r4173, %r2759;
	// end inline asm
	ld.const.u32 	%r2768, [matrix+2636];
	// begin inline asm
	dp4a.u32.u32 %r2767, %r2768, %r4177, %r2763;
	// end inline asm
	ld.const.u32 	%r2772, [matrix+2640];
	// begin inline asm
	dp4a.u32.u32 %r2771, %r2772, %r4181, %r2767;
	// end inline asm
	ld.const.u32 	%r2776, [matrix+2644];
	// begin inline asm
	dp4a.u32.u32 %r2775, %r2776, %r4185, %r2771;
	// end inline asm
	ld.const.u32 	%r2780, [matrix+2648];
	// begin inline asm
	dp4a.u32.u32 %r2779, %r2780, %r4189, %r2775;
	// end inline asm
	ld.const.u32 	%r2784, [matrix+2652];
	// begin inline asm
	dp4a.u32.u32 %r2783, %r2784, %r4193, %r2779;
	// end inline asm
	ld.const.u32 	%r2788, [matrix+2656];
	// begin inline asm
	dp4a.u32.u32 %r2787, %r2788, %r4197, %r2783;
	// end inline asm
	ld.const.u32 	%r2792, [matrix+2660];
	// begin inline asm
	dp4a.u32.u32 %r2791, %r2792, %r4201, %r2787;
	// end inline asm
	ld.const.u32 	%r2796, [matrix+2664];
	// begin inline asm
	dp4a.u32.u32 %r2795, %r2796, %r4205, %r2791;
	// end inline asm
	ld.const.u32 	%r2800, [matrix+2668];
	// begin inline asm
	dp4a.u32.u32 %r2799, %r2800, %r4209, %r2795;
	// end inline asm
	ld.const.u32 	%r2804, [matrix+2672];
	// begin inline asm
	dp4a.u32.u32 %r2803, %r2804, %r4213, %r2799;
	// end inline asm
	ld.const.u32 	%r2808, [matrix+2676];
	// begin inline asm
	dp4a.u32.u32 %r2807, %r2808, %r4217, %r2803;
	// end inline asm
	ld.const.u32 	%r2812, [matrix+2680];
	// begin inline asm
	dp4a.u32.u32 %r2811, %r2812, %r4221, %r2807;
	// end inline asm
	ld.const.u32 	%r2816, [matrix+2684];
	// begin inline asm
	dp4a.u32.u32 %r2815, %r2816, %r4225, %r2811;
	// end inline asm
	shr.u32 	%r4476, %r2751, 6;
	and.b32  	%r4477, %r4476, 240;
	shr.u32 	%r4478, %r2815, 10;
	or.b32  	%r4479, %r4478, %r4477;
	cvt.u64.u32 	%rd412, %r4479;
	xor.b64  	%rd413, %rd351, %rd412;
	ld.const.u32 	%r2820, [matrix+2688];
	// begin inline asm
	dp4a.u32.u32 %r2819, %r2820, %r4165, %r4641;
	// end inline asm
	ld.const.u32 	%r2824, [matrix+2692];
	// begin inline asm
	dp4a.u32.u32 %r2823, %r2824, %r4169, %r2819;
	// end inline asm
	ld.const.u32 	%r2828, [matrix+2696];
	// begin inline asm
	dp4a.u32.u32 %r2827, %r2828, %r4173, %r2823;
	// end inline asm
	ld.const.u32 	%r2832, [matrix+2700];
	// begin inline asm
	dp4a.u32.u32 %r2831, %r2832, %r4177, %r2827;
	// end inline asm
	ld.const.u32 	%r2836, [matrix+2704];
	// begin inline asm
	dp4a.u32.u32 %r2835, %r2836, %r4181, %r2831;
	// end inline asm
	ld.const.u32 	%r2840, [matrix+2708];
	// begin inline asm
	dp4a.u32.u32 %r2839, %r2840, %r4185, %r2835;
	// end inline asm
	ld.const.u32 	%r2844, [matrix+2712];
	// begin inline asm
	dp4a.u32.u32 %r2843, %r2844, %r4189, %r2839;
	// end inline asm
	ld.const.u32 	%r2848, [matrix+2716];
	// begin inline asm
	dp4a.u32.u32 %r2847, %r2848, %r4193, %r2843;
	// end inline asm
	ld.const.u32 	%r2852, [matrix+2720];
	// begin inline asm
	dp4a.u32.u32 %r2851, %r2852, %r4197, %r2847;
	// end inline asm
	ld.const.u32 	%r2856, [matrix+2724];
	// begin inline asm
	dp4a.u32.u32 %r2855, %r2856, %r4201, %r2851;
	// end inline asm
	ld.const.u32 	%r2860, [matrix+2728];
	// begin inline asm
	dp4a.u32.u32 %r2859, %r2860, %r4205, %r2855;
	// end inline asm
	ld.const.u32 	%r2864, [matrix+2732];
	// begin inline asm
	dp4a.u32.u32 %r2863, %r2864, %r4209, %r2859;
	// end inline asm
	ld.const.u32 	%r2868, [matrix+2736];
	// begin inline asm
	dp4a.u32.u32 %r2867, %r2868, %r4213, %r2863;
	// end inline asm
	ld.const.u32 	%r2872, [matrix+2740];
	// begin inline asm
	dp4a.u32.u32 %r2871, %r2872, %r4217, %r2867;
	// end inline asm
	ld.const.u32 	%r2876, [matrix+2744];
	// begin inline asm
	dp4a.u32.u32 %r2875, %r2876, %r4221, %r2871;
	// end inline asm
	ld.const.u32 	%r2880, [matrix+2748];
	// begin inline asm
	dp4a.u32.u32 %r2879, %r2880, %r4225, %r2875;
	// end inline asm
	ld.const.u32 	%r2884, [matrix+2752];
	// begin inline asm
	dp4a.u32.u32 %r2883, %r2884, %r4165, %r4641;
	// end inline asm
	ld.const.u32 	%r2888, [matrix+2756];
	// begin inline asm
	dp4a.u32.u32 %r2887, %r2888, %r4169, %r2883;
	// end inline asm
	ld.const.u32 	%r2892, [matrix+2760];
	// begin inline asm
	dp4a.u32.u32 %r2891, %r2892, %r4173, %r2887;
	// end inline asm
	ld.const.u32 	%r2896, [matrix+2764];
	// begin inline asm
	dp4a.u32.u32 %r2895, %r2896, %r4177, %r2891;
	// end inline asm
	ld.const.u32 	%r2900, [matrix+2768];
	// begin inline asm
	dp4a.u32.u32 %r2899, %r2900, %r4181, %r2895;
	// end inline asm
	ld.const.u32 	%r2904, [matrix+2772];
	// begin inline asm
	dp4a.u32.u32 %r2903, %r2904, %r4185, %r2899;
	// end inline asm
	ld.const.u32 	%r2908, [matrix+2776];
	// begin inline asm
	dp4a.u32.u32 %r2907, %r2908, %r4189, %r2903;
	// end inline asm
	ld.const.u32 	%r2912, [matrix+2780];
	// begin inline asm
	dp4a.u32.u32 %r2911, %r2912, %r4193, %r2907;
	// end inline asm
	ld.const.u32 	%r2916, [matrix+2784];
	// begin inline asm
	dp4a.u32.u32 %r2915, %r2916, %r4197, %r2911;
	// end inline asm
	ld.const.u32 	%r2920, [matrix+2788];
	// begin inline asm
	dp4a.u32.u32 %r2919, %r2920, %r4201, %r2915;
	// end inline asm
	ld.const.u32 	%r2924, [matrix+2792];
	// begin inline asm
	dp4a.u32.u32 %r2923, %r2924, %r4205, %r2919;
	// end inline asm
	ld.const.u32 	%r2928, [matrix+2796];
	// begin inline asm
	dp4a.u32.u32 %r2927, %r2928, %r4209, %r2923;
	// end inline asm
	ld.const.u32 	%r2932, [matrix+2800];
	// begin inline asm
	dp4a.u32.u32 %r2931, %r2932, %r4213, %r2927;
	// end inline asm
	ld.const.u32 	%r2936, [matrix+2804];
	// begin inline asm
	dp4a.u32.u32 %r2935, %r2936, %r4217, %r2931;
	// end inline asm
	ld.const.u32 	%r2940, [matrix+2808];
	// begin inline asm
	dp4a.u32.u32 %r2939, %r2940, %r4221, %r2935;
	// end inline asm
	ld.const.u32 	%r2944, [matrix+2812];
	// begin inline asm
	dp4a.u32.u32 %r2943, %r2944, %r4225, %r2939;
	// end inline asm
	shr.u32 	%r4480, %r2879, 6;
	and.b32  	%r4481, %r4480, 240;
	shr.u32 	%r4482, %r2943, 10;
	or.b32  	%r4483, %r4482, %r4481;
	cvt.u64.u32 	%rd414, %r4483;
	xor.b64  	%rd415, %rd352, %rd414;
	ld.const.u32 	%r2948, [matrix+2816];
	// begin inline asm
	dp4a.u32.u32 %r2947, %r2948, %r4165, %r4641;
	// end inline asm
	ld.const.u32 	%r2952, [matrix+2820];
	// begin inline asm
	dp4a.u32.u32 %r2951, %r2952, %r4169, %r2947;
	// end inline asm
	ld.const.u32 	%r2956, [matrix+2824];
	// begin inline asm
	dp4a.u32.u32 %r2955, %r2956, %r4173, %r2951;
	// end inline asm
	ld.const.u32 	%r2960, [matrix+2828];
	// begin inline asm
	dp4a.u32.u32 %r2959, %r2960, %r4177, %r2955;
	// end inline asm
	ld.const.u32 	%r2964, [matrix+2832];
	// begin inline asm
	dp4a.u32.u32 %r2963, %r2964, %r4181, %r2959;
	// end inline asm
	ld.const.u32 	%r2968, [matrix+2836];
	// begin inline asm
	dp4a.u32.u32 %r2967, %r2968, %r4185, %r2963;
	// end inline asm
	ld.const.u32 	%r2972, [matrix+2840];
	// begin inline asm
	dp4a.u32.u32 %r2971, %r2972, %r4189, %r2967;
	// end inline asm
	ld.const.u32 	%r2976, [matrix+2844];
	// begin inline asm
	dp4a.u32.u32 %r2975, %r2976, %r4193, %r2971;
	// end inline asm
	ld.const.u32 	%r2980, [matrix+2848];
	// begin inline asm
	dp4a.u32.u32 %r2979, %r2980, %r4197, %r2975;
	// end inline asm
	ld.const.u32 	%r2984, [matrix+2852];
	// begin inline asm
	dp4a.u32.u32 %r2983, %r2984, %r4201, %r2979;
	// end inline asm
	ld.const.u32 	%r2988, [matrix+2856];
	// begin inline asm
	dp4a.u32.u32 %r2987, %r2988, %r4205, %r2983;
	// end inline asm
	ld.const.u32 	%r2992, [matrix+2860];
	// begin inline asm
	dp4a.u32.u32 %r2991, %r2992, %r4209, %r2987;
	// end inline asm
	ld.const.u32 	%r2996, [matrix+2864];
	// begin inline asm
	dp4a.u32.u32 %r2995, %r2996, %r4213, %r2991;
	// end inline asm
	ld.const.u32 	%r3000, [matrix+2868];
	// begin inline asm
	dp4a.u32.u32 %r2999, %r3000, %r4217, %r2995;
	// end inline asm
	ld.const.u32 	%r3004, [matrix+2872];
	// begin inline asm
	dp4a.u32.u32 %r3003, %r3004, %r4221, %r2999;
	// end inline asm
	ld.const.u32 	%r3008, [matrix+2876];
	// begin inline asm
	dp4a.u32.u32 %r3007, %r3008, %r4225, %r3003;
	// end inline asm
	ld.const.u32 	%r3012, [matrix+2880];
	// begin inline asm
	dp4a.u32.u32 %r3011, %r3012, %r4165, %r4641;
	// end inline asm
	ld.const.u32 	%r3016, [matrix+2884];
	// begin inline asm
	dp4a.u32.u32 %r3015, %r3016, %r4169, %r3011;
	// end inline asm
	ld.const.u32 	%r3020, [matrix+2888];
	// begin inline asm
	dp4a.u32.u32 %r3019, %r3020, %r4173, %r3015;
	// end inline asm
	ld.const.u32 	%r3024, [matrix+2892];
	// begin inline asm
	dp4a.u32.u32 %r3023, %r3024, %r4177, %r3019;
	// end inline asm
	ld.const.u32 	%r3028, [matrix+2896];
	// begin inline asm
	dp4a.u32.u32 %r3027, %r3028, %r4181, %r3023;
	// end inline asm
	ld.const.u32 	%r3032, [matrix+2900];
	// begin inline asm
	dp4a.u32.u32 %r3031, %r3032, %r4185, %r3027;
	// end inline asm
	ld.const.u32 	%r3036, [matrix+2904];
	// begin inline asm
	dp4a.u32.u32 %r3035, %r3036, %r4189, %r3031;
	// end inline asm
	ld.const.u32 	%r3040, [matrix+2908];
	// begin inline asm
	dp4a.u32.u32 %r3039, %r3040, %r4193, %r3035;
	// end inline asm
	ld.const.u32 	%r3044, [matrix+2912];
	// begin inline asm
	dp4a.u32.u32 %r3043, %r3044, %r4197, %r3039;
	// end inline asm
	ld.const.u32 	%r3048, [matrix+2916];
	// begin inline asm
	dp4a.u32.u32 %r3047, %r3048, %r4201, %r3043;
	// end inline asm
	ld.const.u32 	%r3052, [matrix+2920];
	// begin inline asm
	dp4a.u32.u32 %r3051, %r3052, %r4205, %r3047;
	// end inline asm
	ld.const.u32 	%r3056, [matrix+2924];
	// begin inline asm
	dp4a.u32.u32 %r3055, %r3056, %r4209, %r3051;
	// end inline asm
	ld.const.u32 	%r3060, [matrix+2928];
	// begin inline asm
	dp4a.u32.u32 %r3059, %r3060, %r4213, %r3055;
	// end inline asm
	ld.const.u32 	%r3064, [matrix+2932];
	// begin inline asm
	dp4a.u32.u32 %r3063, %r3064, %r4217, %r3059;
	// end inline asm
	ld.const.u32 	%r3068, [matrix+2936];
	// begin inline asm
	dp4a.u32.u32 %r3067, %r3068, %r4221, %r3063;
	// end inline asm
	ld.const.u32 	%r3072, [matrix+2940];
	// begin inline asm
	dp4a.u32.u32 %r3071, %r3072, %r4225, %r3067;
	// end inline asm
	shr.u32 	%r4484, %r3007, 6;
	and.b32  	%r4485, %r4484, 240;
	shr.u32 	%r4486, %r3071, 10;
	or.b32  	%r4487, %r4486, %r4485;
	cvt.u64.u32 	%rd416, %r4487;
	xor.b64  	%rd417, %rd353, %rd416;
	ld.const.u32 	%r3076, [matrix+2944];
	// begin inline asm
	dp4a.u32.u32 %r3075, %r3076, %r4165, %r4641;
	// end inline asm
	ld.const.u32 	%r3080, [matrix+2948];
	// begin inline asm
	dp4a.u32.u32 %r3079, %r3080, %r4169, %r3075;
	// end inline asm
	ld.const.u32 	%r3084, [matrix+2952];
	// begin inline asm
	dp4a.u32.u32 %r3083, %r3084, %r4173, %r3079;
	// end inline asm
	ld.const.u32 	%r3088, [matrix+2956];
	// begin inline asm
	dp4a.u32.u32 %r3087, %r3088, %r4177, %r3083;
	// end inline asm
	ld.const.u32 	%r3092, [matrix+2960];
	// begin inline asm
	dp4a.u32.u32 %r3091, %r3092, %r4181, %r3087;
	// end inline asm
	ld.const.u32 	%r3096, [matrix+2964];
	// begin inline asm
	dp4a.u32.u32 %r3095, %r3096, %r4185, %r3091;
	// end inline asm
	ld.const.u32 	%r3100, [matrix+2968];
	// begin inline asm
	dp4a.u32.u32 %r3099, %r3100, %r4189, %r3095;
	// end inline asm
	ld.const.u32 	%r3104, [matrix+2972];
	// begin inline asm
	dp4a.u32.u32 %r3103, %r3104, %r4193, %r3099;
	// end inline asm
	ld.const.u32 	%r3108, [matrix+2976];
	// begin inline asm
	dp4a.u32.u32 %r3107, %r3108, %r4197, %r3103;
	// end inline asm
	ld.const.u32 	%r3112, [matrix+2980];
	// begin inline asm
	dp4a.u32.u32 %r3111, %r3112, %r4201, %r3107;
	// end inline asm
	ld.const.u32 	%r3116, [matrix+2984];
	// begin inline asm
	dp4a.u32.u32 %r3115, %r3116, %r4205, %r3111;
	// end inline asm
	ld.const.u32 	%r3120, [matrix+2988];
	// begin inline asm
	dp4a.u32.u32 %r3119, %r3120, %r4209, %r3115;
	// end inline asm
	ld.const.u32 	%r3124, [matrix+2992];
	// begin inline asm
	dp4a.u32.u32 %r3123, %r3124, %r4213, %r3119;
	// end inline asm
	ld.const.u32 	%r3128, [matrix+2996];
	// begin inline asm
	dp4a.u32.u32 %r3127, %r3128, %r4217, %r3123;
	// end inline asm
	ld.const.u32 	%r3132, [matrix+3000];
	// begin inline asm
	dp4a.u32.u32 %r3131, %r3132, %r4221, %r3127;
	// end inline asm
	ld.const.u32 	%r3136, [matrix+3004];
	// begin inline asm
	dp4a.u32.u32 %r3135, %r3136, %r4225, %r3131;
	// end inline asm
	ld.const.u32 	%r3140, [matrix+3008];
	// begin inline asm
	dp4a.u32.u32 %r3139, %r3140, %r4165, %r4641;
	// end inline asm
	ld.const.u32 	%r3144, [matrix+3012];
	// begin inline asm
	dp4a.u32.u32 %r3143, %r3144, %r4169, %r3139;
	// end inline asm
	ld.const.u32 	%r3148, [matrix+3016];
	// begin inline asm
	dp4a.u32.u32 %r3147, %r3148, %r4173, %r3143;
	// end inline asm
	ld.const.u32 	%r3152, [matrix+3020];
	// begin inline asm
	dp4a.u32.u32 %r3151, %r3152, %r4177, %r3147;
	// end inline asm
	ld.const.u32 	%r3156, [matrix+3024];
	// begin inline asm
	dp4a.u32.u32 %r3155, %r3156, %r4181, %r3151;
	// end inline asm
	ld.const.u32 	%r3160, [matrix+3028];
	// begin inline asm
	dp4a.u32.u32 %r3159, %r3160, %r4185, %r3155;
	// end inline asm
	ld.const.u32 	%r3164, [matrix+3032];
	// begin inline asm
	dp4a.u32.u32 %r3163, %r3164, %r4189, %r3159;
	// end inline asm
	ld.const.u32 	%r3168, [matrix+3036];
	// begin inline asm
	dp4a.u32.u32 %r3167, %r3168, %r4193, %r3163;
	// end inline asm
	ld.const.u32 	%r3172, [matrix+3040];
	// begin inline asm
	dp4a.u32.u32 %r3171, %r3172, %r4197, %r3167;
	// end inline asm
	ld.const.u32 	%r3176, [matrix+3044];
	// begin inline asm
	dp4a.u32.u32 %r3175, %r3176, %r4201, %r3171;
	// end inline asm
	ld.const.u32 	%r3180, [matrix+3048];
	// begin inline asm
	dp4a.u32.u32 %r3179, %r3180, %r4205, %r3175;
	// end inline asm
	ld.const.u32 	%r3184, [matrix+3052];
	// begin inline asm
	dp4a.u32.u32 %r3183, %r3184, %r4209, %r3179;
	// end inline asm
	ld.const.u32 	%r3188, [matrix+3056];
	// begin inline asm
	dp4a.u32.u32 %r3187, %r3188, %r4213, %r3183;
	// end inline asm
	ld.const.u32 	%r3192, [matrix+3060];
	// begin inline asm
	dp4a.u32.u32 %r3191, %r3192, %r4217, %r3187;
	// end inline asm
	ld.const.u32 	%r3196, [matrix+3064];
	// begin inline asm
	dp4a.u32.u32 %r3195, %r3196, %r4221, %r3191;
	// end inline asm
	ld.const.u32 	%r3200, [matrix+3068];
	// begin inline asm
	dp4a.u32.u32 %r3199, %r3200, %r4225, %r3195;
	// end inline asm
	shr.u32 	%r4488, %r3135, 6;
	and.b32  	%r4489, %r4488, 240;
	shr.u32 	%r4490, %r3199, 10;
	or.b32  	%r4491, %r4490, %r4489;
	cvt.u64.u32 	%rd418, %r4491;
	ld.const.u32 	%r3204, [matrix+3072];
	// begin inline asm
	dp4a.u32.u32 %r3203, %r3204, %r4165, %r4641;
	// end inline asm
	ld.const.u32 	%r3208, [matrix+3076];
	// begin inline asm
	dp4a.u32.u32 %r3207, %r3208, %r4169, %r3203;
	// end inline asm
	ld.const.u32 	%r3212, [matrix+3080];
	// begin inline asm
	dp4a.u32.u32 %r3211, %r3212, %r4173, %r3207;
	// end inline asm
	ld.const.u32 	%r3216, [matrix+3084];
	// begin inline asm
	dp4a.u32.u32 %r3215, %r3216, %r4177, %r3211;
	// end inline asm
	ld.const.u32 	%r3220, [matrix+3088];
	// begin inline asm
	dp4a.u32.u32 %r3219, %r3220, %r4181, %r3215;
	// end inline asm
	ld.const.u32 	%r3224, [matrix+3092];
	// begin inline asm
	dp4a.u32.u32 %r3223, %r3224, %r4185, %r3219;
	// end inline asm
	ld.const.u32 	%r3228, [matrix+3096];
	// begin inline asm
	dp4a.u32.u32 %r3227, %r3228, %r4189, %r3223;
	// end inline asm
	ld.const.u32 	%r3232, [matrix+3100];
	// begin inline asm
	dp4a.u32.u32 %r3231, %r3232, %r4193, %r3227;
	// end inline asm
	ld.const.u32 	%r3236, [matrix+3104];
	// begin inline asm
	dp4a.u32.u32 %r3235, %r3236, %r4197, %r3231;
	// end inline asm
	ld.const.u32 	%r3240, [matrix+3108];
	// begin inline asm
	dp4a.u32.u32 %r3239, %r3240, %r4201, %r3235;
	// end inline asm
	ld.const.u32 	%r3244, [matrix+3112];
	// begin inline asm
	dp4a.u32.u32 %r3243, %r3244, %r4205, %r3239;
	// end inline asm
	ld.const.u32 	%r3248, [matrix+3116];
	// begin inline asm
	dp4a.u32.u32 %r3247, %r3248, %r4209, %r3243;
	// end inline asm
	ld.const.u32 	%r3252, [matrix+3120];
	// begin inline asm
	dp4a.u32.u32 %r3251, %r3252, %r4213, %r3247;
	// end inline asm
	ld.const.u32 	%r3256, [matrix+3124];
	// begin inline asm
	dp4a.u32.u32 %r3255, %r3256, %r4217, %r3251;
	// end inline asm
	ld.const.u32 	%r3260, [matrix+3128];
	// begin inline asm
	dp4a.u32.u32 %r3259, %r3260, %r4221, %r3255;
	// end inline asm
	ld.const.u32 	%r3264, [matrix+3132];
	// begin inline asm
	dp4a.u32.u32 %r3263, %r3264, %r4225, %r3259;
	// end inline asm
	ld.const.u32 	%r3268, [matrix+3136];
	// begin inline asm
	dp4a.u32.u32 %r3267, %r3268, %r4165, %r4641;
	// end inline asm
	ld.const.u32 	%r3272, [matrix+3140];
	// begin inline asm
	dp4a.u32.u32 %r3271, %r3272, %r4169, %r3267;
	// end inline asm
	ld.const.u32 	%r3276, [matrix+3144];
	// begin inline asm
	dp4a.u32.u32 %r3275, %r3276, %r4173, %r3271;
	// end inline asm
	ld.const.u32 	%r3280, [matrix+3148];
	// begin inline asm
	dp4a.u32.u32 %r3279, %r3280, %r4177, %r3275;
	// end inline asm
	ld.const.u32 	%r3284, [matrix+3152];
	// begin inline asm
	dp4a.u32.u32 %r3283, %r3284, %r4181, %r3279;
	// end inline asm
	ld.const.u32 	%r3288, [matrix+3156];
	// begin inline asm
	dp4a.u32.u32 %r3287, %r3288, %r4185, %r3283;
	// end inline asm
	ld.const.u32 	%r3292, [matrix+3160];
	// begin inline asm
	dp4a.u32.u32 %r3291, %r3292, %r4189, %r3287;
	// end inline asm
	ld.const.u32 	%r3296, [matrix+3164];
	// begin inline asm
	dp4a.u32.u32 %r3295, %r3296, %r4193, %r3291;
	// end inline asm
	ld.const.u32 	%r3300, [matrix+3168];
	// begin inline asm
	dp4a.u32.u32 %r3299, %r3300, %r4197, %r3295;
	// end inline asm
	ld.const.u32 	%r3304, [matrix+3172];
	// begin inline asm
	dp4a.u32.u32 %r3303, %r3304, %r4201, %r3299;
	// end inline asm
	ld.const.u32 	%r3308, [matrix+3176];
	// begin inline asm
	dp4a.u32.u32 %r3307, %r3308, %r4205, %r3303;
	// end inline asm
	ld.const.u32 	%r3312, [matrix+3180];
	// begin inline asm
	dp4a.u32.u32 %r3311, %r3312, %r4209, %r3307;
	// end inline asm
	ld.const.u32 	%r3316, [matrix+3184];
	// begin inline asm
	dp4a.u32.u32 %r3315, %r3316, %r4213, %r3311;
	// end inline asm
	ld.const.u32 	%r3320, [matrix+3188];
	// begin inline asm
	dp4a.u32.u32 %r3319, %r3320, %r4217, %r3315;
	// end inline asm
	ld.const.u32 	%r3324, [matrix+3192];
	// begin inline asm
	dp4a.u32.u32 %r3323, %r3324, %r4221, %r3319;
	// end inline asm
	ld.const.u32 	%r3328, [matrix+3196];
	// begin inline asm
	dp4a.u32.u32 %r3327, %r3328, %r4225, %r3323;
	// end inline asm
	shr.u32 	%r4492, %r3263, 6;
	and.b32  	%r4493, %r4492, 240;
	bfe.u32 	%r4494, %r3327, 10, 8;
	or.b32  	%r4495, %r4494, %r4493;
	cvt.u64.u32 	%rd419, %r4495;
	ld.const.u32 	%r3332, [matrix+3200];
	// begin inline asm
	dp4a.u32.u32 %r3331, %r3332, %r4165, %r4641;
	// end inline asm
	ld.const.u32 	%r3336, [matrix+3204];
	// begin inline asm
	dp4a.u32.u32 %r3335, %r3336, %r4169, %r3331;
	// end inline asm
	ld.const.u32 	%r3340, [matrix+3208];
	// begin inline asm
	dp4a.u32.u32 %r3339, %r3340, %r4173, %r3335;
	// end inline asm
	ld.const.u32 	%r3344, [matrix+3212];
	// begin inline asm
	dp4a.u32.u32 %r3343, %r3344, %r4177, %r3339;
	// end inline asm
	ld.const.u32 	%r3348, [matrix+3216];
	// begin inline asm
	dp4a.u32.u32 %r3347, %r3348, %r4181, %r3343;
	// end inline asm
	ld.const.u32 	%r3352, [matrix+3220];
	// begin inline asm
	dp4a.u32.u32 %r3351, %r3352, %r4185, %r3347;
	// end inline asm
	ld.const.u32 	%r3356, [matrix+3224];
	// begin inline asm
	dp4a.u32.u32 %r3355, %r3356, %r4189, %r3351;
	// end inline asm
	ld.const.u32 	%r3360, [matrix+3228];
	// begin inline asm
	dp4a.u32.u32 %r3359, %r3360, %r4193, %r3355;
	// end inline asm
	ld.const.u32 	%r3364, [matrix+3232];
	// begin inline asm
	dp4a.u32.u32 %r3363, %r3364, %r4197, %r3359;
	// end inline asm
	ld.const.u32 	%r3368, [matrix+3236];
	// begin inline asm
	dp4a.u32.u32 %r3367, %r3368, %r4201, %r3363;
	// end inline asm
	ld.const.u32 	%r3372, [matrix+3240];
	// begin inline asm
	dp4a.u32.u32 %r3371, %r3372, %r4205, %r3367;
	// end inline asm
	ld.const.u32 	%r3376, [matrix+3244];
	// begin inline asm
	dp4a.u32.u32 %r3375, %r3376, %r4209, %r3371;
	// end inline asm
	ld.const.u32 	%r3380, [matrix+3248];
	// begin inline asm
	dp4a.u32.u32 %r3379, %r3380, %r4213, %r3375;
	// end inline asm
	ld.const.u32 	%r3384, [matrix+3252];
	// begin inline asm
	dp4a.u32.u32 %r3383, %r3384, %r4217, %r3379;
	// end inline asm
	ld.const.u32 	%r3388, [matrix+3256];
	// begin inline asm
	dp4a.u32.u32 %r3387, %r3388, %r4221, %r3383;
	// end inline asm
	ld.const.u32 	%r3392, [matrix+3260];
	// begin inline asm
	dp4a.u32.u32 %r3391, %r3392, %r4225, %r3387;
	// end inline asm
	ld.const.u32 	%r3396, [matrix+3264];
	// begin inline asm
	dp4a.u32.u32 %r3395, %r3396, %r4165, %r4641;
	// end inline asm
	ld.const.u32 	%r3400, [matrix+3268];
	// begin inline asm
	dp4a.u32.u32 %r3399, %r3400, %r4169, %r3395;
	// end inline asm
	ld.const.u32 	%r3404, [matrix+3272];
	// begin inline asm
	dp4a.u32.u32 %r3403, %r3404, %r4173, %r3399;
	// end inline asm
	ld.const.u32 	%r3408, [matrix+3276];
	// begin inline asm
	dp4a.u32.u32 %r3407, %r3408, %r4177, %r3403;
	// end inline asm
	ld.const.u32 	%r3412, [matrix+3280];
	// begin inline asm
	dp4a.u32.u32 %r3411, %r3412, %r4181, %r3407;
	// end inline asm
	ld.const.u32 	%r3416, [matrix+3284];
	// begin inline asm
	dp4a.u32.u32 %r3415, %r3416, %r4185, %r3411;
	// end inline asm
	ld.const.u32 	%r3420, [matrix+3288];
	// begin inline asm
	dp4a.u32.u32 %r3419, %r3420, %r4189, %r3415;
	// end inline asm
	ld.const.u32 	%r3424, [matrix+3292];
	// begin inline asm
	dp4a.u32.u32 %r3423, %r3424, %r4193, %r3419;
	// end inline asm
	ld.const.u32 	%r3428, [matrix+3296];
	// begin inline asm
	dp4a.u32.u32 %r3427, %r3428, %r4197, %r3423;
	// end inline asm
	ld.const.u32 	%r3432, [matrix+3300];
	// begin inline asm
	dp4a.u32.u32 %r3431, %r3432, %r4201, %r3427;
	// end inline asm
	ld.const.u32 	%r3436, [matrix+3304];
	// begin inline asm
	dp4a.u32.u32 %r3435, %r3436, %r4205, %r3431;
	// end inline asm
	ld.const.u32 	%r3440, [matrix+3308];
	// begin inline asm
	dp4a.u32.u32 %r3439, %r3440, %r4209, %r3435;
	// end inline asm
	ld.const.u32 	%r3444, [matrix+3312];
	// begin inline asm
	dp4a.u32.u32 %r3443, %r3444, %r4213, %r3439;
	// end inline asm
	ld.const.u32 	%r3448, [matrix+3316];
	// begin inline asm
	dp4a.u32.u32 %r3447, %r3448, %r4217, %r3443;
	// end inline asm
	ld.const.u32 	%r3452, [matrix+3320];
	// begin inline asm
	dp4a.u32.u32 %r3451, %r3452, %r4221, %r3447;
	// end inline asm
	ld.const.u32 	%r3456, [matrix+3324];
	// begin inline asm
	dp4a.u32.u32 %r3455, %r3456, %r4225, %r3451;
	// end inline asm
	shr.u32 	%r4496, %r3391, 6;
	and.b32  	%r4497, %r4496, 240;
	shr.u32 	%r4498, %r3455, 10;
	or.b32  	%r4499, %r4498, %r4497;
	cvt.u64.u32 	%rd420, %r4499;
	xor.b64  	%rd421, %rd364, %rd420;
	and.b64  	%rd422, %rd668, 255;
	xor.b64  	%rd423, %rd422, %rd419;
	ld.const.u32 	%r3460, [matrix+3328];
	// begin inline asm
	dp4a.u32.u32 %r3459, %r3460, %r4165, %r4641;
	// end inline asm
	ld.const.u32 	%r3464, [matrix+3332];
	// begin inline asm
	dp4a.u32.u32 %r3463, %r3464, %r4169, %r3459;
	// end inline asm
	ld.const.u32 	%r3468, [matrix+3336];
	// begin inline asm
	dp4a.u32.u32 %r3467, %r3468, %r4173, %r3463;
	// end inline asm
	ld.const.u32 	%r3472, [matrix+3340];
	// begin inline asm
	dp4a.u32.u32 %r3471, %r3472, %r4177, %r3467;
	// end inline asm
	ld.const.u32 	%r3476, [matrix+3344];
	// begin inline asm
	dp4a.u32.u32 %r3475, %r3476, %r4181, %r3471;
	// end inline asm
	ld.const.u32 	%r3480, [matrix+3348];
	// begin inline asm
	dp4a.u32.u32 %r3479, %r3480, %r4185, %r3475;
	// end inline asm
	ld.const.u32 	%r3484, [matrix+3352];
	// begin inline asm
	dp4a.u32.u32 %r3483, %r3484, %r4189, %r3479;
	// end inline asm
	ld.const.u32 	%r3488, [matrix+3356];
	// begin inline asm
	dp4a.u32.u32 %r3487, %r3488, %r4193, %r3483;
	// end inline asm
	ld.const.u32 	%r3492, [matrix+3360];
	// begin inline asm
	dp4a.u32.u32 %r3491, %r3492, %r4197, %r3487;
	// end inline asm
	ld.const.u32 	%r3496, [matrix+3364];
	// begin inline asm
	dp4a.u32.u32 %r3495, %r3496, %r4201, %r3491;
	// end inline asm
	ld.const.u32 	%r3500, [matrix+3368];
	// begin inline asm
	dp4a.u32.u32 %r3499, %r3500, %r4205, %r3495;
	// end inline asm
	ld.const.u32 	%r3504, [matrix+3372];
	// begin inline asm
	dp4a.u32.u32 %r3503, %r3504, %r4209, %r3499;
	// end inline asm
	ld.const.u32 	%r3508, [matrix+3376];
	// begin inline asm
	dp4a.u32.u32 %r3507, %r3508, %r4213, %r3503;
	// end inline asm
	ld.const.u32 	%r3512, [matrix+3380];
	// begin inline asm
	dp4a.u32.u32 %r3511, %r3512, %r4217, %r3507;
	// end inline asm
	ld.const.u32 	%r3516, [matrix+3384];
	// begin inline asm
	dp4a.u32.u32 %r3515, %r3516, %r4221, %r3511;
	// end inline asm
	ld.const.u32 	%r3520, [matrix+3388];
	// begin inline asm
	dp4a.u32.u32 %r3519, %r3520, %r4225, %r3515;
	// end inline asm
	ld.const.u32 	%r3524, [matrix+3392];
	// begin inline asm
	dp4a.u32.u32 %r3523, %r3524, %r4165, %r4641;
	// end inline asm
	ld.const.u32 	%r3528, [matrix+3396];
	// begin inline asm
	dp4a.u32.u32 %r3527, %r3528, %r4169, %r3523;
	// end inline asm
	ld.const.u32 	%r3532, [matrix+3400];
	// begin inline asm
	dp4a.u32.u32 %r3531, %r3532, %r4173, %r3527;
	// end inline asm
	ld.const.u32 	%r3536, [matrix+3404];
	// begin inline asm
	dp4a.u32.u32 %r3535, %r3536, %r4177, %r3531;
	// end inline asm
	ld.const.u32 	%r3540, [matrix+3408];
	// begin inline asm
	dp4a.u32.u32 %r3539, %r3540, %r4181, %r3535;
	// end inline asm
	ld.const.u32 	%r3544, [matrix+3412];
	// begin inline asm
	dp4a.u32.u32 %r3543, %r3544, %r4185, %r3539;
	// end inline asm
	ld.const.u32 	%r3548, [matrix+3416];
	// begin inline asm
	dp4a.u32.u32 %r3547, %r3548, %r4189, %r3543;
	// end inline asm
	ld.const.u32 	%r3552, [matrix+3420];
	// begin inline asm
	dp4a.u32.u32 %r3551, %r3552, %r4193, %r3547;
	// end inline asm
	ld.const.u32 	%r3556, [matrix+3424];
	// begin inline asm
	dp4a.u32.u32 %r3555, %r3556, %r4197, %r3551;
	// end inline asm
	ld.const.u32 	%r3560, [matrix+3428];
	// begin inline asm
	dp4a.u32.u32 %r3559, %r3560, %r4201, %r3555;
	// end inline asm
	ld.const.u32 	%r3564, [matrix+3432];
	// begin inline asm
	dp4a.u32.u32 %r3563, %r3564, %r4205, %r3559;
	// end inline asm
	ld.const.u32 	%r3568, [matrix+3436];
	// begin inline asm
	dp4a.u32.u32 %r3567, %r3568, %r4209, %r3563;
	// end inline asm
	ld.const.u32 	%r3572, [matrix+3440];
	// begin inline asm
	dp4a.u32.u32 %r3571, %r3572, %r4213, %r3567;
	// end inline asm
	ld.const.u32 	%r3576, [matrix+3444];
	// begin inline asm
	dp4a.u32.u32 %r3575, %r3576, %r4217, %r3571;
	// end inline asm
	ld.const.u32 	%r3580, [matrix+3448];
	// begin inline asm
	dp4a.u32.u32 %r3579, %r3580, %r4221, %r3575;
	// end inline asm
	ld.const.u32 	%r3584, [matrix+3452];
	// begin inline asm
	dp4a.u32.u32 %r3583, %r3584, %r4225, %r3579;
	// end inline asm
	shr.u32 	%r4500, %r3519, 6;
	and.b32  	%r4501, %r4500, 240;
	shr.u32 	%r4502, %r3583, 10;
	or.b32  	%r4503, %r4502, %r4501;
	cvt.u64.u32 	%rd424, %r4503;
	xor.b64  	%rd425, %rd365, %rd424;
	ld.const.u32 	%r3588, [matrix+3456];
	// begin inline asm
	dp4a.u32.u32 %r3587, %r3588, %r4165, %r4641;
	// end inline asm
	ld.const.u32 	%r3592, [matrix+3460];
	// begin inline asm
	dp4a.u32.u32 %r3591, %r3592, %r4169, %r3587;
	// end inline asm
	ld.const.u32 	%r3596, [matrix+3464];
	// begin inline asm
	dp4a.u32.u32 %r3595, %r3596, %r4173, %r3591;
	// end inline asm
	ld.const.u32 	%r3600, [matrix+3468];
	// begin inline asm
	dp4a.u32.u32 %r3599, %r3600, %r4177, %r3595;
	// end inline asm
	ld.const.u32 	%r3604, [matrix+3472];
	// begin inline asm
	dp4a.u32.u32 %r3603, %r3604, %r4181, %r3599;
	// end inline asm
	ld.const.u32 	%r3608, [matrix+3476];
	// begin inline asm
	dp4a.u32.u32 %r3607, %r3608, %r4185, %r3603;
	// end inline asm
	ld.const.u32 	%r3612, [matrix+3480];
	// begin inline asm
	dp4a.u32.u32 %r3611, %r3612, %r4189, %r3607;
	// end inline asm
	ld.const.u32 	%r3616, [matrix+3484];
	// begin inline asm
	dp4a.u32.u32 %r3615, %r3616, %r4193, %r3611;
	// end inline asm
	ld.const.u32 	%r3620, [matrix+3488];
	// begin inline asm
	dp4a.u32.u32 %r3619, %r3620, %r4197, %r3615;
	// end inline asm
	ld.const.u32 	%r3624, [matrix+3492];
	// begin inline asm
	dp4a.u32.u32 %r3623, %r3624, %r4201, %r3619;
	// end inline asm
	ld.const.u32 	%r3628, [matrix+3496];
	// begin inline asm
	dp4a.u32.u32 %r3627, %r3628, %r4205, %r3623;
	// end inline asm
	ld.const.u32 	%r3632, [matrix+3500];
	// begin inline asm
	dp4a.u32.u32 %r3631, %r3632, %r4209, %r3627;
	// end inline asm
	ld.const.u32 	%r3636, [matrix+3504];
	// begin inline asm
	dp4a.u32.u32 %r3635, %r3636, %r4213, %r3631;
	// end inline asm
	ld.const.u32 	%r3640, [matrix+3508];
	// begin inline asm
	dp4a.u32.u32 %r3639, %r3640, %r4217, %r3635;
	// end inline asm
	ld.const.u32 	%r3644, [matrix+3512];
	// begin inline asm
	dp4a.u32.u32 %r3643, %r3644, %r4221, %r3639;
	// end inline asm
	ld.const.u32 	%r3648, [matrix+3516];
	// begin inline asm
	dp4a.u32.u32 %r3647, %r3648, %r4225, %r3643;
	// end inline asm
	ld.const.u32 	%r3652, [matrix+3520];
	// begin inline asm
	dp4a.u32.u32 %r3651, %r3652, %r4165, %r4641;
	// end inline asm
	ld.const.u32 	%r3656, [matrix+3524];
	// begin inline asm
	dp4a.u32.u32 %r3655, %r3656, %r4169, %r3651;
	// end inline asm
	ld.const.u32 	%r3660, [matrix+3528];
	// begin inline asm
	dp4a.u32.u32 %r3659, %r3660, %r4173, %r3655;
	// end inline asm
	ld.const.u32 	%r3664, [matrix+3532];
	// begin inline asm
	dp4a.u32.u32 %r3663, %r3664, %r4177, %r3659;
	// end inline asm
	ld.const.u32 	%r3668, [matrix+3536];
	// begin inline asm
	dp4a.u32.u32 %r3667, %r3668, %r4181, %r3663;
	// end inline asm
	ld.const.u32 	%r3672, [matrix+3540];
	// begin inline asm
	dp4a.u32.u32 %r3671, %r3672, %r4185, %r3667;
	// end inline asm
	ld.const.u32 	%r3676, [matrix+3544];
	// begin inline asm
	dp4a.u32.u32 %r3675, %r3676, %r4189, %r3671;
	// end inline asm
	ld.const.u32 	%r3680, [matrix+3548];
	// begin inline asm
	dp4a.u32.u32 %r3679, %r3680, %r4193, %r3675;
	// end inline asm
	ld.const.u32 	%r3684, [matrix+3552];
	// begin inline asm
	dp4a.u32.u32 %r3683, %r3684, %r4197, %r3679;
	// end inline asm
	ld.const.u32 	%r3688, [matrix+3556];
	// begin inline asm
	dp4a.u32.u32 %r3687, %r3688, %r4201, %r3683;
	// end inline asm
	ld.const.u32 	%r3692, [matrix+3560];
	// begin inline asm
	dp4a.u32.u32 %r3691, %r3692, %r4205, %r3687;
	// end inline asm
	ld.const.u32 	%r3696, [matrix+3564];
	// begin inline asm
	dp4a.u32.u32 %r3695, %r3696, %r4209, %r3691;
	// end inline asm
	ld.const.u32 	%r3700, [matrix+3568];
	// begin inline asm
	dp4a.u32.u32 %r3699, %r3700, %r4213, %r3695;
	// end inline asm
	ld.const.u32 	%r3704, [matrix+3572];
	// begin inline asm
	dp4a.u32.u32 %r3703, %r3704, %r4217, %r3699;
	// end inline asm
	ld.const.u32 	%r3708, [matrix+3576];
	// begin inline asm
	dp4a.u32.u32 %r3707, %r3708, %r4221, %r3703;
	// end inline asm
	ld.const.u32 	%r3712, [matrix+3580];
	// begin inline asm
	dp4a.u32.u32 %r3711, %r3712, %r4225, %r3707;
	// end inline asm
	shr.u32 	%r4504, %r3647, 6;
	and.b32  	%r4505, %r4504, 240;
	shr.u32 	%r4506, %r3711, 10;
	or.b32  	%r4507, %r4506, %r4505;
	cvt.u64.u32 	%rd426, %r4507;
	xor.b64  	%rd427, %rd366, %rd426;
	ld.const.u32 	%r3716, [matrix+3584];
	// begin inline asm
	dp4a.u32.u32 %r3715, %r3716, %r4165, %r4641;
	// end inline asm
	ld.const.u32 	%r3720, [matrix+3588];
	// begin inline asm
	dp4a.u32.u32 %r3719, %r3720, %r4169, %r3715;
	// end inline asm
	ld.const.u32 	%r3724, [matrix+3592];
	// begin inline asm
	dp4a.u32.u32 %r3723, %r3724, %r4173, %r3719;
	// end inline asm
	ld.const.u32 	%r3728, [matrix+3596];
	// begin inline asm
	dp4a.u32.u32 %r3727, %r3728, %r4177, %r3723;
	// end inline asm
	ld.const.u32 	%r3732, [matrix+3600];
	// begin inline asm
	dp4a.u32.u32 %r3731, %r3732, %r4181, %r3727;
	// end inline asm
	ld.const.u32 	%r3736, [matrix+3604];
	// begin inline asm
	dp4a.u32.u32 %r3735, %r3736, %r4185, %r3731;
	// end inline asm
	ld.const.u32 	%r3740, [matrix+3608];
	// begin inline asm
	dp4a.u32.u32 %r3739, %r3740, %r4189, %r3735;
	// end inline asm
	ld.const.u32 	%r3744, [matrix+3612];
	// begin inline asm
	dp4a.u32.u32 %r3743, %r3744, %r4193, %r3739;
	// end inline asm
	ld.const.u32 	%r3748, [matrix+3616];
	// begin inline asm
	dp4a.u32.u32 %r3747, %r3748, %r4197, %r3743;
	// end inline asm
	ld.const.u32 	%r3752, [matrix+3620];
	// begin inline asm
	dp4a.u32.u32 %r3751, %r3752, %r4201, %r3747;
	// end inline asm
	ld.const.u32 	%r3756, [matrix+3624];
	// begin inline asm
	dp4a.u32.u32 %r3755, %r3756, %r4205, %r3751;
	// end inline asm
	ld.const.u32 	%r3760, [matrix+3628];
	// begin inline asm
	dp4a.u32.u32 %r3759, %r3760, %r4209, %r3755;
	// end inline asm
	ld.const.u32 	%r3764, [matrix+3632];
	// begin inline asm
	dp4a.u32.u32 %r3763, %r3764, %r4213, %r3759;
	// end inline asm
	ld.const.u32 	%r3768, [matrix+3636];
	// begin inline asm
	dp4a.u32.u32 %r3767, %r3768, %r4217, %r3763;
	// end inline asm
	ld.const.u32 	%r3772, [matrix+3640];
	// begin inline asm
	dp4a.u32.u32 %r3771, %r3772, %r4221, %r3767;
	// end inline asm
	ld.const.u32 	%r3776, [matrix+3644];
	// begin inline asm
	dp4a.u32.u32 %r3775, %r3776, %r4225, %r3771;
	// end inline asm
	ld.const.u32 	%r3780, [matrix+3648];
	// begin inline asm
	dp4a.u32.u32 %r3779, %r3780, %r4165, %r4641;
	// end inline asm
	ld.const.u32 	%r3784, [matrix+3652];
	// begin inline asm
	dp4a.u32.u32 %r3783, %r3784, %r4169, %r3779;
	// end inline asm
	ld.const.u32 	%r3788, [matrix+3656];
	// begin inline asm
	dp4a.u32.u32 %r3787, %r3788, %r4173, %r3783;
	// end inline asm
	ld.const.u32 	%r3792, [matrix+3660];
	// begin inline asm
	dp4a.u32.u32 %r3791, %r3792, %r4177, %r3787;
	// end inline asm
	ld.const.u32 	%r3796, [matrix+3664];
	// begin inline asm
	dp4a.u32.u32 %r3795, %r3796, %r4181, %r3791;
	// end inline asm
	ld.const.u32 	%r3800, [matrix+3668];
	// begin inline asm
	dp4a.u32.u32 %r3799, %r3800, %r4185, %r3795;
	// end inline asm
	ld.const.u32 	%r3804, [matrix+3672];
	// begin inline asm
	dp4a.u32.u32 %r3803, %r3804, %r4189, %r3799;
	// end inline asm
	ld.const.u32 	%r3808, [matrix+3676];
	// begin inline asm
	dp4a.u32.u32 %r3807, %r3808, %r4193, %r3803;
	// end inline asm
	ld.const.u32 	%r3812, [matrix+3680];
	// begin inline asm
	dp4a.u32.u32 %r3811, %r3812, %r4197, %r3807;
	// end inline asm
	ld.const.u32 	%r3816, [matrix+3684];
	// begin inline asm
	dp4a.u32.u32 %r3815, %r3816, %r4201, %r3811;
	// end inline asm
	ld.const.u32 	%r3820, [matrix+3688];
	// begin inline asm
	dp4a.u32.u32 %r3819, %r3820, %r4205, %r3815;
	// end inline asm
	ld.const.u32 	%r3824, [matrix+3692];
	// begin inline asm
	dp4a.u32.u32 %r3823, %r3824, %r4209, %r3819;
	// end inline asm
	ld.const.u32 	%r3828, [matrix+3696];
	// begin inline asm
	dp4a.u32.u32 %r3827, %r3828, %r4213, %r3823;
	// end inline asm
	ld.const.u32 	%r3832, [matrix+3700];
	// begin inline asm
	dp4a.u32.u32 %r3831, %r3832, %r4217, %r3827;
	// end inline asm
	ld.const.u32 	%r3836, [matrix+3704];
	// begin inline asm
	dp4a.u32.u32 %r3835, %r3836, %r4221, %r3831;
	// end inline asm
	ld.const.u32 	%r3840, [matrix+3708];
	// begin inline asm
	dp4a.u32.u32 %r3839, %r3840, %r4225, %r3835;
	// end inline asm
	shr.u32 	%r4508, %r3775, 6;
	and.b32  	%r4509, %r4508, 240;
	shr.u32 	%r4510, %r3839, 10;
	or.b32  	%r4511, %r4510, %r4509;
	cvt.u64.u32 	%rd428, %r4511;
	xor.b64  	%rd429, %rd367, %rd428;
	ld.const.u32 	%r3844, [matrix+3712];
	// begin inline asm
	dp4a.u32.u32 %r3843, %r3844, %r4165, %r4641;
	// end inline asm
	ld.const.u32 	%r3848, [matrix+3716];
	// begin inline asm
	dp4a.u32.u32 %r3847, %r3848, %r4169, %r3843;
	// end inline asm
	ld.const.u32 	%r3852, [matrix+3720];
	// begin inline asm
	dp4a.u32.u32 %r3851, %r3852, %r4173, %r3847;
	// end inline asm
	ld.const.u32 	%r3856, [matrix+3724];
	// begin inline asm
	dp4a.u32.u32 %r3855, %r3856, %r4177, %r3851;
	// end inline asm
	ld.const.u32 	%r3860, [matrix+3728];
	// begin inline asm
	dp4a.u32.u32 %r3859, %r3860, %r4181, %r3855;
	// end inline asm
	ld.const.u32 	%r3864, [matrix+3732];
	// begin inline asm
	dp4a.u32.u32 %r3863, %r3864, %r4185, %r3859;
	// end inline asm
	ld.const.u32 	%r3868, [matrix+3736];
	// begin inline asm
	dp4a.u32.u32 %r3867, %r3868, %r4189, %r3863;
	// end inline asm
	ld.const.u32 	%r3872, [matrix+3740];
	// begin inline asm
	dp4a.u32.u32 %r3871, %r3872, %r4193, %r3867;
	// end inline asm
	ld.const.u32 	%r3876, [matrix+3744];
	// begin inline asm
	dp4a.u32.u32 %r3875, %r3876, %r4197, %r3871;
	// end inline asm
	ld.const.u32 	%r3880, [matrix+3748];
	// begin inline asm
	dp4a.u32.u32 %r3879, %r3880, %r4201, %r3875;
	// end inline asm
	ld.const.u32 	%r3884, [matrix+3752];
	// begin inline asm
	dp4a.u32.u32 %r3883, %r3884, %r4205, %r3879;
	// end inline asm
	ld.const.u32 	%r3888, [matrix+3756];
	// begin inline asm
	dp4a.u32.u32 %r3887, %r3888, %r4209, %r3883;
	// end inline asm
	ld.const.u32 	%r3892, [matrix+3760];
	// begin inline asm
	dp4a.u32.u32 %r3891, %r3892, %r4213, %r3887;
	// end inline asm
	ld.const.u32 	%r3896, [matrix+3764];
	// begin inline asm
	dp4a.u32.u32 %r3895, %r3896, %r4217, %r3891;
	// end inline asm
	ld.const.u32 	%r3900, [matrix+3768];
	// begin inline asm
	dp4a.u32.u32 %r3899, %r3900, %r4221, %r3895;
	// end inline asm
	ld.const.u32 	%r3904, [matrix+3772];
	// begin inline asm
	dp4a.u32.u32 %r3903, %r3904, %r4225, %r3899;
	// end inline asm
	ld.const.u32 	%r3908, [matrix+3776];
	// begin inline asm
	dp4a.u32.u32 %r3907, %r3908, %r4165, %r4641;
	// end inline asm
	ld.const.u32 	%r3912, [matrix+3780];
	// begin inline asm
	dp4a.u32.u32 %r3911, %r3912, %r4169, %r3907;
	// end inline asm
	ld.const.u32 	%r3916, [matrix+3784];
	// begin inline asm
	dp4a.u32.u32 %r3915, %r3916, %r4173, %r3911;
	// end inline asm
	ld.const.u32 	%r3920, [matrix+3788];
	// begin inline asm
	dp4a.u32.u32 %r3919, %r3920, %r4177, %r3915;
	// end inline asm
	ld.const.u32 	%r3924, [matrix+3792];
	// begin inline asm
	dp4a.u32.u32 %r3923, %r3924, %r4181, %r3919;
	// end inline asm
	ld.const.u32 	%r3928, [matrix+3796];
	// begin inline asm
	dp4a.u32.u32 %r3927, %r3928, %r4185, %r3923;
	// end inline asm
	ld.const.u32 	%r3932, [matrix+3800];
	// begin inline asm
	dp4a.u32.u32 %r3931, %r3932, %r4189, %r3927;
	// end inline asm
	ld.const.u32 	%r3936, [matrix+3804];
	// begin inline asm
	dp4a.u32.u32 %r3935, %r3936, %r4193, %r3931;
	// end inline asm
	ld.const.u32 	%r3940, [matrix+3808];
	// begin inline asm
	dp4a.u32.u32 %r3939, %r3940, %r4197, %r3935;
	// end inline asm
	ld.const.u32 	%r3944, [matrix+3812];
	// begin inline asm
	dp4a.u32.u32 %r3943, %r3944, %r4201, %r3939;
	// end inline asm
	ld.const.u32 	%r3948, [matrix+3816];
	// begin inline asm
	dp4a.u32.u32 %r3947, %r3948, %r4205, %r3943;
	// end inline asm
	ld.const.u32 	%r3952, [matrix+3820];
	// begin inline asm
	dp4a.u32.u32 %r3951, %r3952, %r4209, %r3947;
	// end inline asm
	ld.const.u32 	%r3956, [matrix+3824];
	// begin inline asm
	dp4a.u32.u32 %r3955, %r3956, %r4213, %r3951;
	// end inline asm
	ld.const.u32 	%r3960, [matrix+3828];
	// begin inline asm
	dp4a.u32.u32 %r3959, %r3960, %r4217, %r3955;
	// end inline asm
	ld.const.u32 	%r3964, [matrix+3832];
	// begin inline asm
	dp4a.u32.u32 %r3963, %r3964, %r4221, %r3959;
	// end inline asm
	ld.const.u32 	%r3968, [matrix+3836];
	// begin inline asm
	dp4a.u32.u32 %r3967, %r3968, %r4225, %r3963;
	// end inline asm
	shr.u32 	%r4512, %r3903, 6;
	and.b32  	%r4513, %r4512, 240;
	shr.u32 	%r4514, %r3967, 10;
	or.b32  	%r4515, %r4514, %r4513;
	cvt.u64.u32 	%rd430, %r4515;
	xor.b64  	%rd431, %rd369, %rd430;
	ld.const.u32 	%r3972, [matrix+3840];
	// begin inline asm
	dp4a.u32.u32 %r3971, %r3972, %r4165, %r4641;
	// end inline asm
	ld.const.u32 	%r3976, [matrix+3844];
	// begin inline asm
	dp4a.u32.u32 %r3975, %r3976, %r4169, %r3971;
	// end inline asm
	ld.const.u32 	%r3980, [matrix+3848];
	// begin inline asm
	dp4a.u32.u32 %r3979, %r3980, %r4173, %r3975;
	// end inline asm
	ld.const.u32 	%r3984, [matrix+3852];
	// begin inline asm
	dp4a.u32.u32 %r3983, %r3984, %r4177, %r3979;
	// end inline asm
	ld.const.u32 	%r3988, [matrix+3856];
	// begin inline asm
	dp4a.u32.u32 %r3987, %r3988, %r4181, %r3983;
	// end inline asm
	ld.const.u32 	%r3992, [matrix+3860];
	// begin inline asm
	dp4a.u32.u32 %r3991, %r3992, %r4185, %r3987;
	// end inline asm
	ld.const.u32 	%r3996, [matrix+3864];
	// begin inline asm
	dp4a.u32.u32 %r3995, %r3996, %r4189, %r3991;
	// end inline asm
	ld.const.u32 	%r4000, [matrix+3868];
	// begin inline asm
	dp4a.u32.u32 %r3999, %r4000, %r4193, %r3995;
	// end inline asm
	ld.const.u32 	%r4004, [matrix+3872];
	// begin inline asm
	dp4a.u32.u32 %r4003, %r4004, %r4197, %r3999;
	// end inline asm
	ld.const.u32 	%r4008, [matrix+3876];
	// begin inline asm
	dp4a.u32.u32 %r4007, %r4008, %r4201, %r4003;
	// end inline asm
	ld.const.u32 	%r4012, [matrix+3880];
	// begin inline asm
	dp4a.u32.u32 %r4011, %r4012, %r4205, %r4007;
	// end inline asm
	ld.const.u32 	%r4016, [matrix+3884];
	// begin inline asm
	dp4a.u32.u32 %r4015, %r4016, %r4209, %r4011;
	// end inline asm
	ld.const.u32 	%r4020, [matrix+3888];
	// begin inline asm
	dp4a.u32.u32 %r4019, %r4020, %r4213, %r4015;
	// end inline asm
	ld.const.u32 	%r4024, [matrix+3892];
	// begin inline asm
	dp4a.u32.u32 %r4023, %r4024, %r4217, %r4019;
	// end inline asm
	ld.const.u32 	%r4028, [matrix+3896];
	// begin inline asm
	dp4a.u32.u32 %r4027, %r4028, %r4221, %r4023;
	// end inline asm
	ld.const.u32 	%r4032, [matrix+3900];
	// begin inline asm
	dp4a.u32.u32 %r4031, %r4032, %r4225, %r4027;
	// end inline asm
	ld.const.u32 	%r4036, [matrix+3904];
	// begin inline asm
	dp4a.u32.u32 %r4035, %r4036, %r4165, %r4641;
	// end inline asm
	ld.const.u32 	%r4040, [matrix+3908];
	// begin inline asm
	dp4a.u32.u32 %r4039, %r4040, %r4169, %r4035;
	// end inline asm
	ld.const.u32 	%r4044, [matrix+3912];
	// begin inline asm
	dp4a.u32.u32 %r4043, %r4044, %r4173, %r4039;
	// end inline asm
	ld.const.u32 	%r4048, [matrix+3916];
	// begin inline asm
	dp4a.u32.u32 %r4047, %r4048, %r4177, %r4043;
	// end inline asm
	ld.const.u32 	%r4052, [matrix+3920];
	// begin inline asm
	dp4a.u32.u32 %r4051, %r4052, %r4181, %r4047;
	// end inline asm
	ld.const.u32 	%r4056, [matrix+3924];
	// begin inline asm
	dp4a.u32.u32 %r4055, %r4056, %r4185, %r4051;
	// end inline asm
	ld.const.u32 	%r4060, [matrix+3928];
	// begin inline asm
	dp4a.u32.u32 %r4059, %r4060, %r4189, %r4055;
	// end inline asm
	ld.const.u32 	%r4064, [matrix+3932];
	// begin inline asm
	dp4a.u32.u32 %r4063, %r4064, %r4193, %r4059;
	// end inline asm
	ld.const.u32 	%r4068, [matrix+3936];
	// begin inline asm
	dp4a.u32.u32 %r4067, %r4068, %r4197, %r4063;
	// end inline asm
	ld.const.u32 	%r4072, [matrix+3940];
	// begin inline asm
	dp4a.u32.u32 %r4071, %r4072, %r4201, %r4067;
	// end inline asm
	ld.const.u32 	%r4076, [matrix+3944];
	// begin inline asm
	dp4a.u32.u32 %r4075, %r4076, %r4205, %r4071;
	// end inline asm
	ld.const.u32 	%r4080, [matrix+3948];
	// begin inline asm
	dp4a.u32.u32 %r4079, %r4080, %r4209, %r4075;
	// end inline asm
	ld.const.u32 	%r4084, [matrix+3952];
	// begin inline asm
	dp4a.u32.u32 %r4083, %r4084, %r4213, %r4079;
	// end inline asm
	ld.const.u32 	%r4088, [matrix+3956];
	// begin inline asm
	dp4a.u32.u32 %r4087, %r4088, %r4217, %r4083;
	// end inline asm
	ld.const.u32 	%r4092, [matrix+3960];
	// begin inline asm
	dp4a.u32.u32 %r4091, %r4092, %r4221, %r4087;
	// end inline asm
	ld.const.u32 	%r4096, [matrix+3964];
	// begin inline asm
	dp4a.u32.u32 %r4095, %r4096, %r4225, %r4091;
	// end inline asm
	shr.u32 	%r4516, %r4031, 6;
	and.b32  	%r4517, %r4516, 240;
	shr.u32 	%r4518, %r4095, 10;
	or.b32  	%r4519, %r4518, %r4517;
	cvt.u64.u32 	%rd432, %r4519;
	xor.b64  	%rd433, %rd371, %rd432;
	ld.const.u32 	%r4100, [matrix+3968];
	// begin inline asm
	dp4a.u32.u32 %r4099, %r4100, %r4165, %r4641;
	// end inline asm
	ld.const.u32 	%r4104, [matrix+3972];
	// begin inline asm
	dp4a.u32.u32 %r4103, %r4104, %r4169, %r4099;
	// end inline asm
	ld.const.u32 	%r4108, [matrix+3976];
	// begin inline asm
	dp4a.u32.u32 %r4107, %r4108, %r4173, %r4103;
	// end inline asm
	ld.const.u32 	%r4112, [matrix+3980];
	// begin inline asm
	dp4a.u32.u32 %r4111, %r4112, %r4177, %r4107;
	// end inline asm
	ld.const.u32 	%r4116, [matrix+3984];
	// begin inline asm
	dp4a.u32.u32 %r4115, %r4116, %r4181, %r4111;
	// end inline asm
	ld.const.u32 	%r4120, [matrix+3988];
	// begin inline asm
	dp4a.u32.u32 %r4119, %r4120, %r4185, %r4115;
	// end inline asm
	ld.const.u32 	%r4124, [matrix+3992];
	// begin inline asm
	dp4a.u32.u32 %r4123, %r4124, %r4189, %r4119;
	// end inline asm
	ld.const.u32 	%r4128, [matrix+3996];
	// begin inline asm
	dp4a.u32.u32 %r4127, %r4128, %r4193, %r4123;
	// end inline asm
	ld.const.u32 	%r4132, [matrix+4000];
	// begin inline asm
	dp4a.u32.u32 %r4131, %r4132, %r4197, %r4127;
	// end inline asm
	ld.const.u32 	%r4136, [matrix+4004];
	// begin inline asm
	dp4a.u32.u32 %r4135, %r4136, %r4201, %r4131;
	// end inline asm
	ld.const.u32 	%r4140, [matrix+4008];
	// begin inline asm
	dp4a.u32.u32 %r4139, %r4140, %r4205, %r4135;
	// end inline asm
	ld.const.u32 	%r4144, [matrix+4012];
	// begin inline asm
	dp4a.u32.u32 %r4143, %r4144, %r4209, %r4139;
	// end inline asm
	ld.const.u32 	%r4148, [matrix+4016];
	// begin inline asm
	dp4a.u32.u32 %r4147, %r4148, %r4213, %r4143;
	// end inline asm
	ld.const.u32 	%r4152, [matrix+4020];
	// begin inline asm
	dp4a.u32.u32 %r4151, %r4152, %r4217, %r4147;
	// end inline asm
	ld.const.u32 	%r4156, [matrix+4024];
	// begin inline asm
	dp4a.u32.u32 %r4155, %r4156, %r4221, %r4151;
	// end inline asm
	ld.const.u32 	%r4160, [matrix+4028];
	// begin inline asm
	dp4a.u32.u32 %r4159, %r4160, %r4225, %r4155;
	// end inline asm
	ld.const.u32 	%r4164, [matrix+4032];
	// begin inline asm
	dp4a.u32.u32 %r4163, %r4164, %r4165, %r4641;
	// end inline asm
	ld.const.u32 	%r4168, [matrix+4036];
	// begin inline asm
	dp4a.u32.u32 %r4167, %r4168, %r4169, %r4163;
	// end inline asm
	ld.const.u32 	%r4172, [matrix+4040];
	// begin inline asm
	dp4a.u32.u32 %r4171, %r4172, %r4173, %r4167;
	// end inline asm
	ld.const.u32 	%r4176, [matrix+4044];
	// begin inline asm
	dp4a.u32.u32 %r4175, %r4176, %r4177, %r4171;
	// end inline asm
	ld.const.u32 	%r4180, [matrix+4048];
	// begin inline asm
	dp4a.u32.u32 %r4179, %r4180, %r4181, %r4175;
	// end inline asm
	ld.const.u32 	%r4184, [matrix+4052];
	// begin inline asm
	dp4a.u32.u32 %r4183, %r4184, %r4185, %r4179;
	// end inline asm
	ld.const.u32 	%r4188, [matrix+4056];
	// begin inline asm
	dp4a.u32.u32 %r4187, %r4188, %r4189, %r4183;
	// end inline asm
	ld.const.u32 	%r4192, [matrix+4060];
	// begin inline asm
	dp4a.u32.u32 %r4191, %r4192, %r4193, %r4187;
	// end inline asm
	ld.const.u32 	%r4196, [matrix+4064];
	// begin inline asm
	dp4a.u32.u32 %r4195, %r4196, %r4197, %r4191;
	// end inline asm
	ld.const.u32 	%r4200, [matrix+4068];
	// begin inline asm
	dp4a.u32.u32 %r4199, %r4200, %r4201, %r4195;
	// end inline asm
	ld.const.u32 	%r4204, [matrix+4072];
	// begin inline asm
	dp4a.u32.u32 %r4203, %r4204, %r4205, %r4199;
	// end inline asm
	ld.const.u32 	%r4208, [matrix+4076];
	// begin inline asm
	dp4a.u32.u32 %r4207, %r4208, %r4209, %r4203;
	// end inline asm
	ld.const.u32 	%r4212, [matrix+4080];
	// begin inline asm
	dp4a.u32.u32 %r4211, %r4212, %r4213, %r4207;
	// end inline asm
	ld.const.u32 	%r4216, [matrix+4084];
	// begin inline asm
	dp4a.u32.u32 %r4215, %r4216, %r4217, %r4211;
	// end inline asm
	ld.const.u32 	%r4220, [matrix+4088];
	// begin inline asm
	dp4a.u32.u32 %r4219, %r4220, %r4221, %r4215;
	// end inline asm
	ld.const.u32 	%r4224, [matrix+4092];
	// begin inline asm
	dp4a.u32.u32 %r4223, %r4224, %r4225, %r4219;
	// end inline asm
	shr.u32 	%r4520, %r4159, 6;
	and.b32  	%r4521, %r4520, 240;
	shr.u32 	%r4522, %r4223, 10;
	or.b32  	%r4523, %r4522, %r4521;
	cvt.u64.u32 	%rd434, %r4523;
	shl.b64 	%rd435, %rd434, 56;
	xor.b64  	%rd436, %rd340, %rd388;
	shl.b64 	%rd437, %rd381, 24;
	and.b64  	%rd438, %rd437, 4278190080;
	shl.b64 	%rd439, %rd379, 16;
	and.b64  	%rd440, %rd439, 16711680;
	shl.b64 	%rd441, %rd377, 8;
	and.b64  	%rd442, %rd441, 65280;
	xor.b64  	%rd443, %rd347, %rd403;
	shl.b64 	%rd444, %rd396, 24;
	and.b64  	%rd445, %rd444, 4278190080;
	shl.b64 	%rd446, %rd394, 16;
	and.b64  	%rd447, %rd446, 16711680;
	shl.b64 	%rd448, %rd392, 8;
	and.b64  	%rd449, %rd448, 65280;
	xor.b64  	%rd450, %rd354, %rd418;
	shl.b64 	%rd451, %rd411, 24;
	and.b64  	%rd452, %rd451, 4278190080;
	shl.b64 	%rd453, %rd409, 16;
	and.b64  	%rd454, %rd453, 16711680;
	shl.b64 	%rd455, %rd407, 8;
	and.b64  	%rd456, %rd455, 65280;
	and.b64  	%rd457, %rd668, -72057594037927936;
	xor.b64  	%rd458, %rd457, %rd435;
	shl.b64 	%rd459, %rd436, 56;
	shl.b64 	%rd460, %rd387, 48;
	and.b64  	%rd461, %rd460, 71776119061217280;
	or.b64  	%rd462, %rd459, %rd461;
	shl.b64 	%rd463, %rd385, 40;
	and.b64  	%rd464, %rd463, 280375465082880;
	or.b64  	%rd465, %rd462, %rd464;
	shl.b64 	%rd466, %rd383, 32;
	and.b64  	%rd467, %rd466, 1095216660480;
	or.b64  	%rd468, %rd465, %rd467;
	or.b64  	%rd469, %rd468, %rd438;
	or.b64  	%rd470, %rd469, %rd440;
	and.b64  	%rd471, %rd375, 255;
	or.b64  	%rd472, %rd470, %rd442;
	or.b64  	%rd473, %rd472, %rd471;
	xor.b64  	%rd124, %rd473, 4239941492252378377;
	shl.b64 	%rd474, %rd443, 56;
	shl.b64 	%rd475, %rd402, 48;
	and.b64  	%rd476, %rd475, 71776119061217280;
	or.b64  	%rd477, %rd474, %rd476;
	shl.b64 	%rd478, %rd400, 40;
	and.b64  	%rd479, %rd478, 280375465082880;
	or.b64  	%rd480, %rd477, %rd479;
	shl.b64 	%rd481, %rd398, 32;
	and.b64  	%rd482, %rd481, 1095216660480;
	or.b64  	%rd483, %rd480, %rd482;
	or.b64  	%rd484, %rd483, %rd445;
	or.b64  	%rd485, %rd484, %rd447;
	and.b64  	%rd486, %rd390, 255;
	or.b64  	%rd487, %rd485, %rd449;
	or.b64  	%rd488, %rd487, %rd486;
	xor.b64  	%rd704, %rd488, 8746723911537738262;
	shl.b64 	%rd489, %rd450, 56;
	shl.b64 	%rd490, %rd417, 48;
	and.b64  	%rd491, %rd490, 71776119061217280;
	or.b64  	%rd492, %rd489, %rd491;
	shl.b64 	%rd493, %rd415, 40;
	and.b64  	%rd494, %rd493, 280375465082880;
	or.b64  	%rd495, %rd492, %rd494;
	shl.b64 	%rd496, %rd413, 32;
	and.b64  	%rd497, %rd496, 1095216660480;
	or.b64  	%rd498, %rd495, %rd497;
	or.b64  	%rd499, %rd498, %rd452;
	or.b64  	%rd500, %rd499, %rd454;
	and.b64  	%rd501, %rd405, 255;
	or.b64  	%rd502, %rd500, %rd456;
	or.b64  	%rd503, %rd502, %rd501;
	xor.b64  	%rd699, %rd503, 8796936657246353646;
	shl.b64 	%rd504, %rd433, 48;
	and.b64  	%rd505, %rd504, 71776119061217280;
	or.b64  	%rd506, %rd458, %rd505;
	shl.b64 	%rd507, %rd431, 40;
	and.b64  	%rd508, %rd507, 280375465082880;
	or.b64  	%rd509, %rd506, %rd508;
	shl.b64 	%rd510, %rd429, 32;
	and.b64  	%rd511, %rd510, 1095216660480;
	or.b64  	%rd512, %rd509, %rd511;
	shl.b64 	%rd513, %rd427, 24;
	and.b64  	%rd514, %rd513, 4278190080;
	or.b64  	%rd515, %rd512, %rd514;
	shl.b64 	%rd516, %rd425, 16;
	and.b64  	%rd517, %rd516, 16711680;
	shl.b64 	%rd518, %rd421, 8;
	and.b64  	%rd519, %rd518, 65280;
	or.b64  	%rd520, %rd515, %rd517;
	or.b64  	%rd521, %rd520, %rd519;
	or.b64  	%rd522, %rd521, %rd423;
	xor.b64  	%rd694, %rd522, 1272090201925444760;
	mov.u64 	%rd708, 8270816933120786537;
	mov.u64 	%rd707, -850687345431043546;
	mov.u64 	%rd706, 8596393687355028144;
	mov.u64 	%rd705, -4073852189716399785;
	mov.u64 	%rd703, -4539347866060507718;
	mov.u64 	%rd702, -3233781605604422593;
	mov.u64 	%rd701, 570094237299545110;
	mov.u64 	%rd700, 5171152063242093102;
	mov.u64 	%rd698, 6782861118970774626;
	mov.u64 	%rd697, 7812475424661425213;
	mov.u64 	%rd696, 9119540418498120711;
	mov.u64 	%rd695, -7873636174015165430;
	mov.u64 	%rd693, -9207053471590684088;
	mov.u64 	%rd692, 3370482334374859748;
	mov.u64 	%rd691, -1544774801229058759;
	mov.u64 	%rd690, 6096431547456407061;
	mov.u64 	%rd689, -1792185402154627366;
	mov.u64 	%rd688, -6864424130110145268;
	mov.u64 	%rd687, 5690099369266491460;
	mov.u64 	%rd686, -5074726839974049192;
	mov.u64 	%rd685, 1592359455985097269;
	mov.u64 	%rd684, RC;

$L__BB0_9:
	xor.b64  	%rd523, %rd708, %rd124;
	xor.b64  	%rd524, %rd523, %rd707;
	xor.b64  	%rd525, %rd524, %rd706;
	xor.b64  	%rd526, %rd525, %rd705;
	xor.b64  	%rd527, %rd703, %rd704;
	xor.b64  	%rd528, %rd527, %rd702;
	xor.b64  	%rd529, %rd528, %rd701;
	xor.b64  	%rd530, %rd529, %rd700;
	xor.b64  	%rd531, %rd698, %rd699;
	xor.b64  	%rd532, %rd531, %rd697;
	xor.b64  	%rd533, %rd532, %rd696;
	xor.b64  	%rd534, %rd533, %rd695;
	xor.b64  	%rd535, %rd693, %rd694;
	xor.b64  	%rd536, %rd535, %rd692;
	xor.b64  	%rd537, %rd536, %rd691;
	xor.b64  	%rd538, %rd537, %rd690;
	xor.b64  	%rd539, %rd688, %rd689;
	xor.b64  	%rd540, %rd539, %rd687;
	xor.b64  	%rd541, %rd540, %rd686;
	xor.b64  	%rd542, %rd541, %rd685;
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r4524}, %rd530;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r4525,%dummy}, %rd530;
	}
	shf.l.wrap.b32 	%r4526, %r4525, %r4524, 1;
	shf.l.wrap.b32 	%r4527, %r4524, %r4525, 1;
	mov.b64 	%rd543, {%r4527, %r4526};
	xor.b64  	%rd544, %rd542, %rd543;
	xor.b64  	%rd545, %rd544, %rd124;
	xor.b64  	%rd546, %rd708, %rd544;
	xor.b64  	%rd547, %rd707, %rd544;
	xor.b64  	%rd548, %rd706, %rd544;
	xor.b64  	%rd549, %rd705, %rd544;
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r4528}, %rd534;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r4529,%dummy}, %rd534;
	}
	shf.l.wrap.b32 	%r4530, %r4529, %r4528, 1;
	shf.l.wrap.b32 	%r4531, %r4528, %r4529, 1;
	mov.b64 	%rd550, {%r4531, %r4530};
	xor.b64  	%rd551, %rd550, %rd526;
	xor.b64  	%rd552, %rd704, %rd551;
	xor.b64  	%rd553, %rd703, %rd551;
	xor.b64  	%rd554, %rd702, %rd551;
	xor.b64  	%rd555, %rd701, %rd551;
	xor.b64  	%rd556, %rd700, %rd551;
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r4532}, %rd538;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r4533,%dummy}, %rd538;
	}
	shf.l.wrap.b32 	%r4534, %r4533, %r4532, 1;
	shf.l.wrap.b32 	%r4535, %r4532, %r4533, 1;
	mov.b64 	%rd557, {%r4535, %r4534};
	xor.b64  	%rd558, %rd557, %rd530;
	xor.b64  	%rd559, %rd699, %rd558;
	xor.b64  	%rd560, %rd698, %rd558;
	xor.b64  	%rd561, %rd697, %rd558;
	xor.b64  	%rd562, %rd696, %rd558;
	xor.b64  	%rd563, %rd695, %rd558;
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r4536}, %rd542;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r4537,%dummy}, %rd542;
	}
	shf.l.wrap.b32 	%r4538, %r4537, %r4536, 1;
	shf.l.wrap.b32 	%r4539, %r4536, %r4537, 1;
	mov.b64 	%rd564, {%r4539, %r4538};
	xor.b64  	%rd565, %rd564, %rd534;
	xor.b64  	%rd566, %rd694, %rd565;
	xor.b64  	%rd567, %rd693, %rd565;
	xor.b64  	%rd568, %rd692, %rd565;
	xor.b64  	%rd569, %rd691, %rd565;
	xor.b64  	%rd570, %rd690, %rd565;
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r4540}, %rd526;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r4541,%dummy}, %rd526;
	}
	shf.l.wrap.b32 	%r4542, %r4541, %r4540, 1;
	shf.l.wrap.b32 	%r4543, %r4540, %r4541, 1;
	mov.b64 	%rd571, {%r4543, %r4542};
	xor.b64  	%rd572, %rd538, %rd571;
	xor.b64  	%rd573, %rd689, %rd572;
	xor.b64  	%rd574, %rd688, %rd572;
	xor.b64  	%rd575, %rd687, %rd572;
	xor.b64  	%rd576, %rd686, %rd572;
	xor.b64  	%rd577, %rd685, %rd572;
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r4544}, %rd552;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r4545,%dummy}, %rd552;
	}
	shf.l.wrap.b32 	%r4546, %r4545, %r4544, 1;
	shf.l.wrap.b32 	%r4547, %r4544, %r4545, 1;
	mov.b64 	%rd578, {%r4547, %r4546};
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r4548}, %rd547;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r4549,%dummy}, %rd547;
	}
	shf.l.wrap.b32 	%r4550, %r4549, %r4548, 3;
	shf.l.wrap.b32 	%r4551, %r4548, %r4549, 3;
	mov.b64 	%rd579, {%r4551, %r4550};
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r4552}, %rd560;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r4553,%dummy}, %rd560;
	}
	shf.l.wrap.b32 	%r4554, %r4553, %r4552, 6;
	shf.l.wrap.b32 	%r4555, %r4552, %r4553, 6;
	mov.b64 	%rd580, {%r4555, %r4554};
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r4556}, %rd554;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r4557,%dummy}, %rd554;
	}
	shf.l.wrap.b32 	%r4558, %r4557, %r4556, 10;
	shf.l.wrap.b32 	%r4559, %r4556, %r4557, 10;
	mov.b64 	%rd581, {%r4559, %r4558};
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r4560}, %rd562;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r4561,%dummy}, %rd562;
	}
	shf.l.wrap.b32 	%r4562, %r4561, %r4560, 15;
	shf.l.wrap.b32 	%r4563, %r4560, %r4561, 15;
	mov.b64 	%rd582, {%r4563, %r4562};
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r4564}, %rd569;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r4565,%dummy}, %rd569;
	}
	shf.l.wrap.b32 	%r4566, %r4565, %r4564, 21;
	shf.l.wrap.b32 	%r4567, %r4564, %r4565, 21;
	mov.b64 	%rd583, {%r4567, %r4566};
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r4568}, %rd566;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r4569,%dummy}, %rd566;
	}
	shf.l.wrap.b32 	%r4570, %r4569, %r4568, 28;
	shf.l.wrap.b32 	%r4571, %r4568, %r4569, 28;
	mov.b64 	%rd584, {%r4571, %r4570};
	{
	.reg .b32 %dummy;
	mov.b64 	{%r4572,%dummy}, %rd546;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r4573}, %rd546;
	}
	shf.r.wrap.b32 	%r4574, %r4573, %r4572, 28;
	shf.r.wrap.b32 	%r4575, %r4572, %r4573, 28;
	mov.b64 	%rd585, {%r4575, %r4574};
	{
	.reg .b32 %dummy;
	mov.b64 	{%r4576,%dummy}, %rd555;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r4577}, %rd555;
	}
	shf.r.wrap.b32 	%r4578, %r4577, %r4576, 19;
	shf.r.wrap.b32 	%r4579, %r4576, %r4577, 19;
	mov.b64 	%rd586, {%r4579, %r4578};
	{
	.reg .b32 %dummy;
	mov.b64 	{%r4580,%dummy}, %rd567;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r4581}, %rd567;
	}
	shf.r.wrap.b32 	%r4582, %r4581, %r4580, 9;
	shf.r.wrap.b32 	%r4583, %r4580, %r4581, 9;
	mov.b64 	%rd587, {%r4583, %r4582};
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r4584}, %rd556;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r4585,%dummy}, %rd556;
	}
	shf.l.wrap.b32 	%r4586, %r4585, %r4584, 2;
	shf.l.wrap.b32 	%r4587, %r4584, %r4585, 2;
	mov.b64 	%rd588, {%r4587, %r4586};
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r4588}, %rd577;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r4589,%dummy}, %rd577;
	}
	shf.l.wrap.b32 	%r4590, %r4589, %r4588, 14;
	shf.l.wrap.b32 	%r4591, %r4588, %r4589, 14;
	mov.b64 	%rd589, {%r4591, %r4590};
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r4592}, %rd573;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r4593,%dummy}, %rd573;
	}
	shf.l.wrap.b32 	%r4594, %r4593, %r4592, 27;
	shf.l.wrap.b32 	%r4595, %r4592, %r4593, 27;
	mov.b64 	%rd590, {%r4595, %r4594};
	{
	.reg .b32 %dummy;
	mov.b64 	{%r4596,%dummy}, %rd548;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r4597}, %rd548;
	}
	shf.r.wrap.b32 	%r4598, %r4597, %r4596, 23;
	shf.r.wrap.b32 	%r4599, %r4596, %r4597, 23;
	mov.b64 	%rd591, {%r4599, %r4598};
	{
	.reg .b32 %dummy;
	mov.b64 	{%r4600,%dummy}, %rd570;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r4601}, %rd570;
	}
	shf.r.wrap.b32 	%r4602, %r4601, %r4600, 8;
	shf.r.wrap.b32 	%r4603, %r4600, %r4601, 8;
	mov.b64 	%rd592, {%r4603, %r4602};
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r4604}, %rd576;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r4605,%dummy}, %rd576;
	}
	shf.l.wrap.b32 	%r4606, %r4605, %r4604, 8;
	shf.l.wrap.b32 	%r4607, %r4604, %r4605, 8;
	mov.b64 	%rd593, {%r4607, %r4606};
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r4608}, %rd568;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r4609,%dummy}, %rd568;
	}
	shf.l.wrap.b32 	%r4610, %r4609, %r4608, 25;
	shf.l.wrap.b32 	%r4611, %r4608, %r4609, 25;
	mov.b64 	%rd594, {%r4611, %r4610};
	{
	.reg .b32 %dummy;
	mov.b64 	{%r4612,%dummy}, %rd561;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r4613}, %rd561;
	}
	shf.r.wrap.b32 	%r4614, %r4613, %r4612, 21;
	shf.r.wrap.b32 	%r4615, %r4612, %r4613, 21;
	mov.b64 	%rd595, {%r4615, %r4614};
	{
	.reg .b32 %dummy;
	mov.b64 	{%r4616,%dummy}, %rd559;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r4617}, %rd559;
	}
	shf.r.wrap.b32 	%r4618, %r4617, %r4616, 2;
	shf.r.wrap.b32 	%r4619, %r4616, %r4617, 2;
	mov.b64 	%rd596, {%r4619, %r4618};
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r4620}, %rd549;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r4621,%dummy}, %rd549;
	}
	shf.l.wrap.b32 	%r4622, %r4621, %r4620, 18;
	shf.l.wrap.b32 	%r4623, %r4620, %r4621, 18;
	mov.b64 	%rd597, {%r4623, %r4622};
	{
	.reg .b32 %dummy;
	mov.b64 	{%r4624,%dummy}, %rd575;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r4625}, %rd575;
	}
	shf.r.wrap.b32 	%r4626, %r4625, %r4624, 25;
	shf.r.wrap.b32 	%r4627, %r4624, %r4625, 25;
	mov.b64 	%rd598, {%r4627, %r4626};
	{
	.reg .b32 %dummy;
	mov.b64 	{%r4628,%dummy}, %rd563;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r4629}, %rd563;
	}
	shf.r.wrap.b32 	%r4630, %r4629, %r4628, 3;
	shf.r.wrap.b32 	%r4631, %r4628, %r4629, 3;
	mov.b64 	%rd599, {%r4631, %r4630};
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r4632}, %rd574;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%r4633,%dummy}, %rd574;
	}
	shf.l.wrap.b32 	%r4634, %r4633, %r4632, 20;
	shf.l.wrap.b32 	%r4635, %r4632, %r4633, 20;
	mov.b64 	%rd600, {%r4635, %r4634};
	{
	.reg .b32 %dummy;
	mov.b64 	{%r4636,%dummy}, %rd553;
	}
	{
	.reg .b32 %dummy;
	mov.b64 	{%dummy,%r4637}, %rd553;
	}
	shf.r.wrap.b32 	%r4638, %r4637, %r4636, 20;
	shf.r.wrap.b32 	%r4639, %r4636, %r4637, 20;
	mov.b64 	%rd601, {%r4639, %r4638};
	not.b64 	%rd602, %rd601;
	and.b64  	%rd603, %rd595, %rd602;
	xor.b64  	%rd604, %rd603, %rd545;
	not.b64 	%rd605, %rd595;
	and.b64  	%rd606, %rd583, %rd605;
	xor.b64  	%rd704, %rd606, %rd601;
	not.b64 	%rd607, %rd583;
	and.b64  	%rd608, %rd589, %rd607;
	xor.b64  	%rd699, %rd608, %rd595;
	not.b64 	%rd609, %rd589;
	and.b64  	%rd610, %rd545, %rd609;
	xor.b64  	%rd694, %rd610, %rd583;
	not.b64 	%rd611, %rd545;
	and.b64  	%rd612, %rd601, %rd611;
	xor.b64  	%rd689, %rd589, %rd612;
	not.b64 	%rd613, %rd600;
	and.b64  	%rd614, %rd579, %rd613;
	xor.b64  	%rd708, %rd614, %rd584;
	not.b64 	%rd615, %rd579;
	and.b64  	%rd616, %rd586, %rd615;
	xor.b64  	%rd703, %rd616, %rd600;
	not.b64 	%rd617, %rd586;
	and.b64  	%rd618, %rd599, %rd617;
	xor.b64  	%rd698, %rd618, %rd579;
	not.b64 	%rd619, %rd599;
	and.b64  	%rd620, %rd584, %rd619;
	xor.b64  	%rd693, %rd620, %rd586;
	not.b64 	%rd621, %rd584;
	and.b64  	%rd622, %rd600, %rd621;
	xor.b64  	%rd688, %rd599, %rd622;
	not.b64 	%rd623, %rd580;
	and.b64  	%rd624, %rd594, %rd623;
	xor.b64  	%rd707, %rd624, %rd578;
	not.b64 	%rd625, %rd594;
	and.b64  	%rd626, %rd593, %rd625;
	xor.b64  	%rd702, %rd626, %rd580;
	not.b64 	%rd627, %rd593;
	and.b64  	%rd628, %rd597, %rd627;
	xor.b64  	%rd697, %rd628, %rd594;
	not.b64 	%rd629, %rd597;
	and.b64  	%rd630, %rd578, %rd629;
	xor.b64  	%rd692, %rd630, %rd593;
	not.b64 	%rd631, %rd578;
	and.b64  	%rd632, %rd580, %rd631;
	xor.b64  	%rd687, %rd597, %rd632;
	not.b64 	%rd633, %rd585;
	and.b64  	%rd634, %rd581, %rd633;
	xor.b64  	%rd706, %rd634, %rd590;
	not.b64 	%rd635, %rd581;
	and.b64  	%rd636, %rd582, %rd635;
	xor.b64  	%rd701, %rd636, %rd585;
	not.b64 	%rd637, %rd582;
	and.b64  	%rd638, %rd592, %rd637;
	xor.b64  	%rd696, %rd638, %rd581;
	not.b64 	%rd639, %rd592;
	and.b64  	%rd640, %rd590, %rd639;
	xor.b64  	%rd691, %rd640, %rd582;
	not.b64 	%rd641, %rd590;
	and.b64  	%rd642, %rd585, %rd641;
	xor.b64  	%rd686, %rd592, %rd642;
	not.b64 	%rd643, %rd587;
	and.b64  	%rd644, %rd598, %rd643;
	xor.b64  	%rd705, %rd644, %rd596;
	not.b64 	%rd645, %rd598;
	and.b64  	%rd646, %rd591, %rd645;
	xor.b64  	%rd700, %rd646, %rd587;
	not.b64 	%rd647, %rd591;
	and.b64  	%rd648, %rd588, %rd647;
	xor.b64  	%rd695, %rd648, %rd598;
	not.b64 	%rd649, %rd588;
	and.b64  	%rd650, %rd596, %rd649;
	xor.b64  	%rd690, %rd650, %rd591;
	not.b64 	%rd651, %rd596;
	and.b64  	%rd652, %rd587, %rd651;
	xor.b64  	%rd685, %rd588, %rd652;
	ld.global.nc.u64 	%rd653, [%rd684];
	xor.b64  	%rd124, %rd604, %rd653;
	add.s64 	%rd684, %rd684, 8;
	add.s32 	%r4641, %r4641, 1;
	setp.ne.s32 	%p10, %r4641, 24;
	@%p10 bra 	$L__BB0_9;

	ld.const.u64 	%rd126, [target+24];
	setp.eq.s64 	%p11, %rd694, %rd126;
	@%p11 bra 	$L__BB0_12;
	bra.uni 	$L__BB0_11;

$L__BB0_12:
	ld.const.u64 	%rd127, [target+16];
	setp.eq.s64 	%p12, %rd699, %rd127;
	@%p12 bra 	$L__BB0_14;
	bra.uni 	$L__BB0_13;

$L__BB0_14:
	ld.const.u64 	%rd128, [target+8];
	setp.eq.s64 	%p13, %rd704, %rd128;
	@%p13 bra 	$L__BB0_16;
	bra.uni 	$L__BB0_15;

$L__BB0_16:
	ld.const.u64 	%rd654, [target];
	setp.lt.u64 	%p15, %rd124, %rd654;
	bra.uni 	$L__BB0_17;

$L__BB0_11:
	setp.lt.u64 	%p15, %rd694, %rd126;
	bra.uni 	$L__BB0_17;

$L__BB0_13:
	setp.lt.u64 	%p15, %rd699, %rd127;
	bra.uni 	$L__BB0_17;

$L__BB0_15:
	setp.lt.u64 	%p15, %rd704, %rd128;

$L__BB0_17:
	not.pred 	%p14, %p15;
	@%p14 bra 	$L__BB0_19;

	mov.u64 	%rd655, 0;
	atom.global.cas.b64 	%rd656, [%rd2], %rd655, %rd7;

$L__BB0_19:
	ret;

}

